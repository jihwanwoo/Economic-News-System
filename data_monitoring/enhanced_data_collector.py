"""
í–¥ìƒëœ ê¸€ë¡œë²Œ ê²½ì œ ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“ˆ
ë¯¸êµ­, ì•„ì‹œì•„, ê±°ì‹œì§€í‘œ, ë‰´ìŠ¤, SNS ë¶„ì„ í¬í•¨
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import yfinance as yf
import pandas as pd
import numpy as np
import requests
import feedparser
import asyncio
import aiohttp
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
import logging

# í•„ìš”í•œ ëª¨ë“ˆë“¤ import
from data_monitoring.integrated_alphavantage_collector import IntegratedAlphaVantageCollector
from data_monitoring.alphavantage_intelligence_complete import AlphaVantageIntelligenceComplete
from data_monitoring.fred_data_collector import FREDDataCollector
from data_monitoring.news_social_collector import EnhancedNewsCollector
import json

@dataclass
class MarketData:
    symbol: str
    name: str
    timestamp: datetime
    current_price: float
    previous_close: float
    change_percent: float
    volume: int
    high_24h: float
    low_24h: float
    market_cap: Optional[float] = None
    region: str = "US"

@dataclass
class NewsData:
    title: str
    summary: str
    url: str
    published: datetime
    source: str
    sentiment_score: float = 0.0
    keywords: List[str] = None

@dataclass
class EconomicIndicator:
    name: str
    value: float
    previous_value: float
    change_percent: float
    timestamp: datetime
    unit: str
    importance: str  # high, medium, low

class EnhancedGlobalDataCollector:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.session = None
        
        # Alpha Vantage í†µí•©
        try:
            self.alphavantage_collector = IntegratedAlphaVantageCollector()
            self.alphavantage_intelligence = AlphaVantageIntelligenceComplete()
            self.use_alphavantage = True
            self.logger.info("âœ… Alpha Vantage í†µí•© í™œì„±í™” (ë°ì´í„° + Intelligence)")
        except Exception as e:
            self.logger.warning(f"Alpha Vantage í†µí•© ì‹¤íŒ¨: {e}")
            self.use_alphavantage = False
        
        # FRED ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        try:
            self.fred_collector = FREDDataCollector()
            self.use_fred = True
            self.logger.info("âœ… FRED ë°ì´í„° ìˆ˜ì§‘ê¸° í™œì„±í™”")
        except Exception as e:
            self.logger.warning(f"âš ï¸ FRED ìˆ˜ì§‘ê¸° ë¹„í™œì„±í™”: {e}")
            self.use_fred = False
        
        # ê°•í™”ëœ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        try:
            self.news_collector = EnhancedNewsCollector()
            self.use_enhanced_news = True
            self.logger.info("âœ… ê°•í™”ëœ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° í™œì„±í™”")
        except Exception as e:
            self.logger.warning(f"âš ï¸ ê°•í™”ëœ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ë¹„í™œì„±í™”: {e}")
            self.use_enhanced_news = False
        
        # ê¸€ë¡œë²Œ ì‹œìž¥ ì‹¬ë³¼ ì •ì˜
        self.market_symbols = {
            # ë¯¸êµ­ ì£¼ìš” ì§€ìˆ˜
            "US_INDICES": {
                "^GSPC": "S&P 500",
                "^DJI": "Dow Jones",
                "^IXIC": "NASDAQ",
                "^RUT": "Russell 2000",
                "^VIX": "VIX"
            },
            
            # ë¯¸êµ­ ì£¼ìš” ì£¼ì‹
            "US_STOCKS": {
                "AAPL": "Apple Inc",
                "MSFT": "Microsoft",
                "GOOGL": "Alphabet",
                "AMZN": "Amazon",
                "TSLA": "Tesla",
                "NVDA": "NVIDIA",
                "META": "Meta",
                "NFLX": "Netflix"
            },
            
            # ì•„ì‹œì•„ ì£¼ìš” ì§€ìˆ˜
            "ASIA_INDICES": {
                "^KS11": "KOSPI (í•œêµ­)",
                "^N225": "Nikkei 225 (ì¼ë³¸)",
                "000001.SS": "Shanghai Composite (ì¤‘êµ­)",
                "^HSI": "Hang Seng (í™ì½©)",
                "^TWII": "Taiwan Weighted (ëŒ€ë§Œ)",
                "^STI": "Straits Times (ì‹±ê°€í¬ë¥´)"
            },
            
            # í†µí™”
            "CURRENCIES": {
                "USDKRW=X": "USD/KRW",
                "USDJPY=X": "USD/JPY",
                "USDCNY=X": "USD/CNY",
                "EURUSD=X": "EUR/USD",
                "GBPUSD=X": "GBP/USD",
                "DX-Y.NYB": "Dollar Index (DXY)"  # DXY ëŒ€ì²´ ì‹¬ë³¼
            },
            
            # ì›ìžìž¬
            "COMMODITIES": {
                "GC=F": "Gold",
                "CL=F": "Crude Oil",
                "BTC-USD": "Bitcoin",
                "ETH-USD": "Ethereum"
            },
            
            # ì±„ê¶Œ
            "BONDS": {
                "^TNX": "10-Year Treasury",
                "^TYX": "30-Year Treasury",
                "^FVX": "5-Year Treasury"
            }
        }
        
        # ë‰´ìŠ¤ ì†ŒìŠ¤ ì •ì˜
        self.news_sources = {
            "FINANCIAL": [
                "https://feeds.bloomberg.com/markets/news.rss",
                "https://feeds.reuters.com/reuters/businessNews",
                "https://rss.cnn.com/rss/money_latest.rss",
                "https://feeds.marketwatch.com/marketwatch/topstories/",
                "https://feeds.finance.yahoo.com/rss/2.0/headline"
            ],
            "ECONOMIC": [
                "https://www.federalreserve.gov/feeds/press_all.xml",
                "https://feeds.reuters.com/reuters/economicNews"
            ],
            "ASIA": [
                "https://feeds.reuters.com/reuters/asiaNews",
                "https://english.yonhapnews.co.kr/RSS/news.xml"
            ]
        }
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    def collect_market_data_safe(self, symbol: str, region: str = "US") -> Optional[MarketData]:
        """ì•ˆì „í•œ ì‹œìž¥ ë°ì´í„° ìˆ˜ì§‘ (ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”)"""
        try:
            # DXY íŠ¹ë³„ ì²˜ë¦¬
            if symbol in ["DXY", "$DXY"]:
                symbol = "DX-Y.NYB"  # Yahoo Financeì˜ ì˜¬ë°”ë¥¸ DXY ì‹¬ë³¼
            
            ticker = yf.Ticker(symbol)
            
            # ì—¬ëŸ¬ ê¸°ê°„ìœ¼ë¡œ ì‹œë„
            hist = None
            for period in ["2d", "5d", "1mo"]:
                try:
                    hist = ticker.history(period=period)
                    if not hist.empty and len(hist) >= 2:
                        break
                except:
                    continue
            
            if hist is None or hist.empty:
                self.logger.warning(f"No data found for symbol: {symbol}")
                return None
            
            # ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
            info = {}
            try:
                info = ticker.info
            except:
                self.logger.debug(f"Could not get info for {symbol}, using defaults")
            
            current_data = hist.iloc[-1]
            previous_data = hist.iloc[-2] if len(hist) > 1 else current_data
            
            # ë³€í™”ìœ¨ ê³„ì‚°
            change_percent = 0.0
            if previous_data['Close'] != 0:
                change_percent = ((current_data['Close'] - previous_data['Close']) / previous_data['Close']) * 100
            
            return MarketData(
                symbol=symbol,
                name=info.get('longName', self._get_symbol_name(symbol)),
                timestamp=datetime.now(),
                current_price=float(current_data['Close']),
                previous_close=float(previous_data['Close']),
                change_percent=float(change_percent),
                volume=int(current_data.get('Volume', 0)),
                high_24h=float(current_data['High']),
                low_24h=float(current_data['Low']),
                market_cap=info.get('marketCap'),
                region=region
            )
            
        except Exception as e:
            self.logger.error(f"Error collecting data for {symbol}: {str(e)}")
            return None
    
    def _get_symbol_name(self, symbol: str) -> str:
        """ì‹¬ë³¼ì—ì„œ ì´ë¦„ ì¶”ì¶œ"""
        for category, symbols in self.market_symbols.items():
            if symbol in symbols:
                return symbols[symbol]
        return symbol
    
    async def collect_all_market_data(self) -> Dict[str, Dict[str, MarketData]]:
        """ëª¨ë“  ì‹œìž¥ ë°ì´í„° ìˆ˜ì§‘"""
        results = {}
        
        for category, symbols in self.market_symbols.items():
            self.logger.info(f"Collecting {category} data...")
            category_data = {}
            
            for symbol, name in symbols.items():
                region = "ASIA" if "ASIA" in category else "US"
                data = await asyncio.to_thread(self.collect_market_data_safe, symbol, region)
                if data:
                    category_data[symbol] = data
                    self.logger.debug(f"âœ… {symbol}: {data.current_price}")
                else:
                    self.logger.warning(f"âŒ Failed to collect data for {symbol}")
            
            results[category] = category_data
        
        return results
    
    def collect_news_data(self, max_articles: int = 50) -> List[NewsData]:
        """ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘"""
        all_news = []
        
        for category, sources in self.news_sources.items():
            self.logger.info(f"Collecting {category} news...")
            
            for source_url in sources:
                try:
                    feed = feedparser.parse(source_url)
                    
                    for entry in feed.entries[:10]:  # ê° ì†ŒìŠ¤ì—ì„œ ìµœëŒ€ 10ê°œ
                        try:
                            published = datetime.now()
                            if hasattr(entry, 'published_parsed') and entry.published_parsed:
                                published = datetime(*entry.published_parsed[:6])
                            
                            # ê°„ë‹¨í•œ ê°ì • ë¶„ì„ (í‚¤ì›Œë“œ ê¸°ë°˜)
                            sentiment_score = self._analyze_sentiment(entry.title + " " + entry.get('summary', ''))
                            
                            # í‚¤ì›Œë“œ ì¶”ì¶œ
                            keywords = self._extract_keywords(entry.title + " " + entry.get('summary', ''))
                            
                            news_item = NewsData(
                                title=entry.title,
                                summary=entry.get('summary', '')[:500],  # 500ìž ì œí•œ
                                url=entry.link,
                                published=published,
                                source=feed.feed.get('title', 'Unknown'),
                                sentiment_score=sentiment_score,
                                keywords=keywords
                            )
                            
                            all_news.append(news_item)
                            
                        except Exception as e:
                            self.logger.debug(f"Error processing news entry: {e}")
                            continue
                
                except Exception as e:
                    self.logger.warning(f"Error fetching news from {source_url}: {e}")
                    continue
        
        # ìµœì‹  ë‰´ìŠ¤ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ì œí•œ
        all_news.sort(key=lambda x: x.published, reverse=True)
        return all_news[:max_articles]
    
    def _analyze_sentiment(self, text: str) -> float:
        """ê°„ë‹¨í•œ ê°ì • ë¶„ì„ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        positive_words = [
            'gain', 'rise', 'up', 'surge', 'rally', 'boost', 'strong', 'growth', 
            'positive', 'bullish', 'optimistic', 'recovery', 'improve', 'advance'
        ]
        
        negative_words = [
            'fall', 'drop', 'down', 'decline', 'crash', 'weak', 'loss', 'negative',
            'bearish', 'pessimistic', 'recession', 'crisis', 'concern', 'worry'
        ]
        
        text_lower = text.lower()
        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)
        
        total_words = len(text.split())
        if total_words == 0:
            return 0.0
        
        # -1 (ë§¤ìš° ë¶€ì •) ~ 1 (ë§¤ìš° ê¸ì •)
        sentiment = (positive_count - negative_count) / max(total_words / 10, 1)
        return max(-1.0, min(1.0, sentiment))
    
    def _extract_keywords(self, text: str) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê²½ì œ/ê¸ˆìœµ ê´€ë ¨ í‚¤ì›Œë“œ
        economic_keywords = [
            'inflation', 'interest rate', 'fed', 'gdp', 'unemployment', 'earnings',
            'revenue', 'profit', 'stock', 'market', 'trading', 'investment',
            'economy', 'financial', 'monetary', 'fiscal', 'policy', 'bank',
            'cryptocurrency', 'bitcoin', 'ethereum', 'oil', 'gold', 'dollar'
        ]
        
        text_lower = text.lower()
        found_keywords = []
        
        for keyword in economic_keywords:
            if keyword in text_lower:
                found_keywords.append(keyword)
        
        return found_keywords[:5]  # ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œ
    
    def collect_economic_indicators(self) -> List[EconomicIndicator]:
        """ê²½ì œ ì§€í‘œ ìˆ˜ì§‘ (ì‹œë®¬ë ˆì´ì…˜)"""
        # ì‹¤ì œë¡œëŠ” FRED API, ê²½ì œ ë°ì´í„° API ë“±ì„ ì‚¬ìš©
        indicators = []
        
        try:
            # VIXë¥¼ ë³€ë™ì„± ì§€í‘œë¡œ ì‚¬ìš©
            vix_data = self.collect_market_data_safe("^VIX")
            if vix_data:
                indicators.append(EconomicIndicator(
                    name="Market Volatility (VIX)",
                    value=vix_data.current_price,
                    previous_value=vix_data.previous_close,
                    change_percent=vix_data.change_percent,
                    timestamp=datetime.now(),
                    unit="Index",
                    importance="high"
                ))
            
            # 10ë…„ êµ­ì±„ ìˆ˜ìµë¥ 
            treasury_data = self.collect_market_data_safe("^TNX")
            if treasury_data:
                indicators.append(EconomicIndicator(
                    name="10-Year Treasury Yield",
                    value=treasury_data.current_price,
                    previous_value=treasury_data.previous_close,
                    change_percent=treasury_data.change_percent,
                    timestamp=datetime.now(),
                    unit="Percent",
                    importance="high"
                ))
            
        except Exception as e:
            self.logger.error(f"Error collecting economic indicators: {e}")
        
        return indicators
    
    def analyze_market_sentiment(self, news_data: List[NewsData]) -> Dict[str, Any]:
        """ì‹œìž¥ ê°ì • ë¶„ì„"""
        if not news_data:
            return {"overall_sentiment": 0.0, "sentiment_distribution": {}}
        
        sentiments = [news.sentiment_score for news in news_data]
        
        overall_sentiment = np.mean(sentiments)
        
        # ê°ì • ë¶„í¬
        positive_count = sum(1 for s in sentiments if s > 0.1)
        negative_count = sum(1 for s in sentiments if s < -0.1)
        neutral_count = len(sentiments) - positive_count - negative_count
        
        # í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
        all_keywords = []
        for news in news_data:
            if news.keywords:
                all_keywords.extend(news.keywords)
        
        keyword_freq = {}
        for keyword in all_keywords:
            keyword_freq[keyword] = keyword_freq.get(keyword, 0) + 1
        
        # ìƒìœ„ í‚¤ì›Œë“œ
        top_keywords = sorted(keyword_freq.items(), key=lambda x: x[1], reverse=True)[:10]
        
        return {
            "overall_sentiment": float(overall_sentiment),
            "sentiment_distribution": {
                "positive": positive_count,
                "negative": negative_count,
                "neutral": neutral_count
            },
            "top_keywords": top_keywords,
            "total_articles": len(news_data)
        }
    
    def generate_comprehensive_report(self) -> Dict[str, Any]:
        """ì¢…í•© ì‹œìž¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        self.logger.info("Generating comprehensive market report...")
        
        # ì‹œìž¥ ë°ì´í„° ìˆ˜ì§‘ (ë™ê¸° ë°©ì‹ìœ¼ë¡œ ë³€ê²½)
        market_data = self._collect_market_data_sync()
        
        # ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
        news_data = self.collect_news_data()
        
        # ê²½ì œ ì§€í‘œ ìˆ˜ì§‘
        economic_indicators = self.collect_economic_indicators()
        
        # ê°ì • ë¶„ì„
        sentiment_analysis = self.analyze_market_sentiment(news_data)
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = {
            "timestamp": datetime.now().isoformat(),
            "market_data": self._serialize_market_data(market_data),
            "news_summary": {
                "total_articles": len(news_data),
                "latest_articles": [
                    {
                        "title": news.title,
                        "source": news.source,
                        "sentiment": news.sentiment_score,
                        "published": news.published.isoformat()
                    }
                    for news in news_data[:5]
                ]
            },
            "economic_indicators": [
                {
                    "name": indicator.name,
                    "value": indicator.value,
                    "change_percent": indicator.change_percent,
                    "importance": indicator.importance
                }
                for indicator in economic_indicators
            ],
            "sentiment_analysis": sentiment_analysis,
            "market_summary": self._generate_market_summary(market_data)
        }
        
        return report
    
    def _collect_market_data_sync(self) -> Dict[str, Dict[str, MarketData]]:
        """ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì‹œìž¥ ë°ì´í„° ìˆ˜ì§‘ (Alpha Vantage ìš°ì„ )"""
        results = {}
        
        # Alpha Vantage ë°ì´í„° ìš°ì„  ìˆ˜ì§‘
        if self.use_alphavantage:
            try:
                self.logger.info("ðŸš€ Alpha Vantage ê³ í’ˆì§ˆ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
                av_data = self.alphavantage_collector.collect_priority_data()
                
                # Alpha Vantage ë°ì´í„°ë¥¼ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                if av_data.get("stocks"):
                    results["ALPHAVANTAGE_STOCKS"] = {}
                    for stock_data in av_data["stocks"]:
                        market_data = MarketData(
                            symbol=stock_data.symbol,
                            name=stock_data.name,
                            timestamp=stock_data.timestamp,
                            current_price=stock_data.current_price,
                            previous_close=stock_data.previous_close,
                            change_percent=stock_data.change_percent,
                            volume=stock_data.volume,
                            high_24h=stock_data.high_24h,
                            low_24h=stock_data.low_24h,
                            market_cap=None,
                            region="US"
                        )
                        results["ALPHAVANTAGE_STOCKS"][stock_data.symbol] = market_data
                
                if av_data.get("indices"):
                    results["ALPHAVANTAGE_INDICES"] = {}
                    for index_data in av_data["indices"]:
                        market_data = MarketData(
                            symbol=index_data.symbol,
                            name=index_data.name,
                            timestamp=index_data.timestamp,
                            current_price=index_data.current_price,
                            previous_close=index_data.previous_close,
                            change_percent=index_data.change_percent,
                            volume=index_data.volume,
                            high_24h=index_data.high_24h,
                            low_24h=index_data.low_24h,
                            market_cap=None,
                            region="US"
                        )
                        results["ALPHAVANTAGE_INDICES"][index_data.symbol] = market_data
                
                if av_data.get("forex"):
                    results["ALPHAVANTAGE_FOREX"] = {}
                    for forex_data in av_data["forex"]:
                        market_data = MarketData(
                            symbol=forex_data.symbol,
                            name=forex_data.name,
                            timestamp=forex_data.timestamp,
                            current_price=forex_data.current_price,
                            previous_close=forex_data.previous_close,
                            change_percent=forex_data.change_percent,
                            volume=forex_data.volume,
                            high_24h=forex_data.high_24h,
                            low_24h=forex_data.low_24h,
                            market_cap=None,
                            region="GLOBAL"
                        )
                        results["ALPHAVANTAGE_FOREX"][forex_data.symbol] = market_data
                
                self.logger.info(f"âœ… Alpha Vantage ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {sum(len(v) for v in results.values())}ê°œ")
                
            except Exception as e:
                self.logger.error(f"Alpha Vantage ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
        
        # ê¸°ì¡´ Yahoo Finance ë°ì´í„°ë¡œ ë³´ì™„
        for category, symbols in self.market_symbols.items():
            # Alpha Vantageì—ì„œ ì´ë¯¸ ìˆ˜ì§‘í•œ ì¹´í…Œê³ ë¦¬ëŠ” ê±´ë„ˆë›°ê¸°
            if f"ALPHAVANTAGE_{category}" in results:
                continue
                
            self.logger.info(f"Collecting {category} data (Yahoo Finance)...")
            category_data = {}
            
            for symbol, name in symbols.items():
                region = "ASIA" if "ASIA" in category else "US"
                data = self.collect_market_data_safe(symbol, region)
                if data:
                    category_data[symbol] = data
                    self.logger.debug(f"âœ… {symbol}: {data.current_price}")
                else:
                    self.logger.warning(f"âŒ Failed to collect data for {symbol}")
            
            results[category] = category_data
        
        return results
    
    async def _collect_market_data_async(self):
        """ë¹„ë™ê¸° ì‹œìž¥ ë°ì´í„° ìˆ˜ì§‘"""
        return await asyncio.to_thread(self.collect_all_market_data)
    
    def _serialize_market_data(self, market_data: Dict[str, Dict[str, MarketData]]) -> Dict:
        """ì‹œìž¥ ë°ì´í„° ì§ë ¬í™”"""
        serialized = {}
        for category, data_dict in market_data.items():
            serialized[category] = {}
            for symbol, data in data_dict.items():
                serialized[category][symbol] = {
                    "name": data.name,
                    "current_price": data.current_price,
                    "change_percent": data.change_percent,
                    "volume": data.volume,
                    "region": data.region
                }
        return serialized
    
    def _generate_market_summary(self, market_data: Dict[str, Dict[str, MarketData]]) -> Dict[str, Any]:
        """ì‹œìž¥ ìš”ì•½ ìƒì„±"""
        summary = {
            "us_market_status": "neutral",
            "asia_market_status": "neutral",
            "major_movers": [],
            "risk_indicators": {}
        }
        
        try:
            # ë¯¸êµ­ ì‹œìž¥ ìƒíƒœ
            us_indices = market_data.get("US_INDICES", {})
            if us_indices:
                us_changes = [data.change_percent for data in us_indices.values()]
                avg_change = np.mean(us_changes)
                summary["us_market_status"] = "bullish" if avg_change > 1 else "bearish" if avg_change < -1 else "neutral"
            
            # ì•„ì‹œì•„ ì‹œìž¥ ìƒíƒœ
            asia_indices = market_data.get("ASIA_INDICES", {})
            if asia_indices:
                asia_changes = [data.change_percent for data in asia_indices.values()]
                avg_change = np.mean(asia_changes)
                summary["asia_market_status"] = "bullish" if avg_change > 1 else "bearish" if avg_change < -1 else "neutral"
            
            # ì£¼ìš” ë³€ë™ ì¢…ëª©
            all_data = []
            for category_data in market_data.values():
                all_data.extend(category_data.values())
            
            # ë³€ë™ë¥  ê¸°ì¤€ ì •ë ¬
            sorted_by_change = sorted(all_data, key=lambda x: abs(x.change_percent), reverse=True)
            summary["major_movers"] = [
                {
                    "symbol": data.symbol,
                    "name": data.name,
                    "change_percent": data.change_percent
                }
                for data in sorted_by_change[:5]
            ]
            
            # ë¦¬ìŠ¤í¬ ì§€í‘œ
            vix_data = None
            for category_data in market_data.values():
                for symbol, data in category_data.items():
                    if symbol == "^VIX":
                        vix_data = data
                        break
            
            if vix_data:
                summary["risk_indicators"]["vix"] = {
                    "value": vix_data.current_price,
                    "level": "high" if vix_data.current_price > 25 else "medium" if vix_data.current_price > 15 else "low"
                }
        
        except Exception as e:
            self.logger.error(f"Error generating market summary: {e}")
        
        return summary
    
    def collect_intelligence_data(self) -> Dict[str, Any]:
        """Alpha Vantage Intelligence API ë°ì´í„° ìˆ˜ì§‘ (ìµœì í™”ëœ ë²„ì „)"""
        if not self.use_alphavantage:
            return {}
        
        try:
            self.logger.info("ðŸ§  Intelligence ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘...")
            intelligence_data = self.alphavantage_intelligence.collect_comprehensive_intelligence()
            
            # ë°ì´í„° ìš”ì•½ (ìµœì í™”ëœ êµ¬ì¡°)
            summary = intelligence_data.get('summary', {})
            data_counts = summary.get('data_counts', {})
            market_analysis = summary.get('market_analysis', {})
            
            optimized_summary = {
                'market_status_count': data_counts.get('market_status', 0),
                'top_gainers_count': data_counts.get('top_gainers', 0),
                'top_losers_count': data_counts.get('top_losers', 0),
                'most_active_count': data_counts.get('most_active', 0),
                'open_markets_count': market_analysis.get('open_markets', 0),
                'market_volatility': 'unknown'  # ì¶”í›„ ê³„ì‚° ë¡œì§ ì¶”ê°€
            }
            
            self.logger.info(f"âœ… Intelligence ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {optimized_summary}")
            
            return {
                'data': intelligence_data,
                'summary': optimized_summary,
                'timestamp': datetime.now().isoformat(),
                'status': 'success'
            }
            
        except Exception as e:
            self.logger.error(f"Intelligence ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return {
                'error': str(e),
                'timestamp': datetime.now().isoformat(),
                'status': 'failed'
            }
    
    def collect_fred_data(self) -> Dict[str, Any]:
        """FRED ê²½ì œ ë°ì´í„° ìˆ˜ì§‘"""
        if not hasattr(self, 'use_fred') or not self.use_fred:
            return {}
        
        try:
            self.logger.info("ðŸ“Š FRED ê²½ì œ ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘...")
            fred_data = self.fred_collector.collect_key_indicators()
            
            summary = fred_data.get('summary', {})
            self.logger.info(f"âœ… FRED ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {summary.get('collected_indicators', 0)}ê°œ ì§€í‘œ")
            
            return {
                'data': fred_data,
                'summary': summary,
                'timestamp': datetime.now().isoformat(),
                'status': 'success'
            }
            
        except Exception as e:
            self.logger.error(f"FRED ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return {
                'error': str(e),
                'timestamp': datetime.now().isoformat(),
                'status': 'failed'
            }
    
    def collect_enhanced_news_data(self) -> Dict[str, Any]:
        """ê°•í™”ëœ ë‰´ìŠ¤ ë° ì†Œì…œë¯¸ë””ì–´ ë°ì´í„° ìˆ˜ì§‘"""
        if not hasattr(self, 'use_enhanced_news') or not self.use_enhanced_news:
            return {}
        
        try:
            self.logger.info("ðŸ“° ê°•í™”ëœ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘...")
            
            # ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
            news_data = self.news_collector.collect_news_by_category(max_items_per_source=8)
            
            # ì†Œì…œë¯¸ë””ì–´ ë°ì´í„° ìˆ˜ì§‘
            social_data = self.news_collector.get_social_media_mentions()
            
            # í†µí•© ë°ì´í„° êµ¬ì„±
            enhanced_news = {
                'news_data': news_data,
                'social_data': social_data,
                'combined_summary': self._generate_combined_news_summary(news_data, social_data)
            }
            
            news_summary = news_data.get('summary', {})
            self.logger.info(f"âœ… ê°•í™”ëœ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {news_summary.get('total_articles', 0)}ê°œ ê¸°ì‚¬")
            
            return {
                'data': enhanced_news,
                'summary': enhanced_news['combined_summary'],
                'timestamp': datetime.now().isoformat(),
                'status': 'success'
            }
            
        except Exception as e:
            self.logger.error(f"ê°•í™”ëœ ë‰´ìŠ¤ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return {
                'error': str(e),
                'timestamp': datetime.now().isoformat(),
                'status': 'failed'
            }
    
    def _generate_combined_news_summary(self, news_data: Dict, social_data: Dict) -> Dict[str, Any]:
        """ë‰´ìŠ¤ì™€ ì†Œì…œë¯¸ë””ì–´ ë°ì´í„° í†µí•© ìš”ì•½"""
        try:
            news_summary = news_data.get('summary', {})
            news_sentiment = news_summary.get('sentiment_analysis', {})
            social_sentiment = social_data.get('overall_sentiment', {})
            
            combined_summary = {
                'total_articles': news_summary.get('total_articles', 0),
                'news_sentiment': {
                    'positive_ratio': news_sentiment.get('positive_ratio', 0),
                    'negative_ratio': news_sentiment.get('negative_ratio', 0)
                },
                'social_sentiment': {
                    'score': social_sentiment.get('score', 0),
                    'label': social_sentiment.get('label', 'neutral')
                },
                'trending_topics': news_summary.get('trending_topics', {}),
                'social_mentions': {
                    'twitter': social_data.get('platforms', {}).get('twitter', {}).get('mentions', 0),
                    'reddit_posts': social_data.get('platforms', {}).get('reddit', {}).get('posts', 0)
                },
                'overall_market_sentiment': self._calculate_overall_sentiment(news_sentiment, social_sentiment)
            }
            
            return combined_summary
            
        except Exception as e:
            self.logger.error(f"í†µí•© ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
            return {}
    
    def _calculate_overall_sentiment(self, news_sentiment: Dict, social_sentiment: Dict) -> Dict[str, Any]:
        """ì „ì²´ ì‹œìž¥ ê°ì • ê³„ì‚°"""
        try:
            # ë‰´ìŠ¤ ê°ì • ì ìˆ˜ (0-1 ë²”ìœ„ë¡œ ì •ê·œí™”)
            news_positive = news_sentiment.get('positive_ratio', 0) / 100
            news_negative = news_sentiment.get('negative_ratio', 0) / 100
            news_score = news_positive - news_negative
            
            # ì†Œì…œë¯¸ë””ì–´ ê°ì • ì ìˆ˜ (-1 to 1)
            social_score = social_sentiment.get('score', 0)
            
            # ê°€ì¤‘ í‰ê·  (ë‰´ìŠ¤ 70%, ì†Œì…œë¯¸ë””ì–´ 30%)
            overall_score = (news_score * 0.7) + (social_score * 0.3)
            
            # ë¼ë²¨ë§
            if overall_score > 0.2:
                label = "ë§¤ìš° ê¸ì •ì "
            elif overall_score > 0.05:
                label = "ê¸ì •ì "
            elif overall_score > -0.05:
                label = "ì¤‘ë¦½"
            elif overall_score > -0.2:
                label = "ë¶€ì •ì "
            else:
                label = "ë§¤ìš° ë¶€ì •ì "
            
            return {
                'score': round(overall_score, 3),
                'label': label,
                'news_weight': 0.7,
                'social_weight': 0.3
            }
            
        except Exception as e:
            self.logger.error(f"ì „ì²´ ê°ì • ê³„ì‚° ì˜¤ë¥˜: {e}")
            return {'score': 0, 'label': 'ì¤‘ë¦½', 'news_weight': 0.7, 'social_weight': 0.3}
        
        try:
            self.logger.info("ðŸ§  Intelligence ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘...")
            intelligence_data = self.alphavantage_intelligence.collect_comprehensive_intelligence()
            
            # ë°ì´í„° ìš”ì•½ (ìµœì í™”ëœ êµ¬ì¡°)
            summary = {
                'market_status_count': len(intelligence_data.get('market_status', [])),
                'top_gainers_count': len(intelligence_data.get('top_gainers_losers', {}).get('top_gainers', [])),
                'top_losers_count': len(intelligence_data.get('top_gainers_losers', {}).get('top_losers', [])),
                'most_active_count': len(intelligence_data.get('top_gainers_losers', {}).get('most_actively_traded', [])),
                'open_markets_count': 0,
                'market_volatility': 'unknown'
            }
            
            # ì¶”ê°€ ë¶„ì„
            if 'summary' in intelligence_data:
                intel_summary = intelligence_data['summary']
                if 'market_analysis' in intel_summary:
                    summary['open_markets_count'] = intel_summary['market_analysis'].get('open_markets', 0)
                if 'risk_indicators' in intel_summary:
                    summary['market_volatility'] = intel_summary['risk_indicators'].get('volatility_level', 'unknown')
            
            self.logger.info(f"âœ… Intelligence ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {summary}")
            
            return {
                'data': intelligence_data,
                'summary': summary,
                'timestamp': datetime.now().isoformat(),
                'status': 'success'
            }
            
        except Exception as e:
            self.logger.error(f"Intelligence ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return {
                'error': str(e),
                'timestamp': datetime.now().isoformat(),
                'status': 'failed'
            }
    
    async def generate_comprehensive_report_async(self) -> Dict[str, Any]:
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± (ë¹„ë™ê¸° ë²„ì „)"""
        try:
            # ê¸°ì¡´ ë°ì´í„° ìˆ˜ì§‘
            market_data = await self.collect_all_market_data()
            news_data = self.collect_news_data(max_articles=10)
            intelligence_data = self.collect_intelligence_data()
            
            # ì‹œìž¥ ìš”ì•½
            market_summary = self._generate_market_summary(market_data)
            
            # ê°ì • ë¶„ì„
            sentiment_scores = [news.sentiment_score for news in news_data if news.sentiment_score is not None]
            overall_sentiment = np.mean(sentiment_scores) if sentiment_scores else 0.0
            
            # Intelligence ì¸ì‚¬ì´íŠ¸
            intelligence_insights = {}
            if intelligence_data and 'data' in intelligence_data:
                intel_data = intelligence_data['data']
                
                # ì‹œìž¥ ìƒíƒœ ë¶„ì„
                if 'market_status' in intel_data:
                    open_markets = [m for m in intel_data['market_status'] if m.get('current_status') == 'open']
                    intelligence_insights['open_markets_count'] = len(open_markets)
                
                # ì£¼ìš” ë³€ë™ ì¢…ëª©
                if 'top_gainers_losers' in intel_data:
                    movers = intel_data['top_gainers_losers']
                    if 'top_gainers' in movers and movers['top_gainers']:
                        top_gainer = movers['top_gainers'][0]
                        intelligence_insights['top_gainer'] = {
                            'ticker': top_gainer.get('ticker'),
                            'change_percentage': top_gainer.get('change_percentage')
                        }
                    
                    if 'top_losers' in movers and movers['top_losers']:
                        top_loser = movers['top_losers'][0]
                        intelligence_insights['top_loser'] = {
                            'ticker': top_loser.get('ticker'),
                            'change_percentage': top_loser.get('change_percentage')
                        }
            
            return {
                'timestamp': datetime.now().isoformat(),
                'market_data': self._serialize_market_data(market_data),
                'market_summary': market_summary,
                'news_data': [
                    {
                        'title': news.title,
                        'source': news.source,
                        'sentiment_score': news.sentiment_score,
                        'published_date': news.published.isoformat() if news.published else None
                    }
                    for news in news_data
                ],
                'sentiment_analysis': {
                    'overall_sentiment': overall_sentiment,
                    'sentiment_distribution': {
                        'positive': len([s for s in sentiment_scores if s > 0.1]),
                        'neutral': len([s for s in sentiment_scores if -0.1 <= s <= 0.1]),
                        'negative': len([s for s in sentiment_scores if s < -0.1])
                    }
                },
                'intelligence_data': intelligence_data,
                'intelligence_insights': intelligence_insights,
                'data_sources': {
                    'market_data_sources': list(market_data.keys()),
                    'news_sources_count': len(self.news_sources),
                    'alphavantage_enabled': self.use_alphavantage,
                    'intelligence_enabled': bool(intelligence_data)
                }
            }
            
        except Exception as e:
            self.logger.error(f"ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                'timestamp': datetime.now().isoformat(),
                'error': str(e),
                'status': 'failed'
            }
    
    def generate_comprehensive_report(self) -> Dict[str, Any]:
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± (ë™ê¸° ë²„ì „)"""
        try:
            # ê¸°ì¡´ ë°ì´í„° ìˆ˜ì§‘ (ë™ê¸° ë°©ì‹)
            market_data = {}
            news_data = self.collect_news_data(max_articles=10)
            intelligence_data = self.collect_intelligence_data()
            
            # ì‹œìž¥ ìš”ì•½
            market_summary = {}
            
            # ê°ì • ë¶„ì„
            sentiment_scores = [news.sentiment_score for news in news_data if news.sentiment_score is not None]
            overall_sentiment = np.mean(sentiment_scores) if sentiment_scores else 0.0
            
            # Intelligence ì¸ì‚¬ì´íŠ¸
            intelligence_insights = {}
            if intelligence_data and 'data' in intelligence_data:
                intel_data = intelligence_data['data']
                
                # ì‹œìž¥ ìƒíƒœ ë¶„ì„
                if 'market_status' in intel_data:
                    open_markets = [m for m in intel_data['market_status'] if m.get('current_status') == 'open']
                    intelligence_insights['open_markets_count'] = len(open_markets)
                
                # ì£¼ìš” ë³€ë™ ì¢…ëª©
                if 'top_gainers_losers' in intel_data:
                    movers = intel_data['top_gainers_losers']
                    if 'top_gainers' in movers and movers['top_gainers']:
                        top_gainer = movers['top_gainers'][0]
                        intelligence_insights['top_gainer'] = {
                            'ticker': top_gainer.get('ticker'),
                            'change_percentage': top_gainer.get('change_percentage')
                        }
                    
                    if 'top_losers' in movers and movers['top_losers']:
                        top_loser = movers['top_losers'][0]
                        intelligence_insights['top_loser'] = {
                            'ticker': top_loser.get('ticker'),
                            'change_percentage': top_loser.get('change_percentage')
                        }
            
            return {
                'timestamp': datetime.now().isoformat(),
                'market_data': market_data,
                'market_summary': market_summary,
                'news_data': [
                    {
                        'title': news.title,
                        'source': news.source,
                        'sentiment_score': news.sentiment_score,
                        'published_date': news.published.isoformat() if news.published else None
                    }
                    for news in news_data
                ],
                'sentiment_analysis': {
                    'overall_sentiment': overall_sentiment,
                    'sentiment_distribution': {
                        'positive': len([s for s in sentiment_scores if s > 0.1]),
                        'neutral': len([s for s in sentiment_scores if -0.1 <= s <= 0.1]),
                        'negative': len([s for s in sentiment_scores if s < -0.1])
                    }
                },
                'intelligence_data': intelligence_data,
                'intelligence_insights': intelligence_insights,
                'data_sources': {
                    'market_data_sources': [],
                    'news_sources_count': len(self.news_sources),
                    'alphavantage_enabled': self.use_alphavantage,
                    'intelligence_enabled': bool(intelligence_data)
                }
            }
            
        except Exception as e:
            self.logger.error(f"ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                'timestamp': datetime.now().isoformat(),
                'error': str(e),
                'status': 'failed'
            }

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_enhanced_collector():
    collector = EnhancedGlobalDataCollector()
    
    print("ðŸ” Enhanced Global Data Collector Test")
    print("=" * 50)
    
    # 1. ì‹œìž¥ ë°ì´í„° í…ŒìŠ¤íŠ¸
    print("\nðŸ“Š Market Data Collection:")
    market_data = await collector.collect_all_market_data()
    
    for category, data_dict in market_data.items():
        print(f"\n{category}:")
        for symbol, data in data_dict.items():
            print(f"  {symbol}: {data.current_price:.2f} ({data.change_percent:+.2f}%)")
    
    # 2. ë‰´ìŠ¤ ë°ì´í„° í…ŒìŠ¤íŠ¸
    print("\nðŸ“° News Data Collection:")
    news_data = collector.collect_news_data(max_articles=5)
    for news in news_data:
        print(f"  ðŸ“„ {news.title[:60]}... (Sentiment: {news.sentiment_score:.2f})")
    
    # 3. Intelligence ë°ì´í„° í…ŒìŠ¤íŠ¸
    print("\nðŸ§  Intelligence Data Collection:")
    intelligence_data = collector.collect_intelligence_data()
    if intelligence_data and 'summary' in intelligence_data:
        summary = intelligence_data['summary']
        print(f"  ðŸ“Š Market Status: {summary['market_status_count']}ê°œ")
        print(f"  ðŸ“° News Articles: {summary['news_articles_count']}ê°œ")
        print(f"  ðŸ“ˆ Top Movers: {summary['top_movers_categories']}ê°œ ì¹´í…Œê³ ë¦¬")
        print(f"  ðŸ” Analytics: {summary['analytics_symbols_count']}ê°œ ì‹¬ë³¼")
    else:
        print("  âŒ Intelligence ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
    
    # 4. ì¢…í•© ë¦¬í¬íŠ¸ í…ŒìŠ¤íŠ¸ (ë¹„ë™ê¸° ë²„ì „)
    print("\nðŸ“‹ Comprehensive Report (Async):")
    report = await collector.generate_comprehensive_report_async()
    print(f"  Market Summary: {report.get('market_summary', {})}")
    print(f"  Sentiment: {report.get('sentiment_analysis', {}).get('overall_sentiment', 0):.2f}")
    
    if 'intelligence_insights' in report:
        insights = report['intelligence_insights']
        print(f"  Intelligence Insights:")
        if 'open_markets_count' in insights:
            print(f"    - ê°œìž¥ ì‹œìž¥: {insights['open_markets_count']}ê°œ")
        if 'top_gainer' in insights:
            gainer = insights['top_gainer']
            print(f"    - ìµœê³  ìƒìŠ¹: {gainer['ticker']} ({gainer['change_percentage']}%)")
        if 'top_loser' in insights:
            loser = insights['top_loser']
            print(f"    - ìµœê³  í•˜ë½: {loser['ticker']} ({loser['change_percentage']}%)")

if __name__ == "__main__":
    asyncio.run(test_enhanced_collector())
