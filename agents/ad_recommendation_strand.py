"""
ê´‘ê³  ì¶”ì²œ Strand Agent
ê¸°ì‚¬ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ê´€ë ¨ ê´‘ê³  3ê°œë¥¼ ì¶”ì²œ
"""

import random
from typing import Dict, List, Any, Optional
from datetime import datetime

from .strands_framework import BaseStrandAgent, StrandContext, StrandMessage, MessageType

class AdRecommendationStrand(BaseStrandAgent):
    """ê´‘ê³  ì¶”ì²œ Strand Agent"""
    
    def __init__(self):
        super().__init__(
            agent_id="ad_recommender",
            name="ê´‘ê³  ì¶”ì²œ ì—ì´ì „íŠ¸"
        )
        
        self.capabilities = [
            "contextual_ad_matching",
            "financial_product_recommendation",
            "content_based_targeting",
            "audience_segmentation",
            "ad_performance_optimization"
        ]
        
        # ê´‘ê³  ë°ì´í„°ë² ì´ìŠ¤
        self.ad_database = {
            'investment_platforms': [
                {
                    'id': 'inv_001',
                    'title': 'ìŠ¤ë§ˆíŠ¸ íˆ¬ì í”Œë«í¼',
                    'description': 'AI ê¸°ë°˜ í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ë¡œ ì•ˆì „í•˜ê³  ìˆ˜ìµì„± ë†’ì€ íˆ¬ìë¥¼ ì‹œì‘í•˜ì„¸ìš”.',
                    'cta': 'ë¬´ë£Œ íˆ¬ì ìƒë‹´ ë°›ê¸°',
                    'keywords': ['íˆ¬ì', 'í¬íŠ¸í´ë¦¬ì˜¤', 'ìˆ˜ìµ', 'ìì‚°ê´€ë¦¬'],
                    'target_events': ['price_change', 'volume_spike'],
                    'risk_level': 'medium'
                },
                {
                    'id': 'inv_002',
                    'title': 'ë¡œë³´ì–´ë“œë°”ì´ì € ì„œë¹„ìŠ¤',
                    'description': 'ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ìë™ íˆ¬ì ê´€ë¦¬ë¡œ ì‹œê°„ê³¼ ë…¸ë ¥ì„ ì ˆì•½í•˜ì„¸ìš”.',
                    'cta': '1ê°œì›” ë¬´ë£Œ ì²´í—˜',
                    'keywords': ['ìë™íˆ¬ì', 'ë¡œë³´ì–´ë“œë°”ì´ì €', 'ì „ë¬¸ê°€', 'ê´€ë¦¬'],
                    'target_events': ['high_volatility'],
                    'risk_level': 'low'
                }
            ],
            'trading_tools': [
                {
                    'id': 'tool_001',
                    'title': 'ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ë„êµ¬',
                    'description': 'ì „ë¬¸ íŠ¸ë ˆì´ë”ë“¤ì´ ì‚¬ìš©í•˜ëŠ” ê³ ê¸‰ ì°¨íŠ¸ì™€ ë¶„ì„ ë„êµ¬ë¥¼ ê²½í—˜í•˜ì„¸ìš”.',
                    'cta': 'í”„ë¦¬ë¯¸ì—„ ë„êµ¬ ì²´í—˜',
                    'keywords': ['íŠ¸ë ˆì´ë”©', 'ì°¨íŠ¸', 'ë¶„ì„', 'ì‹¤ì‹œê°„'],
                    'target_events': ['volume_spike', 'high_volatility'],
                    'risk_level': 'high'
                },
                {
                    'id': 'tool_002',
                    'title': 'ëª¨ë°”ì¼ íŠ¸ë ˆì´ë”© ì•±',
                    'description': 'ì–¸ì œ ì–´ë””ì„œë‚˜ ë¹ ë¥´ê³  ì•ˆì „í•œ ëª¨ë°”ì¼ ê±°ë˜ë¥¼ ì¦ê¸°ì„¸ìš”.',
                    'cta': 'ì•± ë‹¤ìš´ë¡œë“œ',
                    'keywords': ['ëª¨ë°”ì¼', 'ê±°ë˜', 'ì•±', 'í¸ë¦¬í•¨'],
                    'target_events': ['price_change'],
                    'risk_level': 'medium'
                }
            ],
            'education_services': [
                {
                    'id': 'edu_001',
                    'title': 'íˆ¬ì êµìœ¡ ì•„ì¹´ë°ë¯¸',
                    'description': 'ê¸°ì´ˆë¶€í„° ê³ ê¸‰ê¹Œì§€, ì²´ê³„ì ì¸ íˆ¬ì êµìœ¡ìœ¼ë¡œ ì „ë¬¸ê°€ê°€ ë˜ì„¸ìš”.',
                    'cta': 'ë¬´ë£Œ ê°•ì˜ ìˆ˜ê°•',
                    'keywords': ['êµìœ¡', 'í•™ìŠµ', 'ê¸°ì´ˆ', 'ì „ë¬¸ê°€'],
                    'target_events': ['price_change', 'volume_spike', 'high_volatility'],
                    'risk_level': 'low'
                },
                {
                    'id': 'edu_002',
                    'title': 'ê²½ì œ ë‰´ìŠ¤ êµ¬ë… ì„œë¹„ìŠ¤',
                    'description': 'ì‹¤ì‹œê°„ ê²½ì œ ë¶„ì„ê³¼ ì „ë¬¸ê°€ ì˜ê²¬ìœ¼ë¡œ ì‹œì¥ì„ ì•ì„œê°€ì„¸ìš”.',
                    'cta': 'í”„ë¦¬ë¯¸ì—„ êµ¬ë…',
                    'keywords': ['ë‰´ìŠ¤', 'ë¶„ì„', 'ì „ë¬¸ê°€', 'ì‹œì¥ì •ë³´'],
                    'target_events': ['price_change', 'volume_spike'],
                    'risk_level': 'low'
                }
            ],
            'financial_products': [
                {
                    'id': 'prod_001',
                    'title': 'ê³ ìˆ˜ìµ ì ê¸ˆ ìƒí’ˆ',
                    'description': 'ì•ˆì „í•˜ë©´ì„œë„ ë†’ì€ ìˆ˜ìµë¥ ì„ ì œê³µí•˜ëŠ” íŠ¹ë³„ ì ê¸ˆ ìƒí’ˆì…ë‹ˆë‹¤.',
                    'cta': 'ìƒí’ˆ ìƒì„¸ë³´ê¸°',
                    'keywords': ['ì ê¸ˆ', 'ì•ˆì „', 'ìˆ˜ìµë¥ ', 'ì €ì¶•'],
                    'target_events': ['high_volatility'],
                    'risk_level': 'low'
                },
                {
                    'id': 'prod_002',
                    'title': 'íˆ¬ìí˜• ë³´í—˜',
                    'description': 'ë³´ì¥ê³¼ íˆ¬ìë¥¼ ë™ì‹œì—! ì•ˆì •ì ì¸ ìˆ˜ìµê³¼ ë³´í—˜ í˜œíƒì„ ëˆ„ë¦¬ì„¸ìš”.',
                    'cta': 'ë¬´ë£Œ ì„¤ê³„ ìƒë‹´',
                    'keywords': ['ë³´í—˜', 'íˆ¬ì', 'ë³´ì¥', 'ì•ˆì •'],
                    'target_events': ['price_change'],
                    'risk_level': 'medium'
                }
            ]
        }
    
    def get_capabilities(self) -> List[str]:
        """ì—ì´ì „íŠ¸ ëŠ¥ë ¥ ë°˜í™˜"""
        return self.capabilities
    
    async def process(self, context: StrandContext, message: Optional[StrandMessage] = None) -> Dict[str, Any]:
        """ê´‘ê³  ì¶”ì²œ ì²˜ë¦¬"""
        
        # í•„ìš”í•œ ë°ì´í„° ìˆ˜ì§‘
        event_data = context.input_data.get('event')
        article = await self.get_shared_data(context, 'article')
        data_analysis = await self.get_shared_data(context, 'data_analysis')
        
        if not event_data or not article:
            raise Exception("ê´‘ê³  ì¶”ì²œì— í•„ìš”í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        self.logger.info("ğŸ“¢ ê´‘ê³  ì¶”ì²œ ì‹œì‘")
        
        try:
            # 1. ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
            context_analysis = await self._analyze_context(event_data, article, data_analysis)
            
            # 2. íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤ ë¶„ì„
            audience_profile = await self._analyze_audience(context_analysis)
            
            # 3. ê´‘ê³  ë§¤ì¹­
            matched_ads = await self._match_advertisements(context_analysis, audience_profile)
            
            # 4. ê´‘ê³  ë­í‚¹ ë° ì„ íƒ
            recommended_ads = await self._rank_and_select_ads(matched_ads, context_analysis)
            
            # 5. ê´‘ê³  ê°œì¸í™”
            personalized_ads = await self._personalize_ads(recommended_ads, context_analysis)
            
            result = {
                'recommended_ads': personalized_ads,
                'context_analysis': context_analysis,
                'audience_profile': audience_profile,
                'recommendation_timestamp': datetime.now().isoformat(),
                'total_ads': len(personalized_ads)
            }
            
            # ê³µìœ  ë©”ëª¨ë¦¬ì— ì €ì¥
            await self.set_shared_data(context, 'advertisements', result)
            
            self.logger.info(f"âœ… ê´‘ê³  ì¶”ì²œ ì™„ë£Œ: {len(personalized_ads)}ê°œ")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ê´‘ê³  ì¶”ì²œ ì‹¤íŒ¨: {e}")
            raise
    
    async def _analyze_context(self, event_data: Dict[str, Any], article: Dict[str, Any], data_analysis: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ ë¶„ì„"""
        
        symbol = event_data.get('symbol', 'Unknown')
        event_type = event_data.get('event_type', 'unknown')
        severity = event_data.get('severity', 'low')
        
        # ê¸°ì‚¬ ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        article_text = f"{article.get('title', '')} {article.get('body', '')} {article.get('conclusion', '')}"
        keywords = await self._extract_keywords(article_text)
        
        # ì‹œì¥ ìƒí™© ë¶„ì„
        market_condition = 'neutral'
        risk_sentiment = 'medium'
        
        if data_analysis:
            # ë³€ë™ì„± ê¸°ë°˜ ì‹œì¥ ìƒí™© íŒë‹¨
            stats = data_analysis.get('statistics', {})
            if stats.get('volatility_annualized'):
                volatility = stats['volatility_annualized']
                if volatility > 0.3:  # 30% ì´ìƒ
                    market_condition = 'volatile'
                    risk_sentiment = 'high'
                elif volatility < 0.15:  # 15% ë¯¸ë§Œ
                    market_condition = 'stable'
                    risk_sentiment = 'low'
            
            # ê¸°ìˆ ì  ì§€í‘œ ê¸°ë°˜ ì¶”ê°€ ë¶„ì„
            technical = data_analysis.get('technical_indicators', {})
            if technical.get('rsi'):
                rsi = technical['rsi']
                if rsi > 70:
                    market_condition = 'overbought'
                elif rsi < 30:
                    market_condition = 'oversold'
        
        return {
            'symbol': symbol,
            'event_type': event_type,
            'severity': severity,
            'keywords': keywords,
            'market_condition': market_condition,
            'risk_sentiment': risk_sentiment,
            'article_length': len(article.get('body', '').split()),
            'has_technical_analysis': bool(data_analysis and data_analysis.get('technical_indicators'))
        }
    
    async def _extract_keywords(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        
        # ê¸ˆìœµ ê´€ë ¨ í‚¤ì›Œë“œ ì‚¬ì „
        financial_keywords = {
            'íˆ¬ì', 'ê±°ë˜', 'ìˆ˜ìµ', 'ì†ì‹¤', 'ë¦¬ìŠ¤í¬', 'ìœ„í—˜', 'ì•ˆì „', 'ìˆ˜ìµë¥ ',
            'í¬íŠ¸í´ë¦¬ì˜¤', 'ìì‚°', 'ì£¼ì‹', 'ì±„ê¶Œ', 'í€ë“œ', 'ì ê¸ˆ', 'ì˜ˆê¸ˆ', 'ë³´í—˜',
            'ë¶„ì„', 'ì˜ˆì¸¡', 'ì „ë§', 'ì¶”ì²œ', 'ìƒìŠ¹', 'í•˜ë½', 'ë³€ë™ì„±', 'ì•ˆì •ì„±',
            'íŠ¸ë ˆì´ë”©', 'ë§¤ìˆ˜', 'ë§¤ë„', 'ì°¨íŠ¸', 'ì§€í‘œ', 'ì‹œì¥', 'ê²½ì œ', 'ê¸ˆìœµ'
        }
        
        # í…ìŠ¤íŠ¸ë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ê³  ë‹¨ì–´ ë¶„ë¦¬
        words = text.lower().split()
        
        # ê¸ˆìœµ í‚¤ì›Œë“œë§Œ ì¶”ì¶œ
        extracted_keywords = []
        for word in words:
            for keyword in financial_keywords:
                if keyword in word:
                    extracted_keywords.append(keyword)
        
        # ì¤‘ë³µ ì œê±° ë° ë¹ˆë„ìˆœ ì •ë ¬
        keyword_counts = {}
        for keyword in extracted_keywords:
            keyword_counts[keyword] = keyword_counts.get(keyword, 0) + 1
        
        # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ ë°˜í™˜
        sorted_keywords = sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True)
        return [keyword for keyword, count in sorted_keywords[:10]]
    
    async def _analyze_audience(self, context_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤ ë¶„ì„"""
        
        event_type = context_analysis.get('event_type', 'unknown')
        risk_sentiment = context_analysis.get('risk_sentiment', 'medium')
        market_condition = context_analysis.get('market_condition', 'neutral')
        
        # ì´ë²¤íŠ¸ ìœ í˜•ë³„ ì˜¤ë””ì–¸ìŠ¤ í”„ë¡œíŒŒì¼
        audience_profiles = {
            'price_change': {
                'investor_type': 'active_trader',
                'risk_tolerance': 'medium_to_high',
                'interests': ['trading_tools', 'market_analysis', 'investment_platforms'],
                'experience_level': 'intermediate'
            },
            'volume_spike': {
                'investor_type': 'momentum_trader',
                'risk_tolerance': 'high',
                'interests': ['trading_tools', 'real_time_data', 'technical_analysis'],
                'experience_level': 'advanced'
            },
            'high_volatility': {
                'investor_type': 'risk_averse',
                'risk_tolerance': 'low_to_medium',
                'interests': ['stable_products', 'education', 'risk_management'],
                'experience_level': 'beginner_to_intermediate'
            }
        }
        
        base_profile = audience_profiles.get(event_type, audience_profiles['price_change'])
        
        # ì‹œì¥ ìƒí™©ì— ë”°ë¥¸ ì¡°ì •
        if market_condition == 'volatile':
            base_profile['risk_tolerance'] = 'low'
            base_profile['interests'].append('education')
        elif market_condition == 'stable':
            base_profile['risk_tolerance'] = 'medium_to_high'
            base_profile['interests'].append('investment_platforms')
        
        return {
            **base_profile,
            'market_awareness': 'high' if context_analysis.get('has_technical_analysis') else 'medium',
            'engagement_level': 'high' if context_analysis.get('article_length', 0) > 100 else 'medium'
        }
    
    async def _match_advertisements(self, context_analysis: Dict[str, Any], audience_profile: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ê´‘ê³  ë§¤ì¹­"""
        
        event_type = context_analysis.get('event_type', 'unknown')
        keywords = context_analysis.get('keywords', [])
        risk_sentiment = context_analysis.get('risk_sentiment', 'medium')
        
        matched_ads = []
        
        # ëª¨ë“  ê´‘ê³  ì¹´í…Œê³ ë¦¬ ê²€í† 
        for category, ads in self.ad_database.items():
            for ad in ads:
                score = 0
                
                # ì´ë²¤íŠ¸ íƒ€ì… ë§¤ì¹­
                if event_type in ad.get('target_events', []):
                    score += 3
                
                # í‚¤ì›Œë“œ ë§¤ì¹­
                ad_keywords = ad.get('keywords', [])
                keyword_matches = len(set(keywords) & set(ad_keywords))
                score += keyword_matches * 2
                
                # ë¦¬ìŠ¤í¬ ë ˆë²¨ ë§¤ì¹­
                ad_risk = ad.get('risk_level', 'medium')
                audience_risk = audience_profile.get('risk_tolerance', 'medium')
                
                if self._risk_compatibility(ad_risk, audience_risk):
                    score += 2
                
                # ê´€ì‹¬ì‚¬ ë§¤ì¹­
                audience_interests = audience_profile.get('interests', [])
                if category.replace('_', ' ') in ' '.join(audience_interests):
                    score += 1
                
                if score > 0:
                    matched_ads.append({
                        **ad,
                        'category': category,
                        'match_score': score,
                        'match_reasons': self._get_match_reasons(ad, context_analysis, audience_profile)
                    })
        
        return matched_ads
    
    def _risk_compatibility(self, ad_risk: str, audience_risk: str) -> bool:
        """ë¦¬ìŠ¤í¬ í˜¸í™˜ì„± ê²€ì‚¬"""
        
        risk_levels = {'low': 1, 'medium': 2, 'high': 3}
        
        ad_level = risk_levels.get(ad_risk, 2)
        
        # ì˜¤ë””ì–¸ìŠ¤ ë¦¬ìŠ¤í¬ í—ˆìš©ë„ íŒŒì‹±
        if 'low' in audience_risk:
            audience_max = 1 if 'to' not in audience_risk else 2
        elif 'high' in audience_risk:
            audience_max = 3
        else:
            audience_max = 2
        
        return ad_level <= audience_max
    
    def _get_match_reasons(self, ad: Dict[str, Any], context_analysis: Dict[str, Any], audience_profile: Dict[str, Any]) -> List[str]:
        """ë§¤ì¹­ ì´ìœ  ìƒì„±"""
        
        reasons = []
        
        # ì´ë²¤íŠ¸ íƒ€ì… ë§¤ì¹­
        if context_analysis.get('event_type') in ad.get('target_events', []):
            reasons.append(f"{context_analysis.get('event_type')} ì´ë²¤íŠ¸ì— ì í•©")
        
        # í‚¤ì›Œë“œ ë§¤ì¹­
        keywords = context_analysis.get('keywords', [])
        ad_keywords = ad.get('keywords', [])
        matches = set(keywords) & set(ad_keywords)
        if matches:
            reasons.append(f"ê´€ë ¨ í‚¤ì›Œë“œ: {', '.join(list(matches)[:3])}")
        
        # ë¦¬ìŠ¤í¬ ë ˆë²¨
        if self._risk_compatibility(ad.get('risk_level', 'medium'), audience_profile.get('risk_tolerance', 'medium')):
            reasons.append("ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ ì í•©")
        
        return reasons
    
    async def _rank_and_select_ads(self, matched_ads: List[Dict[str, Any]], context_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ê´‘ê³  ë­í‚¹ ë° ì„ íƒ"""
        
        # ë§¤ì¹˜ ìŠ¤ì½”ì–´ë¡œ ì •ë ¬
        sorted_ads = sorted(matched_ads, key=lambda x: x.get('match_score', 0), reverse=True)
        
        # ë‹¤ì–‘ì„±ì„ ìœ„í•´ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìµœëŒ€ 1ê°œì”© ì„ íƒ
        selected_ads = []
        used_categories = set()
        
        for ad in sorted_ads:
            category = ad.get('category')
            if category not in used_categories and len(selected_ads) < 3:
                selected_ads.append(ad)
                used_categories.add(category)
        
        # 3ê°œê°€ ì•ˆ ë˜ë©´ ìŠ¤ì½”ì–´ ìˆœìœ¼ë¡œ ì¶”ê°€
        if len(selected_ads) < 3:
            for ad in sorted_ads:
                if ad not in selected_ads and len(selected_ads) < 3:
                    selected_ads.append(ad)
        
        # ì—¬ì „íˆ 3ê°œê°€ ì•ˆ ë˜ë©´ ëœë¤ìœ¼ë¡œ ì¶”ê°€
        if len(selected_ads) < 3:
            all_ads = []
            for category_ads in self.ad_database.values():
                all_ads.extend(category_ads)
            
            remaining_ads = [ad for ad in all_ads if ad not in selected_ads]
            while len(selected_ads) < 3 and remaining_ads:
                selected_ads.append(remaining_ads.pop(random.randint(0, len(remaining_ads) - 1)))
        
        return selected_ads[:3]  # ìµœëŒ€ 3ê°œ
    
    async def _personalize_ads(self, ads: List[Dict[str, Any]], context_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ê´‘ê³  ê°œì¸í™”"""
        
        personalized_ads = []
        symbol = context_analysis.get('symbol', 'Unknown')
        event_type = context_analysis.get('event_type', 'unknown')
        
        for i, ad in enumerate(ads):
            personalized_ad = {
                'id': ad.get('id', f'ad_{i+1}'),
                'title': ad.get('title', 'íˆ¬ì ìƒí’ˆ'),
                'description': ad.get('description', 'íˆ¬ì ê´€ë ¨ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.'),
                'cta': ad.get('cta', 'ìì„¸íˆ ë³´ê¸°'),
                'category': ad.get('category', 'general'),
                'match_score': ad.get('match_score', 0),
                'match_reasons': ad.get('match_reasons', []),
                'personalization': {
                    'symbol_context': symbol,
                    'event_context': event_type,
                    'relevance_score': ad.get('match_score', 0) / 10.0
                }
            }
            
            # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì„¤ëª… ê°œì¸í™”
            if symbol != 'Unknown' and event_type == 'volume_spike':
                personalized_ad['description'] += f" {symbol}ê³¼ ê°™ì€ í™œë°œí•œ ê±°ë˜ ìƒí™©ì—ì„œ ë”ìš± ìœ ìš©í•©ë‹ˆë‹¤."
            elif event_type == 'high_volatility':
                personalized_ad['description'] += " ë³€ë™ì„±ì´ ë†’ì€ ì‹œì¥ì—ì„œ ì•ˆì •ì ì¸ íˆ¬ìë¥¼ ë„ì™€ë“œë¦½ë‹ˆë‹¤."
            
            personalized_ads.append(personalized_ad)
        
        return personalized_ads
