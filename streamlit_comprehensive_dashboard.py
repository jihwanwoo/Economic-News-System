#!/usr/bin/env python3
"""
ì¢…í•© ê²½ì œ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ - ë©€í‹°í˜ì´ì§€ ë²„ì „
ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ë¥¼ ë§í¬ì™€ í•¨ê»˜ ìƒì„¸ í‘œì‹œ
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import sys
import os
from datetime import datetime, timedelta
import json
import time

# ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data_monitoring.enhanced_data_collector import EnhancedGlobalDataCollector

# í˜ì´ì§€ ëª¨ë“ˆë“¤ import
from streamlit_fred_page import show_fred_page
from streamlit_news_page import show_news_page
from streamlit_reddit_page import show_social_media_page
from streamlit_asian_markets_page import show_asian_markets_page
from streamlit_network_analysis_page import show_network_analysis_page
from streamlit_enhanced_network_page import create_enhanced_network_page
from streamlit_real_network_page import create_real_network_page
from streamlit_stock_monitor_page import show_stock_monitor_page
from streamlit_ai_article_generator import show_ai_article_generator, generate_article_fallback
from data_monitoring.integrated_event_system import IntegratedEventSystem

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ§  ì¢…í•© ê²½ì œ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ìºì‹œëœ ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜
def collect_all_comprehensive_data_with_progress():
    """ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ ëª¨ë“  ë°ì´í„° ì¢…í•© ìˆ˜ì§‘"""
    
    # ì§„í–‰ë¥  í‘œì‹œ ì»¨í…Œì´ë„ˆ
    st.subheader("ğŸ“Š ì¢…í•© ë°ì´í„° ìˆ˜ì§‘ ì§„í–‰ ìƒí™©")
    
    # ì§„í–‰ë¥  ë°”
    progress_bar = st.progress(0)
    
    # ìƒíƒœ í…ìŠ¤íŠ¸
    status_text = st.empty()
    
    # ìˆ˜ì§‘ í†µê³„
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        intelligence_status = st.empty()
    with col2:
        fred_status = st.empty()
    with col3:
        news_status = st.empty()
    with col4:
        reddit_status = st.empty()
    
    # ë¡œê·¸ ì»¨í…Œì´ë„ˆ
    st.markdown("#### ğŸ“ ì‹¤ì‹œê°„ ë¡œê·¸")
    log_container = st.empty()
    
    # ë¡œê·¸ ì €ì¥
    logs = []
    start_time = time.time()
    
    def add_log(message, level="INFO"):
        timestamp = datetime.now().strftime("%H:%M:%S")
        emoji = {"INFO": "â„¹ï¸", "SUCCESS": "âœ…", "ERROR": "âŒ", "WARNING": "âš ï¸"}.get(level, "ğŸ“")
        log_entry = f"{emoji} [{timestamp}] {message}"
        logs.append(log_entry)
        
        # ìµœê·¼ 15ê°œ ë¡œê·¸ë§Œ í‘œì‹œ
        recent_logs = logs[-15:]
        log_container.text("\n".join(recent_logs))
    
    def update_progress(current, total, message=""):
        # ì•ˆì „í•œ ì§„í–‰ë¥  ê³„ì‚°
        if total <= 0:
            progress = 0.0
        else:
            progress = current / total
        
        # ì§„í–‰ë¥ ì„ 0.0 ~ 1.0 ë²”ìœ„ë¡œ ì œí•œ
        progress = max(0.0, min(progress, 1.0))
        
        try:
            progress_bar.progress(progress)
        except Exception as e:
            # ì§„í–‰ë¥  ë°” ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ ì‹œ ë¡œê·¸ë§Œ ê¸°ë¡
            print(f"Progress bar update failed: {e}")
        
        elapsed = time.time() - start_time
        status_msg = f"ì§„í–‰ë¥ : {current}/{total} ({progress*100:.1f}%) - ê²½ê³¼ì‹œê°„: {elapsed:.1f}ì´ˆ"
        if message:
            status_msg += f"\nğŸ”„ í˜„ì¬ ì‘ì—…: {message}"
        
        try:
            status_text.text(status_msg)
        except Exception as e:
            print(f"Status text update failed: {e}")
    
    try:
        collector = EnhancedGlobalDataCollector()
        
        # ì „ì²´ ìˆ˜ì§‘ ì‹œì‘
        add_log("ğŸš€ ì¢…í•© ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤", "SUCCESS")
        update_progress(0, 100, "ì´ˆê¸°í™” ì¤‘...")
        time.sleep(0.5)
        
        # 1. Intelligence ë°ì´í„° ìˆ˜ì§‘
        add_log("ğŸ§  Alpha Vantage Intelligence ë°ì´í„° ìˆ˜ì§‘ ì¤‘...", "INFO")
        intelligence_status.metric("Intelligence", "ìˆ˜ì§‘ ì¤‘...", "ğŸ”„")
        update_progress(10, 100, "Alpha Vantage Intelligence API í˜¸ì¶œ")
        
        intelligence_data = collector.collect_intelligence_data()
        
        if intelligence_data:
            intelligence_status.metric("Intelligence", "ì™„ë£Œ", "âœ…")
            add_log("âœ… Alpha Vantage Intelligence ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ", "SUCCESS")
        else:
            intelligence_status.metric("Intelligence", "ì‹¤íŒ¨", "âŒ")
            add_log("âŒ Alpha Vantage Intelligence ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨", "ERROR")
        
        update_progress(30, 100, "Intelligence ë°ì´í„° ì™„ë£Œ")
        time.sleep(0.5)
        
        # 2. FRED ë°ì´í„° ìˆ˜ì§‘
        add_log("ğŸ“Š FRED ê²½ì œ ì§€í‘œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...", "INFO")
        fred_status.metric("FRED", "ìˆ˜ì§‘ ì¤‘...", "ğŸ”„")
        update_progress(40, 100, "FRED API í˜¸ì¶œ")
        
        fred_data = collector.collect_fred_data()
        
        if fred_data:
            fred_status.metric("FRED", "ì™„ë£Œ", "âœ…")
            add_log("âœ… FRED ê²½ì œ ì§€í‘œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ", "SUCCESS")
        else:
            fred_status.metric("FRED", "ì‹¤íŒ¨", "âŒ")
            add_log("âŒ FRED ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨", "ERROR")
        
        update_progress(60, 100, "FRED ë°ì´í„° ì™„ë£Œ")
        time.sleep(0.5)
        
        # 3. ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
        add_log("ğŸ“° ê°•í™”ëœ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...", "INFO")
        news_status.metric("ë‰´ìŠ¤", "ìˆ˜ì§‘ ì¤‘...", "ğŸ”„")
        update_progress(70, 100, "ë‰´ìŠ¤ API í˜¸ì¶œ")
        
        news_data = collector.collect_enhanced_news_data()
        
        if news_data:
            news_status.metric("ë‰´ìŠ¤", "ì™„ë£Œ", "âœ…")
            add_log("âœ… ê°•í™”ëœ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ", "SUCCESS")
        else:
            news_status.metric("ë‰´ìŠ¤", "ì‹¤íŒ¨", "âŒ")
            add_log("âŒ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨", "ERROR")
        
        update_progress(90, 100, "ë‰´ìŠ¤ ë°ì´í„° ì™„ë£Œ")
        time.sleep(0.5)
        
        # 4. Reddit ë°ì´í„° (ì¶”ê°€)
        add_log("ğŸ“± Reddit ì†Œì…œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...", "INFO")
        reddit_status.metric("Reddit", "ìˆ˜ì§‘ ì¤‘...", "ğŸ”„")
        update_progress(95, 100, "Reddit API í˜¸ì¶œ")
        
        # Reddit ë°ì´í„°ëŠ” ë‰´ìŠ¤ ë°ì´í„°ì— í¬í•¨ë˜ì–´ ìˆìŒ
        reddit_status.metric("Reddit", "ì™„ë£Œ", "âœ…")
        add_log("âœ… Reddit ì†Œì…œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ", "SUCCESS")
        
        # ì™„ë£Œ
        progress_bar.progress(1.0)
        update_progress(100, 100, "ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
        status_text.success("âœ… ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        add_log("ğŸ‰ ì¢…í•© ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ì™„ë£Œ!", "SUCCESS")
        
        return {
            'intelligence': intelligence_data,
            'fred': fred_data,
            'news': news_data,
            'timestamp': datetime.now().isoformat()
        }, None
        
    except Exception as e:
        add_log(f"ğŸ’¥ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "ERROR")
        status_text.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None, str(e)

@st.cache_data(ttl=300)  # 5ë¶„ ìºì‹œ
def collect_all_comprehensive_data():
    """ìºì‹œëœ ë°ì´í„° ìˆ˜ì§‘ (ë°±ê·¸ë¼ìš´ë“œìš©)"""
    try:
        collector = EnhancedGlobalDataCollector()
        
        # ëª¨ë“  ë°ì´í„° ì†ŒìŠ¤ ìˆ˜ì§‘
        intelligence_data = collector.collect_intelligence_data()
        fred_data = collector.collect_fred_data()
        news_data = collector.collect_enhanced_news_data()
        
        return {
            'intelligence': intelligence_data,
            'fred': fred_data,
            'news': news_data,
            'timestamp': datetime.now().isoformat()
        }, None
        
    except Exception as e:
        return None, str(e)

def main():
    """ë©”ì¸ ëŒ€ì‹œë³´ë“œ"""
    
    # í—¤ë”
    st.title("ğŸ§  ì¢…í•© ê²½ì œ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ")
    st.markdown("**ì‹¤ì‹œê°„ ê²½ì œ ë°ì´í„° í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ**")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜
    with st.sidebar:
        st.header("ğŸ“Š í˜ì´ì§€ ë„¤ë¹„ê²Œì´ì…˜")
        
        page = st.selectbox(
            "í˜ì´ì§€ ì„ íƒ",
            [
                "ğŸ  ëŒ€ì‹œë³´ë“œ í™ˆ",
                "ğŸ¤– AI ê¸°ì‚¬ ìƒì„±",
                "ğŸ“Š ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ê¸°ë°˜ AI ê¸°ì‚¬",
                "ğŸ“ˆ ê°œë³„ ì£¼ì‹ ëª¨ë‹ˆí„°ë§",
                "ğŸ§  Alpha Vantage Intelligence",
                "ğŸ“Š FRED ê²½ì œ ì§€í‘œ",
                "ğŸŒ ì•„ì‹œì•„ ì‹œì¥ ë¶„ì„",
                "ğŸ“° ë‰´ìŠ¤ ë¶„ì„",
                "ğŸ“± ì†Œì…œë¯¸ë””ì–´ (Reddit)",
                "ğŸ•¸ï¸ ì†Œì…œ ë„¤íŠ¸ì›Œí¬ ë¶„ì„",
                "ğŸš€ ê°œì„ ëœ ë„¤íŠ¸ì›Œí¬ ë¶„ì„",
                "ğŸ“± ì‹¤ì œ Reddit ë„¤íŠ¸ì›Œí¬ ë¶„ì„",
                "ğŸ“ˆ í†µí•© ë¶„ì„",
                "ğŸ” ìƒì„¸ ë°ì´í„°"
            ]
        )
        
        st.markdown("---")
        
        # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
        if st.button("ğŸ”„ ì „ì²´ ë°ì´í„° ìƒˆë¡œê³ ì¹¨", type="primary", key="sidebar_refresh"):
            st.cache_data.clear()
            st.rerun()
        
        # ì—…ë°ì´íŠ¸ ì •ë³´
        st.subheader("â° ì‹œìŠ¤í…œ ì •ë³´")
        st.write(f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {datetime.now().strftime('%H:%M:%S')}")
        st.write("ìºì‹œ ì‹œê°„: 5ë¶„")
        st.write("ë°ì´í„° ì†ŒìŠ¤: 4ê°œ")
    
    # ë°ì´í„° ë¡œë”© - ì„¸ì…˜ ìƒíƒœ í™•ì¸
    if 'comprehensive_data' not in st.session_state or st.button("ğŸ”„ ìƒˆë¡œìš´ ë°ì´í„° ìˆ˜ì§‘", type="primary", key="comprehensive_data_collect"):
        # ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ ë°ì´í„° ìˆ˜ì§‘
        with st.container():
            all_data, error = collect_all_comprehensive_data_with_progress()
        
        if error:
            st.error(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {error}")
            return
        
        if not all_data:
            st.warning("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        st.session_state.comprehensive_data = all_data
        st.session_state.last_comprehensive_update = datetime.now()
        
        # ì„±ê³µ ë©”ì‹œì§€
        st.success("âœ… ì¢…í•© ë°ì´í„° ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        time.sleep(2)
        st.rerun()
    
    # ìºì‹œëœ ë°ì´í„° ì‚¬ìš©
    if 'comprehensive_data' in st.session_state:
        all_data = st.session_state.comprehensive_data
        last_update = st.session_state.get('last_comprehensive_update', datetime.now())
        
        # ì—…ë°ì´íŠ¸ ì‹œê°„ í‘œì‹œ
        st.info(f"ğŸ“… ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {last_update.strftime('%Y-%m-%d %H:%M:%S')}")
    else:
        st.info("ğŸ“Š 'ìƒˆë¡œìš´ ë°ì´í„° ìˆ˜ì§‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì„¸ìš”.")
        return
    
    # í˜ì´ì§€ë³„ ë¼ìš°íŒ…
    if page == "ğŸ  ëŒ€ì‹œë³´ë“œ í™ˆ":
        show_dashboard_home(all_data)
    elif page == "ğŸ¤– AI ê¸°ì‚¬ ìƒì„±":
        show_ai_article_generator()
    elif page == "ğŸ“Š ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ê¸°ë°˜ AI ê¸°ì‚¬":
        show_realtime_event_ai_articles(all_data)
    elif page == "ğŸ“ˆ ê°œë³„ ì£¼ì‹ ëª¨ë‹ˆí„°ë§":
        show_stock_monitor_page()
    elif page == "ğŸ§  Alpha Vantage Intelligence":
        show_alpha_vantage_page(all_data['intelligence'])
    elif page == "ğŸ“Š FRED ê²½ì œ ì§€í‘œ":
        show_fred_page(all_data['fred'])
    elif page == "ğŸŒ ì•„ì‹œì•„ ì‹œì¥ ë¶„ì„":
        show_asian_markets_page()
    elif page == "ğŸ“° ë‰´ìŠ¤ ë¶„ì„":
        show_news_page(all_data['news'])
    elif page == "ğŸ“± ì†Œì…œë¯¸ë””ì–´ (Reddit)":
        show_social_media_page(all_data['news'])
    elif page == "ğŸ•¸ï¸ ì†Œì…œ ë„¤íŠ¸ì›Œí¬ ë¶„ì„":
        show_network_analysis_page(all_data['news'])
    elif page == "ğŸš€ ê°œì„ ëœ ë„¤íŠ¸ì›Œí¬ ë¶„ì„":
        create_enhanced_network_page()
    elif page == "ğŸ“± ì‹¤ì œ Reddit ë„¤íŠ¸ì›Œí¬ ë¶„ì„":
        create_real_network_page()
    elif page == "ğŸ“ˆ í†µí•© ë¶„ì„":
        show_integrated_analysis(all_data)
    elif page == "ğŸ” ìƒì„¸ ë°ì´í„°":
        show_detailed_data(all_data)

def show_realtime_event_ai_articles(all_data):
    """ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ê¸°ë°˜ AI ê¸°ì‚¬ ìƒì„± í˜ì´ì§€"""
    st.header("ğŸ“Š ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ê¸°ë°˜ AI ê¸°ì‚¬ ìƒì„±")
    st.markdown("**ë°ì´í„° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì—ì„œ ê°ì§€ëœ ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI ê¸°ì‚¬ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.**")
    st.markdown("---")
    
    # ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ê°ì§€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    try:
        event_system = IntegratedEventSystem()
        
        # ì´ë²¤íŠ¸ ê°ì§€ ì‹¤í–‰
        with st.spinner("ğŸ” ì‹¤ì‹œê°„ ì‹œì¥ ì´ë²¤íŠ¸ ê°ì§€ ì¤‘..."):
            import asyncio
            
            # ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
            try:
                loop = asyncio.get_event_loop()
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            analysis_result = loop.run_until_complete(event_system.run_comprehensive_analysis())
        
        if not analysis_result or 'events' not in analysis_result:
            st.warning("âš ï¸ í˜„ì¬ ê°ì§€ëœ ì¤‘ìš”í•œ ì‹œì¥ ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ ì‹œì¥ì´ ì•ˆì •ì ì´ê±°ë‚˜ ê±°ë˜ ì‹œê°„ ì™¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return
        
        events = analysis_result['events']
        summary = analysis_result.get('summary', {})
        
        if not events:
            st.warning("âš ï¸ í˜„ì¬ ê°ì§€ëœ ì¤‘ìš”í•œ ì‹œì¥ ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ ì‹œì¥ì´ ì•ˆì •ì ì´ê±°ë‚˜ ê±°ë˜ ì‹œê°„ ì™¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return
        
        # ê°ì§€ëœ ì´ë²¤íŠ¸ í‘œì‹œ
        st.subheader(f"ğŸš¨ ê°ì§€ëœ ì´ë²¤íŠ¸ ({len(events)}ê°œ)")
        
        # ë¶„ì„ ìš”ì•½ í‘œì‹œ
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì´ ì´ë²¤íŠ¸", f"{summary.get('total_events', 0)}ê°œ")
        
        with col2:
            st.metric("ì‹œì¥ ê°ì •", summary.get('market_sentiment', 'neutral').upper())
        
        with col3:
            st.metric("ìœ„í—˜ ìˆ˜ì¤€", summary.get('risk_level', 'low').upper())
        
        with col4:
            st.metric("ì‹¬ê°ë„", summary.get('severity_assessment', 'low').upper())
        
        # ì´ë²¤íŠ¸ ìš”ì•½ í…Œì´ë¸”
        event_data = []
        for event in events:
            event_data.append({
                'ì‹¬ë³¼': event.get('symbol', 'N/A'),
                'ì´ë²¤íŠ¸ ìœ í˜•': event.get('event_type', 'N/A'),
                'ì„¤ëª…': event.get('description', 'N/A')[:50] + '...',
                'ì‹¬ê°ë„': f"{event.get('severity', 0):.2f}",
                'ê°ì •': event.get('sentiment', 'neutral')
            })
        
        if event_data:
            df_events = pd.DataFrame(event_data)
            st.dataframe(df_events, use_container_width=True)
        
        # ì£¼ìš” ì¸ì‚¬ì´íŠ¸ í‘œì‹œ
        insights = summary.get('key_insights', [])
        if insights:
            st.subheader("ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸")
            for i, insight in enumerate(insights, 1):
                st.write(f"{i}. {insight}")
        
        # AI ê¸°ì‚¬ ìƒì„± ë²„íŠ¼
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col2:
            if st.button("ğŸ¤– ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ê¸°ë°˜ AI ê¸°ì‚¬ ìƒì„±", type="primary", key="realtime_ai_article"):
                # ì´ë²¤íŠ¸ë¥¼ AI ê¸°ì‚¬ ìƒì„±ì— ì í•©í•œ í˜•íƒœë¡œ ë³€í™˜
                formatted_events = []
                for event in events:
                    formatted_events.append({
                        'symbol': event.get('symbol', 'MARKET'),
                        'description': event.get('description', 'ì‹œì¥ ì´ë²¤íŠ¸'),
                        'sentiment': event.get('sentiment', 'neutral'),
                        'severity': event.get('severity', 0.5),
                        'event_type': event.get('event_type', 'market_event')
                    })
                
                generate_realtime_ai_article(formatted_events)
    
    except Exception as e:
        st.error(f"âŒ ì´ë²¤íŠ¸ ê°ì§€ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {str(e)}")
        st.info("ğŸ’¡ ëŒ€ì‹  ìˆ˜ë™ìœ¼ë¡œ AI ê¸°ì‚¬ë¥¼ ìƒì„±í•˜ì‹œë ¤ë©´ 'ğŸ¤– AI ê¸°ì‚¬ ìƒì„±' í˜ì´ì§€ë¥¼ ì´ìš©í•˜ì„¸ìš”.")
        
        # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
        with st.expander("ğŸ” ë””ë²„ê¹… ì •ë³´"):
            st.write(f"ì˜¤ë¥˜ ìƒì„¸: {str(e)}")
            st.write("ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

def generate_realtime_ai_article(events):
    """ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI ê¸°ì‚¬ ìƒì„±"""
    
    # ì§„í–‰ë¥  í‘œì‹œ
    progress_container = st.container()
    
    with progress_container:
        st.subheader("ğŸ¤– AI ê¸°ì‚¬ ìƒì„± ì§„í–‰ ìƒí™©")
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # ê°€ì§œ íŠ¸ë˜ì»¤ í´ë˜ìŠ¤ (ì§„í–‰ë¥  í‘œì‹œìš©)
        class StreamlitProgressTracker:
            def __init__(self, progress_bar, status_text):
                self.progress_bar = progress_bar
                self.status_text = status_text
                self.current_step = 0
                self.total_steps = 6
            
            def update_step(self, step, description):
                self.current_step = step
                progress = step / self.total_steps
                self.progress_bar.progress(progress)
                self.status_text.text(f"ë‹¨ê³„ {step}/{self.total_steps}: {description}")
            
            def add_log(self, message, level="INFO"):
                if level == "SUCCESS":
                    st.success(f"âœ… {message}")
                elif level == "ERROR":
                    st.error(f"âŒ {message}")
                else:
                    st.info(f"â„¹ï¸ {message}")
        
        # íŠ¸ë˜ì»¤ ì´ˆê¸°í™”
        tracker = StreamlitProgressTracker(progress_bar, status_text)
        
        # AI ê¸°ì‚¬ ìƒì„± ì‹¤í–‰
        try:
            result = generate_article_fallback(events, tracker)
            
            if result:
                # ì§„í–‰ë¥  ì™„ë£Œ
                progress_bar.progress(1.0)
                status_text.text("âœ… AI ê¸°ì‚¬ ìƒì„± ì™„ë£Œ!")
                
                # ê²°ê³¼ í‘œì‹œ
                st.success("ğŸ‰ ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ê¸°ë°˜ AI ê¸°ì‚¬ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                
                # ê¸°ì‚¬ ë‚´ìš© í‘œì‹œ
                display_generated_article(result)
                
            else:
                st.error("âŒ AI ê¸°ì‚¬ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            st.error(f"ğŸ’¥ AI ê¸°ì‚¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def display_generated_article(result):
    """ìƒì„±ëœ ê¸°ì‚¬ í‘œì‹œ"""
    
    # ê¸°ì‚¬ ì •ë³´
    article = result.get('article', {})
    analysis = result.get('analysis', {})
    review = result.get('review', {})
    images = result.get('images', {})
    
    # ê¸°ì‚¬ ì œëª© ë° ë©”íƒ€ ì •ë³´
    st.markdown("---")
    st.header("ğŸ“° ìƒì„±ëœ AI ê¸°ì‚¬")
    
    # ë©”íƒ€ ì •ë³´
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ê°ì§€ëœ ì´ë²¤íŠ¸", f"{analysis.get('total_events', 0)}ê°œ")
    
    with col2:
        st.metric("ì‹œì¥ ê°ì •", analysis.get('market_sentiment', 'neutral').upper())
    
    with col3:
        st.metric("í’ˆì§ˆ ì ìˆ˜", f"{review.get('quality_score', 0)}/10")
    
    with col4:
        st.metric("ê¸°ì‚¬ ê¸¸ì´", f"{len(article.get('content', ''))}ì")
    
    # ê¸°ì‚¬ ì œëª©
    st.subheader(f"ğŸ“° {article.get('title', 'ì œëª© ì—†ìŒ')}")
    
    # ê¸°ì‚¬ ë‚´ìš©
    st.markdown("### ğŸ“ ê¸°ì‚¬ ë‚´ìš©")
    content = article.get('content', 'ë‚´ìš© ì—†ìŒ')
    st.markdown(content)
    
    # AI ì¼ëŸ¬ìŠ¤íŠ¸ë ˆì´ì…˜ í‘œì‹œ
    ai_illustration = images.get('ai_illustration')
    if ai_illustration:
        st.markdown("### ğŸ¨ AI ìƒì„± ì¼ëŸ¬ìŠ¤íŠ¸ë ˆì´ì…˜")
        
        # ì´ë¯¸ì§€ íŒŒì¼ í‘œì‹œ
        image_file = ai_illustration.get('image_file')
        if image_file and image_file.get('image_path'):
            image_path = image_file['image_path']
            if os.path.exists(image_path):
                from PIL import Image
                try:
                    img = Image.open(image_path)
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.image(img, caption="AI ìƒì„± ì¼ëŸ¬ìŠ¤íŠ¸ë ˆì´ì…˜")
                    with col2:
                        st.image(img, caption="AI ìƒì„± ì¼ëŸ¬ìŠ¤íŠ¸ë ˆì´ì…˜ (ì „ì²´ ë„ˆë¹„)", use_container_width=True)
                    
                    # ì´ë¯¸ì§€ ì •ë³´
                    st.info(f"""
                    **ì´ë¯¸ì§€ ì •ë³´:**
                    - ëª¨ë¸: {image_file.get('model_used', 'Unknown')}
                    - íŒŒì¼ í¬ê¸°: {os.path.getsize(image_path)} bytes
                    - ìƒì„± ì‹œê°„: {image_file.get('generated_at', 'Unknown')}
                    """)
                    
                except Exception as e:
                    st.error(f"ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜: {e}")
        
        # í…ìŠ¤íŠ¸ ì„¤ëª…
        description = ai_illustration.get('description', '')
        if description:
            st.markdown("**ğŸ“ ì¼ëŸ¬ìŠ¤íŠ¸ë ˆì´ì…˜ ì„¤ëª…:**")
            st.text_area("AI ìƒì„± ì„¤ëª…", value=description, height=150, disabled=True)
    
    # ì›Œë“œí´ë¼ìš°ë“œ í‘œì‹œ
    wordcloud = images.get('wordcloud')
    if wordcloud and wordcloud.get('generated') and wordcloud.get('image'):
        st.markdown("### ğŸ”¤ í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ")
        try:
            st.image(wordcloud['image'], caption="ê¸°ì‚¬ í•µì‹¬ í‚¤ì›Œë“œ", use_container_width=True)
        except Exception as e:
            st.write(f"ì›Œë“œí´ë¼ìš°ë“œ í‘œì‹œ ì˜¤ë¥˜: {e}")
            keywords = wordcloud.get('keywords', [])
            if keywords:
                st.write("**ì£¼ìš” í‚¤ì›Œë“œ:**", ", ".join(list(set(keywords))[:15]))
    
    # ê²€ìˆ˜ ê²°ê³¼
    if review:
        st.markdown("### ğŸ” AI ê²€ìˆ˜ ê²°ê³¼")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("í’ˆì§ˆ ì ìˆ˜", f"{review.get('quality_score', 0)}/10")
        
        with col2:
            suggestions = review.get('suggestions', [])
            if suggestions:
                st.write("**ê°œì„  ì œì•ˆ:**")
                for i, suggestion in enumerate(suggestions[:3], 1):
                    st.write(f"{i}. {suggestion}")
    
    # ë‹¤ìš´ë¡œë“œ ì˜µì…˜
    st.markdown("---")
    st.subheader("ğŸ’¾ ë‹¤ìš´ë¡œë“œ ì˜µì…˜")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # ê¸°ì‚¬ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ
        content_text = f"# {article.get('title', 'ì œëª© ì—†ìŒ')}\n\n{article.get('content', 'ë‚´ìš© ì—†ìŒ')}"
        st.download_button(
            label="ğŸ“„ ê¸°ì‚¬ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ",
            data=content_text,
            file_name=f"realtime_ai_article_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
            mime="text/markdown"
        )
    
    with col2:
        # ë¶„ì„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        analysis_data = json.dumps(analysis, indent=2, ensure_ascii=False)
        st.download_button(
            label="ğŸ“Š ë¶„ì„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ",
            data=analysis_data,
            file_name=f"realtime_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
    
    with col3:
        # ì „ì²´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
        full_data = json.dumps(result, indent=2, ensure_ascii=False, default=str)
        st.download_button(
            label="ğŸ“‹ ì „ì²´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
            data=full_data,
            file_name=f"realtime_full_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
    """í†µí•© ë¶„ì„ í˜ì´ì§€"""
    st.header("ğŸ“ˆ í†µí•© ë¶„ì„")
    
    intelligence_data = all_data.get('intelligence', {})
    fred_data = all_data.get('fred', {})
    news_data = all_data.get('news', {})
    
    # ì „ì²´ ì‹œì¥ ê°ì • ì¢…í•©
    st.subheader("ğŸ­ ì¢…í•© ì‹œì¥ ê°ì •")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Alpha Vantage ì‹œì¥ ìƒíƒœ
        intel_summary = intelligence_data.get('summary', {})
        open_markets = intel_summary.get('open_markets_count', 0)
        total_markets = intel_summary.get('market_status_count', 0)
        
        if total_markets > 0:
            market_ratio = open_markets / total_markets
            st.metric(
                "ê¸€ë¡œë²Œ ì‹œì¥ í™œì„±ë„",
                f"{market_ratio:.1%}",
                f"{open_markets}/{total_markets} ê°œì¥"
            )
    
    with col2:
        # FRED ê²½ì œ ì§€í‘œ íŠ¸ë Œë“œ
        fred_summary = fred_data.get('summary', {})
        highlights = fred_summary.get('key_highlights', {})
        
        if 'growth' in highlights:
            growth_trend = highlights['growth'].get('trend', 'ë³´í•©')
            gdp_rate = highlights['growth'].get('gdp_growth_rate', 0)
            st.metric(
                "ê²½ì œ ì„±ì¥ ë™í–¥",
                growth_trend,
                f"GDP: {gdp_rate}%"
            )
    
    with col3:
        # ë‰´ìŠ¤ ê°ì • ë¶„ì„
        news_summary = news_data.get('summary', {})
        overall_sentiment = news_summary.get('overall_market_sentiment', {})
        
        if overall_sentiment:
            sentiment_label = overall_sentiment.get('label', 'ì¤‘ë¦½')
            sentiment_score = overall_sentiment.get('score', 0)
            st.metric(
                "ë‰´ìŠ¤ ì‹œì¥ ê°ì •",
                sentiment_label,
                f"ì ìˆ˜: {sentiment_score:+.3f}"
            )
    
    st.markdown("---")
    
    # ë°ì´í„° ì†ŒìŠ¤ë³„ ìƒíƒœ
    st.subheader("ğŸ“Š ë°ì´í„° ì†ŒìŠ¤ ìƒíƒœ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        intel_status = intelligence_data.get('status', 'failed')
        status_color = "ğŸŸ¢" if intel_status == 'success' else "ğŸ”´"
        st.write(f"{status_color} **Alpha Vantage**")
        st.caption(f"ìƒíƒœ: {intel_status}")
        if intel_status == 'success':
            st.caption(f"ì‹œì¥: {intel_summary.get('market_status_count', 0)}ê°œ")
    
    with col2:
        fred_status = fred_data.get('status', 'failed')
        status_color = "ğŸŸ¢" if fred_status == 'success' else "ğŸ”´"
        st.write(f"{status_color} **FRED**")
        st.caption(f"ìƒíƒœ: {fred_status}")
        if fred_status == 'success':
            st.caption(f"ì§€í‘œ: {fred_summary.get('collected_indicators', 0)}ê°œ")
    
    with col3:
        news_status = news_data.get('status', 'failed')
        status_color = "ğŸŸ¢" if news_status == 'success' else "ğŸ”´"
        st.write(f"{status_color} **ë‰´ìŠ¤**")
        st.caption(f"ìƒíƒœ: {news_status}")
        if news_status == 'success':
            st.caption(f"ê¸°ì‚¬: {news_summary.get('total_articles', 0)}ê°œ")
    
    with col4:
        social_mentions = news_summary.get('social_mentions', {})
        reddit_posts = social_mentions.get('reddit_posts', 0)
        status_color = "ğŸŸ¢" if reddit_posts > 0 else "ğŸ”´"
        st.write(f"{status_color} **Reddit**")
        st.caption("ìƒíƒœ: ì‹¤ì‹œê°„")
        st.caption(f"í¬ìŠ¤íŠ¸: {reddit_posts}ê°œ")
    
    # ì¢…í•© ì°¨íŠ¸
    st.subheader("ğŸ“ˆ ì¢…í•© íŠ¸ë Œë“œ ë¶„ì„")
    
    # ì‹œì¥ ì§€í‘œ ì¢…í•© ì°¨íŠ¸ (ì˜ˆì‹œ)
    if fred_data.get('status') == 'success':
        fred_info = fred_data.get('data', {})
        indicators = fred_info.get('indicators', {})
        
        # ì£¼ìš” ì§€í‘œë“¤ì˜ ë³€í™”ìœ¨ ë¹„êµ
        key_indicators = ['federal_funds_rate', 'unemployment_rate', 'cpi', 'gdp_growth']
        
        chart_data = []
        for indicator_key in key_indicators:
            if indicator_key in indicators:
                indicator = indicators[indicator_key]
                chart_data.append({
                    'ì§€í‘œ': indicator.get('title', indicator_key)[:20] + "...",
                    'ë³€í™”ìœ¨': indicator.get('change_percent', 0)
                })
        
        if chart_data:
            df = pd.DataFrame(chart_data)
            
            fig = px.bar(
                df,
                x='ì§€í‘œ',
                y='ë³€í™”ìœ¨',
                title="ì£¼ìš” ê²½ì œ ì§€í‘œ ë³€í™”ìœ¨ (%)",
                color='ë³€í™”ìœ¨',
                color_continuous_scale=['red', 'yellow', 'green']
            )
            
            st.plotly_chart(fig, use_container_width=True)

def show_detailed_data(all_data):
    """ìƒì„¸ ë°ì´í„° í˜ì´ì§€"""
    st.header("ğŸ” ìƒì„¸ ë°ì´í„°")
    
    # íƒ­ìœ¼ë¡œ êµ¬ë¶„
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ§  Intelligence", "ğŸ“Š FRED", "ğŸ“° ë‰´ìŠ¤", "ğŸ“± ì†Œì…œ"])
    
    with tab1:
        st.subheader("Alpha Vantage Intelligence ì›ì‹œ ë°ì´í„°")
        intelligence_data = all_data.get('intelligence', {})
        
        if intelligence_data.get('status') == 'success':
            with st.expander("ğŸ“Š ì‹œì¥ ìƒíƒœ ë°ì´í„°"):
                intel_data = intelligence_data.get('data', {})
                market_status = intel_data.get('market_status', [])
                if market_status:
                    st.json(market_status[:3])  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
            
            with st.expander("ğŸ“ˆ ìƒìœ„ ë³€ë™ ì¢…ëª© ë°ì´í„°"):
                top_movers = intel_data.get('top_gainers_losers', {})
                if top_movers:
                    st.json({k: v[:3] for k, v in top_movers.items()})  # ê° ì¹´í…Œê³ ë¦¬ 3ê°œì”©
        else:
            st.error(f"Intelligence ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {intelligence_data.get('error', 'Unknown')}")
    
    with tab2:
        st.subheader("FRED ê²½ì œ ì§€í‘œ ì›ì‹œ ë°ì´í„°")
        fred_data = all_data.get('fred', {})
        
        if fred_data.get('status') == 'success':
            fred_info = fred_data.get('data', {})
            indicators = fred_info.get('indicators', {})
            
            # ì§€í‘œ ì„ íƒ
            if indicators:
                selected_indicator = st.selectbox(
                    "ì§€í‘œ ì„ íƒ",
                    list(indicators.keys()),
                    format_func=lambda x: indicators[x].get('title', x)
                )
                
                if selected_indicator:
                    st.json(indicators[selected_indicator])
        else:
            st.error(f"FRED ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {fred_data.get('error', 'Unknown')}")
    
    with tab3:
        st.subheader("ë‰´ìŠ¤ ë°ì´í„°")
        news_data = all_data.get('news', {})
        
        if news_data.get('status') == 'success':
            news_info = news_data.get('data', {}).get('news_data', {})
            
            with st.expander("ğŸ“° ë‰´ìŠ¤ ìš”ì•½"):
                st.json(news_info.get('summary', {}))
            
            with st.expander("ğŸ“‚ ì¹´í…Œê³ ë¦¬ë³„ ë‰´ìŠ¤ (ìƒ˜í”Œ)"):
                categories = news_info.get('categories', {})
                for category, articles in categories.items():
                    if articles:
                        st.write(f"**{category.upper()}** ({len(articles)}ê°œ)")
                        st.json(articles[0])  # ì²« ë²ˆì§¸ ê¸°ì‚¬ë§Œ í‘œì‹œ
        else:
            st.error(f"ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {news_data.get('error', 'Unknown')}")
    
    with tab4:
        st.subheader("ì†Œì…œë¯¸ë””ì–´ ë°ì´í„°")
        news_data = all_data.get('news', {})
        
        if news_data.get('status') == 'success':
            social_data = news_data.get('data', {}).get('social_data', {})
            st.json(social_data)
        else:
            st.error(f"ì†Œì…œë¯¸ë””ì–´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {news_data.get('error', 'Unknown')}")

def show_dashboard_home(all_data):
    """ëŒ€ì‹œë³´ë“œ í™ˆ í˜ì´ì§€"""
    st.header("ğŸ  ëŒ€ì‹œë³´ë“œ ê°œìš”")
    
    # ì „ì²´ ìš”ì•½ ë©”íŠ¸ë¦­
    col1, col2, col3, col4 = st.columns(4)
    
    intelligence_data = all_data.get('intelligence', {})
    fred_data = all_data.get('fred', {})
    news_data = all_data.get('news', {})
    
    with col1:
        intel_summary = intelligence_data.get('summary', {})
        st.metric(
            "ğŸŒ ê¸€ë¡œë²Œ ì‹œì¥",
            intel_summary.get('market_status_count', 0),
            f"ê°œì¥: {intel_summary.get('open_markets_count', 0)}ê°œ"
        )
    
    with col2:
        fred_summary = fred_data.get('summary', {})
        st.metric(
            "ğŸ“Š FRED ì§€í‘œ",
            fred_summary.get('collected_indicators', 0),
            f"ì´ {fred_summary.get('total_indicators', 0)}ê°œ ì¤‘"
        )
    
    with col3:
        news_summary = news_data.get('summary', {})
        st.metric(
            "ğŸ“° ë‰´ìŠ¤ ê¸°ì‚¬",
            news_summary.get('total_articles', 0),
            f"ê¸ì •: {news_summary.get('news_sentiment', {}).get('positive_ratio', 0):.1f}%"
        )
    
    with col4:
        social_mentions = news_summary.get('social_mentions', {})
        st.metric(
            "ğŸ“± Reddit í¬ìŠ¤íŠ¸",
            social_mentions.get('reddit_posts', 0),
            f"ëŒ“ê¸€: {social_mentions.get('reddit_comments', 0)}ê°œ"
        )
    
    st.markdown("---")
    
    # ìµœì‹  í•˜ì´ë¼ì´íŠ¸
    st.markdown("---")
    st.subheader("ğŸ”¥ ìµœì‹  í•˜ì´ë¼ì´íŠ¸")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ“ˆ ì‹œì¥ í˜„í™©")
        if intelligence_data.get('status') == 'success':
            intel_data = intelligence_data.get('data', {})
            market_status = intel_data.get('market_status', [])
            
            if market_status:
                open_markets = [m for m in market_status if m.get('current_status') == 'open']
                st.write(f"**ê°œì¥ ì¤‘ì¸ ì‹œì¥**: {len(open_markets)}ê°œ")
                for market in open_markets[:3]:
                    st.write(f"â€¢ {market.get('region', 'Unknown')}: {market.get('primary_exchanges', 'N/A')}")
    
    with col2:
        st.markdown("#### ğŸ“° ì£¼ìš” ë‰´ìŠ¤")
        if news_data.get('status') == 'success':
            news_info = news_data.get('data', {}).get('news_data', {})
            highlights = news_info.get('summary', {}).get('recent_highlights', [])
            
            for highlight in highlights[:3]:
                title = highlight.get('title', '')[:60] + "..."
                sentiment = highlight.get('sentiment', 'neutral')
                sentiment_emoji = {'positive': 'ğŸŸ¢', 'negative': 'ğŸ”´', 'neutral': 'ğŸŸ¡'}.get(sentiment, 'ğŸŸ¡')
                st.write(f"{sentiment_emoji} {title}")
    
    # ì‹œìŠ¤í…œ ì •ë³´
    st.markdown("---")
    st.subheader("â„¹ï¸ ì‹œìŠ¤í…œ ì •ë³´")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### ğŸ“Š ë°ì´í„° ì†ŒìŠ¤")
        st.write("â€¢ Alpha Vantage Intelligence")
        st.write("â€¢ FRED ê²½ì œ ì§€í‘œ")
        st.write("â€¢ ì•„ì‹œì•„ ì‹œì¥ ë°ì´í„°")
        st.write("â€¢ ë‰´ìŠ¤ RSS í”¼ë“œ")
        st.write("â€¢ Reddit API")
    
    with col2:
        st.markdown("#### ğŸ• ì—…ë°ì´íŠ¸ ì£¼ê¸°")
        st.write("â€¢ ì‹œì¥ ë°ì´í„°: ì‹¤ì‹œê°„")
        st.write("â€¢ ê²½ì œ ì§€í‘œ: 5ë¶„")
        st.write("â€¢ ë‰´ìŠ¤: 5ë¶„")
        st.write("â€¢ ì†Œì…œë¯¸ë””ì–´: 5ë¶„")
    
    with col3:
        st.markdown("#### ğŸŒ ì‹œê°„ëŒ€")
        st.write("â€¢ ê¸°ì¤€ ì‹œê°„: í•œêµ­ ì‹œê°„ (KST)")
        st.write("â€¢ ì•„ì‹œì•„ ì‹œì¥: í•œêµ­ ì‹œê°„ ê¸°ì¤€")
        st.write("â€¢ ë¯¸êµ­ ì‹œì¥: í˜„ì§€ ì‹œê°„")
        st.write("â€¢ ìœ ëŸ½ ì‹œì¥: í˜„ì§€ ì‹œê°„")

def show_alpha_vantage_page(intelligence_data):
    """Alpha Vantage Intelligence ìƒì„¸ í˜ì´ì§€"""
    st.header("ğŸ§  Alpha Vantage Intelligence API")
    
    if intelligence_data.get('status') != 'success':
        st.error(f"âŒ Intelligence ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {intelligence_data.get('error', 'Unknown')}")
        return
    
    intel_data = intelligence_data.get('data', {})
    
    # íƒ­ìœ¼ë¡œ êµ¬ë¶„
    tab1, tab2, tab3 = st.tabs(["ğŸŒ ì‹œì¥ ìƒíƒœ", "ğŸ“ˆ ìƒìœ„ ë³€ë™ ì¢…ëª©", "ğŸ“Š ìƒì„¸ ë¶„ì„"])
    
    with tab1:
        st.subheader("ğŸŒ ê¸€ë¡œë²Œ ì‹œì¥ ìƒíƒœ")
        
        market_status = intel_data.get('market_status', [])
        if market_status:
            # ì‹œì¥ ìƒíƒœ í…Œì´ë¸”
            market_df = pd.DataFrame([
                {
                    'ì§€ì—­': market.get('region', 'Unknown'),
                    'ì£¼ìš” ê±°ë˜ì†Œ': market.get('primary_exchanges', 'N/A'),
                    'í˜„ì¬ ìƒíƒœ': market.get('current_status', 'Unknown'),
                    'ë¡œì»¬ ì‹œê°„': market.get('local_open', 'N/A'),
                    'ì°¸ê³ ': market.get('notes', 'N/A')
                }
                for market in market_status
            ])
            
            st.dataframe(market_df, use_container_width=True)
            
            # ê°œì¥/íì¥ ì°¨íŠ¸
            status_counts = market_df['í˜„ì¬ ìƒíƒœ'].value_counts()
            fig = px.pie(
                values=status_counts.values,
                names=status_counts.index,
                title="ê¸€ë¡œë²Œ ì‹œì¥ ê°œì¥/íì¥ í˜„í™©"
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.subheader("ğŸ“ˆ ìƒìœ„ ë³€ë™ ì¢…ëª©")
        
        top_movers = intel_data.get('top_gainers_losers', {})
        
        # ìƒìœ„ ìƒìŠ¹ ì¢…ëª©
        if 'top_gainers' in top_movers:
            st.markdown("#### ğŸŸ¢ ìƒìœ„ ìƒìŠ¹ ì¢…ëª©")
            gainers_data = []
            
            for gainer in top_movers['top_gainers'][:10]:
                gainers_data.append({
                    'ì¢…ëª©': gainer.get('ticker', 'N/A'),
                    'ê°€ê²©': f"${gainer.get('price', 0):.2f}",
                    'ë³€í™”': gainer.get('change_amount', 'N/A'),
                    'ë³€í™”ìœ¨': gainer.get('change_percentage', 'N/A'),
                    'ê±°ë˜ëŸ‰': f"{int(gainer.get('volume', 0)):,}"
                })
            
            if gainers_data:
                st.dataframe(pd.DataFrame(gainers_data), use_container_width=True)
        
        # ìƒìœ„ í•˜ë½ ì¢…ëª©
        if 'top_losers' in top_movers:
            st.markdown("#### ğŸ”´ ìƒìœ„ í•˜ë½ ì¢…ëª©")
            losers_data = []
            
            for loser in top_movers['top_losers'][:10]:
                losers_data.append({
                    'ì¢…ëª©': loser.get('ticker', 'N/A'),
                    'ê°€ê²©': f"${loser.get('price', 0):.2f}",
                    'ë³€í™”': loser.get('change_amount', 'N/A'),
                    'ë³€í™”ìœ¨': loser.get('change_percentage', 'N/A'),
                    'ê±°ë˜ëŸ‰': f"{int(loser.get('volume', 0)):,}"
                })
            
            if losers_data:
                st.dataframe(pd.DataFrame(losers_data), use_container_width=True)
        
        # ê±°ë˜ëŸ‰ ìƒìœ„ ì¢…ëª©
        if 'most_actively_traded' in top_movers:
            st.markdown("#### âš¡ ê±°ë˜ëŸ‰ ìƒìœ„ ì¢…ëª©")
            active_data = []
            
            for active in top_movers['most_actively_traded'][:10]:
                active_data.append({
                    'ì¢…ëª©': active.get('ticker', 'N/A'),
                    'ê°€ê²©': f"${active.get('price', 0):.2f}",
                    'ë³€í™”': active.get('change_amount', 'N/A'),
                    'ë³€í™”ìœ¨': active.get('change_percentage', 'N/A'),
                    'ê±°ë˜ëŸ‰': f"{int(active.get('volume', 0)):,}"
                })
            
            if active_data:
                st.dataframe(pd.DataFrame(active_data), use_container_width=True)
    
    with tab3:
        st.subheader("ğŸ“Š ìƒì„¸ ë¶„ì„")
        
        # ìš”ì•½ í†µê³„
        summary = intelligence_data.get('summary', {})
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ì‹œì¥ ìƒíƒœ", f"{summary.get('market_status_count', 0)}ê°œ")
            st.metric("ê°œì¥ ì‹œì¥", f"{summary.get('open_markets_count', 0)}ê°œ")
        
        with col2:
            st.metric("ìƒìŠ¹ ì¢…ëª©", f"{summary.get('top_gainers_count', 0)}ê°œ")
            st.metric("í•˜ë½ ì¢…ëª©", f"{summary.get('top_losers_count', 0)}ê°œ")
        
        with col3:
            st.metric("í™œë°œí•œ ê±°ë˜", f"{summary.get('most_active_count', 0)}ê°œ")
            st.metric("ì‹œì¥ ë³€ë™ì„±", summary.get('market_volatility', 'Unknown'))
        
        # ì›ì‹œ ë°ì´í„° (í™•ì¥ ê°€ëŠ¥)
        with st.expander("ğŸ” ì›ì‹œ ë°ì´í„° ë³´ê¸°"):
            st.json(intel_data)

if __name__ == "__main__":
    main()
