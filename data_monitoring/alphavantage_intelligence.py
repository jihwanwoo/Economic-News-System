"""
Alpha Vantage Intelligence API í†µí•©
Market Intelligence, News & Sentiment, Earnings, Top Movers ë“± ê³ ê¸‰ ë°ì´í„° ìˆ˜ì§‘
"""

import requests
import pandas as pd
import numpy as np
import configparser
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from pathlib import Path
import json

@dataclass
class MarketStatus:
    market: str
    region: str
    primary_exchanges: str
    local_open: str
    local_close: str
    current_status: str
    notes: str

@dataclass
class MarketNews:
    title: str
    url: str
    time_published: datetime
    authors: List[str]
    summary: str
    banner_image: str
    source: str
    category_within_source: str
    source_domain: str
    topics: List[Dict[str, str]]
    overall_sentiment_score: float
    overall_sentiment_label: str
    ticker_sentiment: List[Dict[str, Any]]

@dataclass
class TopMover:
    ticker: str
    price: float
    change_amount: float
    change_percentage: str
    volume: int

@dataclass
class InsiderTransaction:
    symbol: str
    name: str
    link: str
    summary: str
    transaction_type: str
    acquisition_or_disposition: str

@dataclass
class AnalyticsData:
    symbol: str
    metric: str
    value: float
    timestamp: datetime

class AlphaVantageIntelligence:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.api_key = self._load_api_key()
        self.base_url = "https://www.alphavantage.co/query"
        
        # API í˜¸ì¶œ ì œí•œ
        self.call_interval = 12  # seconds between calls
        self.last_call_time = 0
        
    def _load_api_key(self) -> str:
        """configure íŒŒì¼ì—ì„œ Alpha Vantage API í‚¤ ë¡œë“œ"""
        try:
            config_file = Path(__file__).parent.parent / "configure"
            if not config_file.exists():
                raise FileNotFoundError("configure íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            config = configparser.ConfigParser()
            config.read(config_file)
            
            if 'alphavantage' not in config:
                raise KeyError("configure íŒŒì¼ì— [alphavantage] ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤")
            
            api_key = config['alphavantage'].get('api_key')
            if not api_key:
                raise ValueError("Alpha Vantage API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            self.logger.info("âœ… Alpha Vantage Intelligence API í‚¤ ë¡œë“œ ì™„ë£Œ")
            return api_key
            
        except Exception as e:
            self.logger.error(f"API í‚¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _wait_for_rate_limit(self):
        """API í˜¸ì¶œ ì œí•œ ì¤€ìˆ˜"""
        current_time = time.time()
        time_since_last_call = current_time - self.last_call_time
        
        if time_since_last_call < self.call_interval:
            wait_time = self.call_interval - time_since_last_call
            self.logger.debug(f"Rate limit wait: {wait_time:.1f}s")
            time.sleep(wait_time)
        
        self.last_call_time = time.time()
    
    def get_market_status(self) -> List[MarketStatus]:
        """ê¸€ë¡œë²Œ ì‹œì¥ ê°œì¥/íì¥ ìƒíƒœ ì¡°íšŒ"""
        self._wait_for_rate_limit()
        
        try:
            params = {
                "function": "MARKET_STATUS",
                "apikey": self.api_key
            }
            
            response = requests.get(self.base_url, params=params, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            if "Error Message" in data or "Note" in data:
                self.logger.warning(f"Market status API issue: {data}")
                return []
            
            markets = data.get("markets", [])
            market_statuses = []
            
            self.logger.debug(f"Processing {len(markets)} markets from API response")
            
            for i, market_data in enumerate(markets):
                try:
                    market_status = MarketStatus(
                        market=market_data.get("market_type", ""),
                        region=market_data.get("region", ""),
                        primary_exchanges=market_data.get("primary_exchanges", ""),
                        local_open=market_data.get("local_open", ""),
                        local_close=market_data.get("local_close", ""),
                        current_status=market_data.get("current_status", ""),
                        notes=market_data.get("notes", "")
                    )
                    market_statuses.append(market_status)
                    self.logger.debug(f"Successfully parsed market {i+1}: {market_status.region}")
                except Exception as e:
                    self.logger.error(f"Error parsing market status {i+1}: {e}")
                    self.logger.error(f"Market data: {market_data}")
                    continue
            
            self.logger.info(f"âœ… ê¸€ë¡œë²Œ ì‹œì¥ ìƒíƒœ ìˆ˜ì§‘: {len(market_statuses)}ê°œ ì‹œì¥")
            return market_statuses
            
        except Exception as e:
            self.logger.error(f"Error getting market status: {e}")
            return []
    
    def get_market_news_sentiment(self, tickers: str = None, topics: str = None, 
                                 time_from: str = None, time_to: str = None,
                                 sort: str = "LATEST", limit: int = 50) -> List[MarketNews]:
        """ì‹œì¥ ë‰´ìŠ¤ ë° ê°ì • ë¶„ì„ ë°ì´í„° ìˆ˜ì§‘"""
        self._wait_for_rate_limit()
        
        try:
            params = {
                "function": "NEWS_SENTIMENT",
                "apikey": self.api_key,
                "sort": sort,
                "limit": limit
            }
            
            if tickers:
                params["tickers"] = tickers
            if topics:
                params["topics"] = topics
            if time_from:
                params["time_from"] = time_from
            if time_to:
                params["time_to"] = time_to
            
            response = requests.get(self.base_url, params=params, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            if "Error Message" in data or "Note" in data:
                self.logger.warning(f"News sentiment API issue: {data}")
                return []
            
            feed = data.get("feed", [])
            news_items = []
            
            for news_data in feed:
                try:
                    # ì‹œê°„ íŒŒì‹±
                    time_published = datetime.strptime(
                        news_data.get("time_published", ""), 
                        "%Y%m%dT%H%M%S"
                    )
                    
                    # ê°ì • ë¶„ì„ ë°ì´í„° íŒŒì‹±
                    overall_sentiment = news_data.get("overall_sentiment_score", 0.0)
                    overall_label = news_data.get("overall_sentiment_label", "Neutral")
                    
                    # í‹°ì»¤ë³„ ê°ì • ë¶„ì„
                    ticker_sentiment = news_data.get("ticker_sentiment", [])
                    
                    news_item = MarketNews(
                        title=news_data.get("title", ""),
                        url=news_data.get("url", ""),
                        time_published=time_published,
                        authors=news_data.get("authors", []),
                        summary=news_data.get("summary", ""),
                        banner_image=news_data.get("banner_image", ""),
                        source=news_data.get("source", ""),
                        category_within_source=news_data.get("category_within_source", ""),
                        source_domain=news_data.get("source_domain", ""),
                        topics=news_data.get("topics", []),
                        overall_sentiment_score=float(overall_sentiment),
                        overall_sentiment_label=overall_label,
                        ticker_sentiment=ticker_sentiment
                    )
                    
                    news_items.append(news_item)
                    
                except Exception as e:
                    self.logger.debug(f"Error parsing news item: {e}")
                    continue
            
            self.logger.info(f"âœ… ì‹œì¥ ë‰´ìŠ¤ ë° ê°ì • ë¶„ì„: {len(news_items)}ê°œ ê¸°ì‚¬")
            return news_items
            
        except Exception as e:
            self.logger.error(f"Error getting news sentiment: {e}")
            return []
    
    def get_top_gainers_losers(self) -> Dict[str, List[TopMover]]:
        """ìƒìŠ¹/í•˜ë½/ê±°ë˜ëŸ‰ ìƒìœ„ ì¢…ëª© ì¡°íšŒ"""
        self._wait_for_rate_limit()
        
        try:
            params = {
                "function": "TOP_GAINERS_LOSERS",
                "apikey": self.api_key
            }
            
            response = requests.get(self.base_url, params=params, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            if "Error Message" in data or "Note" in data:
                self.logger.warning(f"Top movers API issue: {data}")
                return {"top_gainers": [], "top_losers": [], "most_actively_traded": []}
            
            result = {
                "top_gainers": [],
                "top_losers": [],
                "most_actively_traded": []
            }
            
            # ìƒìŠ¹ ì¢…ëª©
            gainers_data = data.get("top_gainers", [])
            self.logger.debug(f"Processing {len(gainers_data)} gainers")
            for i, gainer in enumerate(gainers_data):
                try:
                    top_mover = TopMover(
                        ticker=gainer.get("ticker", ""),
                        price=float(gainer.get("price", 0)),
                        change_amount=float(gainer.get("change_amount", 0)),
                        change_percentage=gainer.get("change_percentage", "0%"),
                        volume=int(gainer.get("volume", 0))
                    )
                    result["top_gainers"].append(top_mover)
                    self.logger.debug(f"Successfully parsed gainer {i+1}: {top_mover.ticker}")
                except Exception as e:
                    self.logger.error(f"Error parsing gainer {i+1}: {e}")
                    self.logger.error(f"Gainer data: {gainer}")
                    continue
            
            # í•˜ë½ ì¢…ëª©
            losers_data = data.get("top_losers", [])
            self.logger.debug(f"Processing {len(losers_data)} losers")
            for i, loser in enumerate(losers_data):
                try:
                    top_mover = TopMover(
                        ticker=loser.get("ticker", ""),
                        price=float(loser.get("price", 0)),
                        change_amount=float(loser.get("change_amount", 0)),
                        change_percentage=loser.get("change_percentage", "0%"),
                        volume=int(loser.get("volume", 0))
                    )
                    result["top_losers"].append(top_mover)
                    self.logger.debug(f"Successfully parsed loser {i+1}: {top_mover.ticker}")
                except Exception as e:
                    self.logger.error(f"Error parsing loser {i+1}: {e}")
                    self.logger.error(f"Loser data: {loser}")
                    continue
            
            # ê±°ë˜ëŸ‰ ìƒìœ„ ì¢…ëª©
            active_data = data.get("most_actively_traded", [])
            self.logger.debug(f"Processing {len(active_data)} most active")
            for i, active in enumerate(active_data):
                try:
                    top_mover = TopMover(
                        ticker=active.get("ticker", ""),
                        price=float(active.get("price", 0)),
                        change_amount=float(active.get("change_amount", 0)),
                        change_percentage=active.get("change_percentage", "0%"),
                        volume=int(active.get("volume", 0))
                    )
                    result["most_actively_traded"].append(top_mover)
                    self.logger.debug(f"Successfully parsed active {i+1}: {top_mover.ticker}")
                except Exception as e:
                    self.logger.error(f"Error parsing active {i+1}: {e}")
                    self.logger.error(f"Active data: {active}")
                    continue
            
            total_items = sum(len(movers) for movers in result.values())
            self.logger.info(f"âœ… ìƒìœ„ ì¢…ëª© ë°ì´í„°: {total_items}ê°œ ì¢…ëª©")
            return result
            
        except Exception as e:
            self.logger.error(f"Error getting top gainers/losers: {e}")
            return {"top_gainers": [], "top_losers": [], "most_actively_traded": []}
                try:
                    top_mover = TopMover(
                        ticker=loser.get("ticker", ""),
                        price=float(loser.get("price", 0)),
                        change_amount=float(loser.get("change_amount", 0)),
                        change_percentage=loser.get("change_percentage", "0%"),
                        volume=int(loser.get("volume", 0))
                    )
                    result["top_losers"].append(top_mover)
                except Exception as e:
                    self.logger.debug(f"Error parsing loser: {e}")
                    continue
            
            # ê±°ë˜ëŸ‰ ìƒìœ„ ì¢…ëª©
            for active in data.get("most_actively_traded", []):
                try:
                    top_mover = TopMover(
                        ticker=active.get("ticker", ""),
                        price=float(active.get("price", 0)),
                        change_amount=float(active.get("change_amount", 0)),
                        change_percentage=active.get("change_percentage", "0%"),
                        volume=int(active.get("volume", 0))
                    )
                    result["most_actively_traded"].append(top_mover)
                except Exception as e:
                    self.logger.debug(f"Error parsing active stock: {e}")
                    continue
            
            total_count = sum(len(movers) for movers in result.values())
            self.logger.info(f"âœ… ìƒìœ„ ì¢…ëª© ë°ì´í„°: {total_count}ê°œ ì¢…ëª©")
            return result
            
        except Exception as e:
            self.logger.error(f"Error getting top movers: {e}")
            return {}
    
    def get_insider_transactions(self, symbol: str = None) -> List[InsiderTransaction]:
        """ë‚´ë¶€ì ê±°ë˜ ì •ë³´ ì¡°íšŒ"""
        self._wait_for_rate_limit()
        
        try:
            params = {
                "function": "INSIDER_TRANSACTIONS",
                "apikey": self.api_key
            }
            
            if symbol:
                params["symbol"] = symbol
            
            response = requests.get(self.base_url, params=params, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            if "Error Message" in data or "Note" in data:
                self.logger.warning(f"Insider transactions API issue: {data}")
                return []
            
            transactions = []
            feed = data.get("feed", [])
            
            for transaction_data in feed:
                try:
                    transaction = InsiderTransaction(
                        symbol=transaction_data.get("symbol", ""),
                        name=transaction_data.get("name", ""),
                        link=transaction_data.get("link", ""),
                        summary=transaction_data.get("summary", ""),
                        transaction_type=transaction_data.get("transaction_type", ""),
                        acquisition_or_disposition=transaction_data.get("acquisition_or_disposition", "")
                    )
                    transactions.append(transaction)
                except Exception as e:
                    self.logger.debug(f"Error parsing insider transaction: {e}")
                    continue
            
            self.logger.info(f"âœ… ë‚´ë¶€ì ê±°ë˜ ì •ë³´: {len(transactions)}ê°œ")
            return transactions
            
        except Exception as e:
            self.logger.error(f"Error getting insider transactions: {e}")
            return []
    
    def get_analytics_sliding_window(self, symbols: List[str], range_: str = "1month",
                                   interval: str = "daily", ohlc: str = "close",
                                   window_size: int = 10, 
                                   calculations: str = "MEAN,STDDEV") -> Dict[str, List[AnalyticsData]]:
        """ê³ ê¸‰ ë¶„ì„ ë°ì´í„° (ìŠ¬ë¼ì´ë”© ìœˆë„ìš°)"""
        results = {}
        
        for symbol in symbols:
            self._wait_for_rate_limit()
            
            try:
                params = {
                    "function": "ANALYTICS_SLIDING_WINDOW",
                    "SYMBOLS": symbol,
                    "RANGE": range_,
                    "INTERVAL": interval,
                    "OHLC": ohlc,
                    "WINDOW_SIZE": window_size,
                    "CALCULATIONS": calculations,
                    "apikey": self.api_key
                }
                
                response = requests.get(self.base_url, params=params, timeout=30)
                response.raise_for_status()
                data = response.json()
                
                if "Error Message" in data or "Note" in data:
                    self.logger.warning(f"Analytics API issue for {symbol}: {data}")
                    continue
                
                analytics_data = []
                payload = data.get("payload", {})
                
                for date_str, metrics in payload.items():
                    try:
                        timestamp = datetime.strptime(date_str, "%Y-%m-%d")
                        
                        for metric_name, value in metrics.items():
                            if value and value != "null":
                                analytics_point = AnalyticsData(
                                    symbol=symbol,
                                    metric=metric_name,
                                    value=float(value),
                                    timestamp=timestamp
                                )
                                analytics_data.append(analytics_point)
                    except Exception as e:
                        self.logger.debug(f"Error parsing analytics data: {e}")
                        continue
                
                results[symbol] = analytics_data
                self.logger.info(f"âœ… {symbol} ê³ ê¸‰ ë¶„ì„: {len(analytics_data)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
                
            except Exception as e:
                self.logger.error(f"Error getting analytics for {symbol}: {e}")
                continue
        
        return results
    
    def collect_comprehensive_intelligence(self) -> Dict[str, Any]:
        """ì¢…í•© Intelligence ë°ì´í„° ìˆ˜ì§‘ (ì‘ë™í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸ë§Œ)"""
        self.logger.info("ğŸ§  Alpha Vantage Intelligence ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        
        intelligence_data = {
            "timestamp": datetime.now().isoformat(),
            "market_status": [],
            "top_gainers_losers": {},
            "summary": {}
        }
        
        try:
            # 1. ê¸€ë¡œë²Œ ì‹œì¥ ìƒíƒœ (âœ… ì‘ë™)
            self.logger.info("ğŸŒ ê¸€ë¡œë²Œ ì‹œì¥ ìƒíƒœ ìˆ˜ì§‘ ì¤‘...")
            market_status = self.get_market_status()
            intelligence_data["market_status"] = [
                {
                    "market": status.market,
                    "region": status.region,
                    "primary_exchanges": status.primary_exchanges,
                    "current_status": status.current_status,
                    "local_open": status.local_open,
                    "local_close": status.local_close,
                    "notes": status.notes
                }
                for status in market_status
            ]
            
            # 2. ìƒìœ„ ì¢…ëª© (ìƒìŠ¹/í•˜ë½/ê±°ë˜ëŸ‰) (âœ… ì‘ë™)
            self.logger.info("ğŸ“ˆ ìƒìœ„ ì¢…ëª© ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            top_movers = self.get_top_gainers_losers()
            
            for category, movers in top_movers.items():
                intelligence_data["top_gainers_losers"][category] = [
                    {
                        "ticker": mover.ticker,
                        "price": float(mover.price),
                        "change_amount": float(mover.change_amount),
                        "change_percentage": mover.change_percentage.replace('%', ''),
                        "volume": int(mover.volume)
                    }
                    for mover in movers
                ]
            
            # 3. ìš”ì•½ í†µê³„ ìƒì„±
            intelligence_data["summary"] = self._generate_intelligence_summary(intelligence_data)
            
        except Exception as e:
            self.logger.error(f"Intelligence ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # ìˆ˜ì§‘ ì™„ë£Œ ë¡œê·¸
        total_items = (
            len(intelligence_data["market_status"]) +
            sum(len(movers) for movers in intelligence_data["top_gainers_losers"].values())
        )
        
        self.logger.info(f"âœ… Intelligence ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {total_items}ê°œ í•­ëª©")
        return intelligence_data
    
    def _generate_intelligence_summary(self, intelligence_data: Dict[str, Any]) -> Dict[str, Any]:
        """Intelligence ë°ì´í„° ìš”ì•½ ìƒì„±"""
        summary = {
            "collection_time": datetime.now().isoformat(),
            "market_analysis": {},
            "top_movers_analysis": {},
            "risk_indicators": {}
        }
        
        try:
            # ì‹œì¥ ìƒíƒœ ë¶„ì„
            market_status = intelligence_data.get("market_status", [])
            open_markets = [m for m in market_status if m["current_status"] == "open"]
            closed_markets = [m for m in market_status if m["current_status"] == "closed"]
            
            summary["market_analysis"] = {
                "total_markets": len(market_status),
                "open_markets": len(open_markets),
                "closed_markets": len(closed_markets),
                "open_market_regions": list(set(m["region"] for m in open_markets)),
                "market_status_distribution": {
                    "open": len(open_markets),
                    "closed": len(closed_markets)
                }
            }
            
            # ìƒìœ„ ì¢…ëª© ë¶„ì„
            top_movers = intelligence_data.get("top_gainers_losers", {})
            
            if "top_gainers" in top_movers and top_movers["top_gainers"]:
                gainers = top_movers["top_gainers"]
                top_gainer = gainers[0]
                avg_gain = sum(float(g["change_percentage"]) for g in gainers) / len(gainers)
                
                summary["top_movers_analysis"]["gainers"] = {
                    "count": len(gainers),
                    "top_performer": {
                        "ticker": top_gainer["ticker"],
                        "change_percentage": float(top_gainer["change_percentage"]),
                        "volume": top_gainer["volume"]
                    },
                    "average_gain": round(avg_gain, 2)
                }
            
            if "top_losers" in top_movers and top_movers["top_losers"]:
                losers = top_movers["top_losers"]
                top_loser = losers[0]
                avg_loss = sum(float(l["change_percentage"]) for l in losers) / len(losers)
                
                summary["top_movers_analysis"]["losers"] = {
                    "count": len(losers),
                    "worst_performer": {
                        "ticker": top_loser["ticker"],
                        "change_percentage": float(top_loser["change_percentage"]),
                        "volume": top_loser["volume"]
                    },
                    "average_loss": round(avg_loss, 2)
                }
            
            if "most_actively_traded" in top_movers and top_movers["most_actively_traded"]:
                most_active = top_movers["most_actively_traded"]
                top_volume = most_active[0]
                total_volume = sum(m["volume"] for m in most_active)
                
                summary["top_movers_analysis"]["most_active"] = {
                    "count": len(most_active),
                    "highest_volume": {
                        "ticker": top_volume["ticker"],
                        "volume": top_volume["volume"],
                        "change_percentage": float(top_volume["change_percentage"])
                    },
                    "total_volume": total_volume
                }
            
            # ë¦¬ìŠ¤í¬ ì§€í‘œ ê³„ì‚°
            if "top_gainers" in top_movers and "top_losers" in top_movers:
                gainers = top_movers["top_gainers"]
                losers = top_movers["top_losers"]
                
                if gainers and losers:
                    max_gain = max(float(g["change_percentage"]) for g in gainers)
                    max_loss = min(float(l["change_percentage"]) for l in losers)
                    volatility = max_gain - max_loss
                    
                    summary["risk_indicators"] = {
                        "max_gain_percentage": round(max_gain, 2),
                        "max_loss_percentage": round(max_loss, 2),
                        "market_volatility": round(volatility, 2),
                        "volatility_level": "high" if volatility > 100 else "medium" if volatility > 50 else "low"
                    }
        
        except Exception as e:
            self.logger.error(f"Intelligence ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
            summary["error"] = str(e)
        
        return summary
    
    def save_intelligence_data(self, intelligence_data: Dict[str, Any], filename: str = None):
        """Intelligence ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"alphavantage_intelligence_{timestamp}.json"
        
        output_dir = Path(__file__).parent.parent / "output"
        output_dir.mkdir(exist_ok=True)
        
        filepath = output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(intelligence_data, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"ğŸ“ Intelligence ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filepath}")
    
    def get_intelligence_summary(self, intelligence_data: Dict[str, Any]) -> Dict[str, Any]:
        """Intelligence ë°ì´í„° ìš”ì•½"""
        summary = {
            "timestamp": intelligence_data.get("timestamp"),
            "data_overview": {
                "market_status_count": len(intelligence_data.get("market_status", [])),
                "news_articles_count": len(intelligence_data.get("market_news", [])),
                "top_movers_categories": len(intelligence_data.get("top_movers", {})),
                "insider_transactions_count": len(intelligence_data.get("insider_transactions", [])),
                "analytics_symbols_count": len(intelligence_data.get("analytics", {}))
            },
            "market_insights": {},
            "sentiment_analysis": {},
            "key_highlights": []
        }
        
        # ì‹œì¥ ìƒíƒœ ìš”ì•½
        market_status = intelligence_data.get("market_status", [])
        open_markets = [m for m in market_status if m.get("current_status") == "open"]
        closed_markets = [m for m in market_status if m.get("current_status") == "closed"]
        
        summary["market_insights"] = {
            "open_markets": len(open_markets),
            "closed_markets": len(closed_markets),
            "total_markets": len(market_status)
        }
        
        # ê°ì • ë¶„ì„ ìš”ì•½
        market_news = intelligence_data.get("market_news", [])
        if market_news:
            sentiment_scores = [news.get("overall_sentiment_score", 0) for news in market_news]
            avg_sentiment = np.mean(sentiment_scores) if sentiment_scores else 0
            
            summary["sentiment_analysis"] = {
                "average_sentiment": avg_sentiment,
                "sentiment_label": "Bullish" if avg_sentiment > 0.1 else "Bearish" if avg_sentiment < -0.1 else "Neutral",
                "total_articles": len(market_news)
            }
        
        # ì£¼ìš” í•˜ì´ë¼ì´íŠ¸
        highlights = []
        
        # ìƒìœ„ ìƒìŠ¹/í•˜ë½ ì¢…ëª©
        top_movers = intelligence_data.get("top_movers", {})
        if top_movers.get("top_gainers"):
            top_gainer = top_movers["top_gainers"][0]
            highlights.append(f"ğŸ“ˆ ìµœê³  ìƒìŠ¹: {top_gainer['ticker']} ({top_gainer['change_percentage']})")
        
        if top_movers.get("top_losers"):
            top_loser = top_movers["top_losers"][0]
            highlights.append(f"ğŸ“‰ ìµœê³  í•˜ë½: {top_loser['ticker']} ({top_loser['change_percentage']})")
        
        # ì£¼ìš” ë‰´ìŠ¤
        if market_news:
            latest_news = market_news[0]
            highlights.append(f"ğŸ“° ìµœì‹  ë‰´ìŠ¤: {latest_news['title'][:50]}...")
        
        summary["key_highlights"] = highlights
        
        return summary

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_alphavantage_intelligence():
    intelligence = AlphaVantageIntelligence()
    
    print("ğŸ§  Alpha Vantage Intelligence API í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ì¢…í•© Intelligence ë°ì´í„° ìˆ˜ì§‘
    intelligence_data = intelligence.collect_comprehensive_intelligence()
    
    # ìš”ì•½ ì •ë³´ ì¶œë ¥
    summary = intelligence.get_intelligence_summary(intelligence_data)
    
    print(f"\nğŸ“Š ë°ì´í„° ê°œìš”:")
    for key, value in summary["data_overview"].items():
        print(f"  {key}: {value}")
    
    print(f"\nğŸŒ ì‹œì¥ í˜„í™©:")
    market_insights = summary["market_insights"]
    print(f"  ê°œì¥ ì‹œì¥: {market_insights.get('open_markets', 0)}ê°œ")
    print(f"  íì¥ ì‹œì¥: {market_insights.get('closed_markets', 0)}ê°œ")
    
    print(f"\nğŸ’­ ê°ì • ë¶„ì„:")
    sentiment = summary["sentiment_analysis"]
    if sentiment:
        print(f"  í‰ê·  ê°ì •: {sentiment.get('average_sentiment', 0):.3f}")
        print(f"  ê°ì • ë¼ë²¨: {sentiment.get('sentiment_label', 'N/A')}")
        print(f"  ë¶„ì„ ê¸°ì‚¬: {sentiment.get('total_articles', 0)}ê°œ")
    
    print(f"\nğŸ”¥ ì£¼ìš” í•˜ì´ë¼ì´íŠ¸:")
    for highlight in summary["key_highlights"]:
        print(f"  {highlight}")
    
    # ë°ì´í„° ì €ì¥
    intelligence.save_intelligence_data(intelligence_data)
    
    print(f"\nâœ… Intelligence ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥ ì™„ë£Œ!")

if __name__ == "__main__":
    test_alphavantage_intelligence()
