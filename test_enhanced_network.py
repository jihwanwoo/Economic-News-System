#!/usr/bin/env python3
"""
ê°œì„ ëœ ê²½ì œ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ í…ŒìŠ¤íŠ¸
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data_monitoring.enhanced_economic_network_analyzer import EnhancedEconomicNetworkAnalyzer
import json

def test_enhanced_network_analysis():
    """ê°œì„ ëœ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸš€ ê°œì„ ëœ ê²½ì œ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = EnhancedEconomicNetworkAnalyzer()
    
    # ìƒ˜í”Œ ê²½ì œ í…ìŠ¤íŠ¸
    sample_texts = [
        "ì—°ì¤€ì´ ê¸°ì¤€ê¸ˆë¦¬ë¥¼ 0.25%p ì¸ìƒí•˜ë©° ì¸í”Œë ˆì´ì…˜ ì–µì œì— ë‚˜ì„°ë‹¤. ì´ë²ˆ ê¸ˆë¦¬ ì¸ìƒìœ¼ë¡œ ì£¼ì‹ì‹œì¥ì€ í•˜ë½ì„¸ë¥¼ ë³´ì´ê³  ìˆìœ¼ë©°, íŠ¹íˆ ê¸°ìˆ ì£¼ê°€ í° íƒ€ê²©ì„ ë°›ê³  ìˆë‹¤.",
        "ì• í”Œê³¼ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ê°€ AI ê¸°ìˆ  ê°œë°œì„ ìœ„í•œ íŒŒíŠ¸ë„ˆì‹­ì„ ë°œí‘œí–ˆë‹¤. ì´ëŠ” ê¸°ìˆ  ì„¹í„°ì˜ ê²½ìŸë ¥ ê°•í™”ì™€ í•¨ê»˜ ê´€ë ¨ ì£¼ê°€ ìƒìŠ¹ì„ ì´ëŒê³  ìˆë‹¤.",
        "ì¤‘êµ­ê³¼ ë¯¸êµ­ ê°„ì˜ ë¬´ì—­ ë¶„ìŸì´ ì¬ì í™”ë˜ë©´ì„œ ê¸€ë¡œë²Œ ê³µê¸‰ë§ì— ì°¨ì§ˆì´ ìš°ë ¤ëœë‹¤. ì´ë¡œ ì¸í•´ ì›ìì¬ ê°€ê²©ì´ ìƒìŠ¹í•˜ê³  ì¸í”Œë ˆì´ì…˜ ì••ë ¥ì´ ì¦ê°€í•˜ê³  ìˆë‹¤.",
        "ë¹„íŠ¸ì½”ì¸ì´ ë‹¤ì‹œ 5ë§Œ ë‹¬ëŸ¬ë¥¼ ëŒíŒŒí•˜ë©° ì•”í˜¸í™”í ì‹œì¥ì´ í™œê¸°ë¥¼ ë ê³  ìˆë‹¤. ê¸°ê´€ íˆ¬ììë“¤ì˜ ê´€ì‹¬ ì¦ê°€ì™€ í•¨ê»˜ ë””ì§€í„¸ ìì‚°ì— ëŒ€í•œ íˆ¬ì ì‹¬ë¦¬ê°€ ê°œì„ ë˜ê³  ìˆë‹¤.",
        "ESG íˆ¬ìê°€ ì£¼ë¥˜ë¡œ ìë¦¬ì¡ìœ¼ë©´ì„œ ì¹œí™˜ê²½ ê¸°ì—…ë“¤ì˜ ì£¼ê°€ê°€ ìƒìŠ¹í•˜ê³  ìˆë‹¤. íŠ¹íˆ ì¬ìƒì—ë„ˆì§€ì™€ ì „ê¸°ì°¨ ê´€ë ¨ ê¸°ì—…ë“¤ì´ í° ê´€ì‹¬ì„ ë°›ê³  ìˆë‹¤.",
        "ê³ ìš©ì‹œì¥ì´ ê°œì„ ë˜ë©´ì„œ ì‹¤ì—…ë¥ ì´ 3.5%ë¡œ í•˜ë½í–ˆë‹¤. ì´ëŠ” ì†Œë¹„ì ì‹ ë¢°ë„ ìƒìŠ¹ê³¼ í•¨ê»˜ ì†Œë¹„ ì¦ê°€ë¡œ ì´ì–´ì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.",
        "ë¶€ë™ì‚° ì‹œì¥ì´ ê¸ˆë¦¬ ì¸ìƒì—ë„ ë¶ˆêµ¬í•˜ê³  ê²¬ì¡°í•œ ëª¨ìŠµì„ ë³´ì´ê³  ìˆë‹¤. ì£¼íƒ ê³µê¸‰ ë¶€ì¡±ê³¼ í•¨ê»˜ ê°€ê²© ìƒìŠ¹ ì••ë ¥ì´ ì§€ì†ë˜ê³  ìˆë‹¤.",
        "ì—ë„ˆì§€ ê°€ê²© ìƒìŠ¹ìœ¼ë¡œ ì¸í”Œë ˆì´ì…˜ ìš°ë ¤ê°€ ì»¤ì§€ê³  ìˆë‹¤. íŠ¹íˆ ì›ìœ ì™€ ì²œì—°ê°€ìŠ¤ ê°€ê²© ê¸‰ë“±ì´ ì „ì²´ ë¬¼ê°€ ìƒìŠ¹ì„ ì£¼ë„í•˜ê³  ìˆë‹¤.",
        "ì •ë¶€ì˜ ëŒ€ê·œëª¨ ì¸í”„ë¼ íˆ¬ì ê³„íšì´ ë°œí‘œë˜ë©´ì„œ ê±´ì„¤ ë° ì†Œì¬ ê´€ë ¨ ì£¼ì‹ë“¤ì´ ê°•ì„¸ë¥¼ ë³´ì´ê³  ìˆë‹¤. ì´ëŠ” ê²½ê¸° ë¶€ì–‘ íš¨ê³¼ì™€ í•¨ê»˜ ê³ ìš© ì°½ì¶œì—ë„ ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.",
        "ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ê°€ ì¦ê°€í•˜ë©´ì„œ ì•ˆì „ìì‚° ì„ í˜¸ í˜„ìƒì´ ë‚˜íƒ€ë‚˜ê³  ìˆë‹¤. ê¸ˆê³¼ êµ­ì±„ ê°€ê²©ì´ ìƒìŠ¹í•˜ëŠ” ë°˜ë©´, ìœ„í—˜ìì‚°ì¸ ì£¼ì‹ì€ ë³€ë™ì„±ì´ í™•ëŒ€ë˜ê³  ìˆë‹¤."
    ]
    
    print(f"ğŸ“ ë¶„ì„í•  í…ìŠ¤íŠ¸ ìˆ˜: {len(sample_texts)}")
    print()
    
    # 1. ê°œë… ì¶”ì¶œ í…ŒìŠ¤íŠ¸
    print("1ï¸âƒ£ ê²½ì œ ê°œë… ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    
    for i, text in enumerate(sample_texts[:3], 1):
        print(f"\nğŸ“„ í…ìŠ¤íŠ¸ {i}: {text[:50]}...")
        concepts, scores = analyzer.extract_economic_concepts(text)
        
        print(f"   ë°œê²¬ëœ ê°œë… ìˆ˜: {len(concepts)}")
        for concept, data in list(concepts.items())[:3]:
            display_name = analyzer._get_concept_display_name(concept)
            print(f"   â€¢ {display_name}: {data['score']:.1f}ì  ({len(data['terms'])}ê°œ ìš©ì–´)")
    
    # 2. ë„¤íŠ¸ì›Œí¬ ë¶„ì„ í…ŒìŠ¤íŠ¸
    print("\n\n2ï¸âƒ£ ë„¤íŠ¸ì›Œí¬ ê´€ê³„ ë¶„ì„ í…ŒìŠ¤íŠ¸")
    print("-" * 40)
    
    network_result = analyzer.analyze_concept_relationships(sample_texts)
    
    if 'error' in network_result:
        print(f"âŒ ë¶„ì„ ì˜¤ë¥˜: {network_result['error']}")
        return
    
    G = network_result['graph']
    concepts = network_result['concepts']
    metrics = network_result['metrics']
    
    print(f"ğŸ“Š ë„¤íŠ¸ì›Œí¬ ê·œëª¨:")
    print(f"   â€¢ ë…¸ë“œ ìˆ˜: {len(G.nodes())}")
    print(f"   â€¢ ì—£ì§€ ìˆ˜: {len(G.edges())}")
    print(f"   â€¢ ë„¤íŠ¸ì›Œí¬ ë°€ë„: {metrics.get('density', 0):.3f}")
    
    # 3. ìƒìœ„ ê°œë…ë“¤
    print(f"\nğŸ† ìƒìœ„ ê²½ì œ ê°œë…ë“¤:")
    for concept, data in sorted(concepts.items(), key=lambda x: x[1]['total_score'], reverse=True)[:5]:
        display_name = analyzer._get_concept_display_name(concept)
        print(f"   â€¢ {display_name}: {data['total_score']:.1f}ì  ({data['mention_count']}íšŒ ì–¸ê¸‰)")
    
    # 4. ì£¼ìš” ê´€ê³„ë“¤
    print(f"\nğŸ”— ì£¼ìš” ê´€ê³„ë“¤:")
    edges_with_weight = [(edge[0], edge[1], edge[2]['weight']) for edge in G.edges(data=True)]
    edges_sorted = sorted(edges_with_weight, key=lambda x: x[2], reverse=True)
    
    for source, target, weight in edges_sorted[:5]:
        source_name = analyzer._get_concept_display_name(source)
        target_name = analyzer._get_concept_display_name(target)
        print(f"   â€¢ {source_name} â†” {target_name}: {weight:.2f}")
    
    # 5. ì¸ì‚¬ì´íŠ¸ ìƒì„±
    print(f"\nğŸ’¡ ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸:")
    insights = analyzer.generate_network_insights(network_result)
    for insight in insights:
        print(f"   â€¢ {insight}")
    
    # 6. ê²°ê³¼ ì €ì¥
    output_file = f"output/enhanced_network_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    # ê·¸ë˜í”„ëŠ” JSONìœ¼ë¡œ ì§ë ¬í™”í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì œì™¸
    save_data = {
        'concepts': concepts,
        'metrics': metrics,
        'insights': insights,
        'node_count': len(G.nodes()),
        'edge_count': len(G.edges()),
        'nodes': list(G.nodes()),
        'edges': [(edge[0], edge[1], edge[2]) for edge in G.edges(data=True)]
    }
    
    try:
        os.makedirs('output', exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
    except Exception as e:
        print(f"âŒ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    print("\n" + "=" * 60)
    print("âœ… ê°œì„ ëœ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    # ê°œì„  íš¨ê³¼ ìš”ì•½
    print(f"\nğŸš€ ê°œì„  íš¨ê³¼ ìš”ì•½:")
    print(f"   â€¢ ë…¸ë“œ ìˆ˜: {len(G.nodes())}ê°œ (ê¸°ì¡´ 7-21ê°œ â†’ ëŒ€í­ ì¦ê°€)")
    print(f"   â€¢ ì˜ë¯¸ ìˆëŠ” ê´€ê³„: ê²½ì œì  ì—°ê´€ì„± ê¸°ë°˜")
    print(f"   â€¢ ì¹´í…Œê³ ë¦¬í™”: 16ê°œ ê²½ì œ ë¶„ì•¼ë¡œ ì²´ê³„í™”")
    print(f"   â€¢ ê°ì • ë¶„ì„: ê°œë…ë³„ ê¸ì •/ë¶€ì • ê°ì • ë¶„ì„")
    print(f"   â€¢ ì‹¤ì‹œê°„ ì¸ì‚¬ì´íŠ¸: {len(insights)}ê°œ ì¸ì‚¬ì´íŠ¸ ìë™ ìƒì„±")

if __name__ == "__main__":
    from datetime import datetime
    test_enhanced_network_analysis()
