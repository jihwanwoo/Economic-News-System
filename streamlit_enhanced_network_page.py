#!/usr/bin/env python3
"""
ê°œì„ ëœ ê²½ì œ ê°œë… ë„¤íŠ¸ì›Œí¬ ë¶„ì„ Streamlit í˜ì´ì§€
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import networkx as nx
import numpy as np
from datetime import datetime
import sys
import os
import json
import random

# ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data_monitoring.enhanced_economic_network_analyzer import EnhancedEconomicNetworkAnalyzer

def create_enhanced_network_page():
    """ê°œì„ ëœ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ í˜ì´ì§€ ìƒì„±"""
    
    st.title("ğŸ•¸ï¸ ê°œì„ ëœ ê²½ì œ ê°œë… ë„¤íŠ¸ì›Œí¬ ë¶„ì„")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
        
        # ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ
        data_source = st.selectbox(
            "ë°ì´í„° ì†ŒìŠ¤",
            ["ìë™ ì„ íƒ", "Reddit ì „ìš©", "ë¬´ë£Œ ëŒ€ì•ˆ (Reddit+Nitter)", "ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°"]
        )
        
        # ë°ì´í„° ì†ŒìŠ¤ ì •ë³´ í‘œì‹œ
        if data_source == "ìë™ ì„ íƒ":
            st.info("ğŸ’¡ API í‚¤ ìœ ë¬´ì— ë”°ë¼ ìµœì ì˜ ì†ŒìŠ¤ë¥¼ ìë™ ì„ íƒí•©ë‹ˆë‹¤")
        elif data_source == "Reddit ì „ìš©":
            st.info("ğŸ“± Reddit ê²½ì œ ì„œë¸Œë ˆë”§ì—ì„œ ì‹¤ì œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤")
        elif data_source == "ë¬´ë£Œ ëŒ€ì•ˆ (Reddit+Nitter)":
            st.info("ğŸ†“ ì—¬ëŸ¬ ë¬´ë£Œ ì†ŒìŠ¤ë¥¼ ì¡°í•©í•˜ì—¬ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤")
        else:
            st.info("ğŸ­ í˜„ì‹¤ì ì¸ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤")
        
        # ë„¤íŠ¸ì›Œí¬ ì„¤ì •
        st.subheader("ë„¤íŠ¸ì›Œí¬ ì„¤ì •")
        min_edge_weight = st.slider("ìµœì†Œ ì—°ê²° ê°•ë„", 0.1, 1.0, 0.3, 0.1)
        max_nodes = st.slider("ìµœëŒ€ ë…¸ë“œ ìˆ˜", 10, 50, 30, 5)
        layout_type = st.selectbox("ë ˆì´ì•„ì›ƒ", ["spring", "circular", "kamada_kawai", "random"])
        
        # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
        if st.button("ğŸ” ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì‹¤í–‰", type="primary", key="enhanced_network_analysis"):
            st.session_state.run_analysis = True
    
    # ë©”ì¸ ì»¨í…ì¸ 
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“Š ê²½ì œ ê°œë… ë„¤íŠ¸ì›Œí¬")
        
        # ë¶„ì„ ì‹¤í–‰
        if st.session_state.get('run_analysis', False):
            with st.spinner("ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì¤‘..."):
                network_data = run_enhanced_network_analysis(
                    data_source, min_edge_weight, max_nodes
                )
                st.session_state.network_data = network_data
                st.session_state.run_analysis = False
        
        # ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”
        if 'network_data' in st.session_state:
            network_data = st.session_state.network_data
            
            if 'error' not in network_data:
                # ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ìƒì„±
                fig = create_enhanced_network_visualization(
                    network_data, layout_type, min_edge_weight
                )
                st.plotly_chart(fig, use_container_width=True, height=600)
                
                # ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­ í‘œì‹œ
                display_network_metrics(network_data)
            else:
                st.error(f"ë¶„ì„ ì˜¤ë¥˜: {network_data['error']}")
        else:
            # ì´ˆê¸° ìƒíƒœ - ìƒ˜í”Œ ë„¤íŠ¸ì›Œí¬ í‘œì‹œ
            st.info("ğŸ‘† ì‚¬ì´ë“œë°”ì—ì„œ 'ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
            display_sample_network()
    
    with col2:
        st.subheader("ğŸ“ˆ ë¶„ì„ ê²°ê³¼")
        
        if 'network_data' in st.session_state and 'error' not in st.session_state.network_data:
            network_data = st.session_state.network_data
            
            # ì£¼ìš” ì¸ì‚¬ì´íŠ¸
            st.markdown("### ğŸ¯ ì£¼ìš” ì¸ì‚¬ì´íŠ¸")
            analyzer = EnhancedEconomicNetworkAnalyzer()
            insights = analyzer.generate_network_insights(network_data)
            
            for insight in insights:
                st.markdown(f"â€¢ {insight}")
            
            # ìƒìœ„ ê°œë…ë“¤
            st.markdown("### ğŸ† í•µì‹¬ ê²½ì œ ê°œë…")
            display_top_concepts(network_data)
            
            # ê´€ê³„ ìœ í˜• ë¶„í¬
            st.markdown("### ğŸ”— ê´€ê³„ ìœ í˜• ë¶„í¬")
            display_relationship_distribution(network_data)
            
            # ê°ì • ë¶„ì„ ê²°ê³¼
            st.markdown("### ğŸ˜Š ê°ì • ë¶„ì„")
            display_sentiment_analysis(network_data)
        
        else:
            st.markdown("### ğŸ“‹ ë¶„ì„ ëŒ€ê¸° ì¤‘")
            st.info("ë„¤íŠ¸ì›Œí¬ ë¶„ì„ì„ ì‹¤í–‰í•˜ë©´ ì—¬ê¸°ì— ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
            
            # ê°œì„  ì‚¬í•­ ì„¤ëª…
            st.markdown("### âœ¨ ê°œì„ ëœ ê¸°ëŠ¥")
            st.markdown("""
            **ğŸš€ ì£¼ìš” ê°œì„ ì‚¬í•­:**
            - **50+ ë…¸ë“œ**: 16ê°œ ê²½ì œ ì¹´í…Œê³ ë¦¬ Ã— ë‹¤ì–‘í•œ ì„¸ë¶€ ê°œë…
            - **ì˜ë¯¸ ìˆëŠ” ê´€ê³„**: ë‹¨ìˆœ ë™ì‹œì¶œí˜„ â†’ ê²½ì œì  ì—°ê´€ì„±
            - **ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ**: ê°œë… ì¤‘ìš”ë„ ë° ê´€ê³„ ê°•ë„ ë°˜ì˜
            - **ê°ì • ë¶„ì„**: ê°œë…ë³„ ê¸ì •/ë¶€ì • ê°ì • ë¶„ì„
            - **ì‹œê°„ì  ë¶„ì„**: íŠ¸ë Œë“œ ë³€í™” ì¶”ì 
            - **ì¸í„°ë™í‹°ë¸Œ**: ì‹¤ì‹œê°„ í•„í„°ë§ ë° íƒìƒ‰
            """)

@st.cache_data(ttl=300)
def run_enhanced_network_analysis(data_source: str, min_edge_weight: float, max_nodes: int) -> dict:
    """ê°œì„ ëœ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì‹¤í–‰"""
    
    analyzer = EnhancedEconomicNetworkAnalyzer()
    
    try:
        # í†µí•© ì†Œì…œ ë°ì´í„° ìˆ˜ì§‘ê¸° ì‚¬ìš©
        from data_monitoring.integrated_social_collector import IntegratedSocialCollector
        
        collector = IntegratedSocialCollector()
        
        # ë°ì´í„° ì†ŒìŠ¤ ë§¤í•‘
        source_mapping = {
            "ìë™ ì„ íƒ": "auto",
            "Reddit ì „ìš©": "reddit_only", 
            "ë¬´ë£Œ ëŒ€ì•ˆ (Reddit+Nitter)": "free_alternatives",
            "ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°": "simulation"
        }
        
        mapped_source = source_mapping.get(data_source, "simulation")
        
        # ì‹¤ì œ ì†Œì…œ ë°ì´í„° ìˆ˜ì§‘
        sample_texts = collector.collect_social_data_for_network_analysis(
            data_source=mapped_source,
            max_items=50
        )
        
        # ë°±ì—…: ìƒ˜í”Œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ìƒ˜í”Œ ì‚¬ìš©
        if not sample_texts:
            sample_texts = generate_sample_economic_texts("ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°")
        
    except Exception as e:
        st.warning(f"âš ï¸ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        # ë°±ì—…: ê¸°ë³¸ ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©
        sample_texts = generate_sample_economic_texts(data_source)
    
    try:
        # ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì‹¤í–‰
        network_result = analyzer.analyze_concept_relationships(sample_texts)
        
        # ë…¸ë“œ ìˆ˜ ì œí•œ
        if network_result.get('graph') and len(network_result['graph'].nodes()) > max_nodes:
            # ì¤‘ìš”ë„ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ ë…¸ë“œë§Œ ì„ íƒ
            G = network_result['graph']
            node_scores = [(node, data.get('score', 0)) for node, data in G.nodes(data=True)]
            top_nodes = sorted(node_scores, key=lambda x: x[1], reverse=True)[:max_nodes]
            top_node_names = [node for node, _ in top_nodes]
            
            # ì„œë¸Œê·¸ë˜í”„ ìƒì„±
            subG = G.subgraph(top_node_names).copy()
            network_result['graph'] = subG
            network_result['node_count'] = len(subG.nodes())
            network_result['edge_count'] = len(subG.edges())
        
        # ë°ì´í„° ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€
        network_result['data_source'] = data_source
        network_result['text_count'] = len(sample_texts)
        
        return network_result
        
    except Exception as e:
        return {'error': str(e), 'data_source': data_source}

def generate_sample_economic_texts(data_source: str) -> list:
    """ë°ì´í„° ì†ŒìŠ¤ë³„ ìƒ˜í”Œ í…ìŠ¤íŠ¸ ìƒì„±"""
    
    if data_source == "ìƒ˜í”Œ ê²½ì œ ë‰´ìŠ¤":
        return [
            "ì—°ì¤€ì´ ê¸°ì¤€ê¸ˆë¦¬ë¥¼ 0.25%p ì¸ìƒí•˜ë©° ì¸í”Œë ˆì´ì…˜ ì–µì œì— ë‚˜ì„°ë‹¤. ì´ë²ˆ ê¸ˆë¦¬ ì¸ìƒìœ¼ë¡œ ì£¼ì‹ì‹œì¥ì€ í•˜ë½ì„¸ë¥¼ ë³´ì´ê³  ìˆìœ¼ë©°, íŠ¹íˆ ê¸°ìˆ ì£¼ê°€ í° íƒ€ê²©ì„ ë°›ê³  ìˆë‹¤.",
            "ì• í”Œê³¼ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ê°€ AI ê¸°ìˆ  ê°œë°œì„ ìœ„í•œ íŒŒíŠ¸ë„ˆì‹­ì„ ë°œí‘œí–ˆë‹¤. ì´ëŠ” ê¸°ìˆ  ì„¹í„°ì˜ ê²½ìŸë ¥ ê°•í™”ì™€ í•¨ê»˜ ê´€ë ¨ ì£¼ê°€ ìƒìŠ¹ì„ ì´ëŒê³  ìˆë‹¤.",
            "ì¤‘êµ­ê³¼ ë¯¸êµ­ ê°„ì˜ ë¬´ì—­ ë¶„ìŸì´ ì¬ì í™”ë˜ë©´ì„œ ê¸€ë¡œë²Œ ê³µê¸‰ë§ì— ì°¨ì§ˆì´ ìš°ë ¤ëœë‹¤. ì´ë¡œ ì¸í•´ ì›ìì¬ ê°€ê²©ì´ ìƒìŠ¹í•˜ê³  ì¸í”Œë ˆì´ì…˜ ì••ë ¥ì´ ì¦ê°€í•˜ê³  ìˆë‹¤.",
            "ë¹„íŠ¸ì½”ì¸ì´ ë‹¤ì‹œ 5ë§Œ ë‹¬ëŸ¬ë¥¼ ëŒíŒŒí•˜ë©° ì•”í˜¸í™”í ì‹œì¥ì´ í™œê¸°ë¥¼ ë ê³  ìˆë‹¤. ê¸°ê´€ íˆ¬ììë“¤ì˜ ê´€ì‹¬ ì¦ê°€ì™€ í•¨ê»˜ ë””ì§€í„¸ ìì‚°ì— ëŒ€í•œ íˆ¬ì ì‹¬ë¦¬ê°€ ê°œì„ ë˜ê³  ìˆë‹¤.",
            "ESG íˆ¬ìê°€ ì£¼ë¥˜ë¡œ ìë¦¬ì¡ìœ¼ë©´ì„œ ì¹œí™˜ê²½ ê¸°ì—…ë“¤ì˜ ì£¼ê°€ê°€ ìƒìŠ¹í•˜ê³  ìˆë‹¤. íŠ¹íˆ ì¬ìƒì—ë„ˆì§€ì™€ ì „ê¸°ì°¨ ê´€ë ¨ ê¸°ì—…ë“¤ì´ í° ê´€ì‹¬ì„ ë°›ê³  ìˆë‹¤.",
            "ê³ ìš©ì‹œì¥ì´ ê°œì„ ë˜ë©´ì„œ ì‹¤ì—…ë¥ ì´ 3.5%ë¡œ í•˜ë½í–ˆë‹¤. ì´ëŠ” ì†Œë¹„ì ì‹ ë¢°ë„ ìƒìŠ¹ê³¼ í•¨ê»˜ ì†Œë¹„ ì¦ê°€ë¡œ ì´ì–´ì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.",
            "ë¶€ë™ì‚° ì‹œì¥ì´ ê¸ˆë¦¬ ì¸ìƒì—ë„ ë¶ˆêµ¬í•˜ê³  ê²¬ì¡°í•œ ëª¨ìŠµì„ ë³´ì´ê³  ìˆë‹¤. ì£¼íƒ ê³µê¸‰ ë¶€ì¡±ê³¼ í•¨ê»˜ ê°€ê²© ìƒìŠ¹ ì••ë ¥ì´ ì§€ì†ë˜ê³  ìˆë‹¤.",
            "ì—ë„ˆì§€ ê°€ê²© ìƒìŠ¹ìœ¼ë¡œ ì¸í”Œë ˆì´ì…˜ ìš°ë ¤ê°€ ì»¤ì§€ê³  ìˆë‹¤. íŠ¹íˆ ì›ìœ ì™€ ì²œì—°ê°€ìŠ¤ ê°€ê²© ê¸‰ë“±ì´ ì „ì²´ ë¬¼ê°€ ìƒìŠ¹ì„ ì£¼ë„í•˜ê³  ìˆë‹¤.",
            "ì •ë¶€ì˜ ëŒ€ê·œëª¨ ì¸í”„ë¼ íˆ¬ì ê³„íšì´ ë°œí‘œë˜ë©´ì„œ ê±´ì„¤ ë° ì†Œì¬ ê´€ë ¨ ì£¼ì‹ë“¤ì´ ê°•ì„¸ë¥¼ ë³´ì´ê³  ìˆë‹¤. ì´ëŠ” ê²½ê¸° ë¶€ì–‘ íš¨ê³¼ì™€ í•¨ê»˜ ê³ ìš© ì°½ì¶œì—ë„ ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.",
            "ì§€ì •í•™ì  ë¦¬ìŠ¤í¬ê°€ ì¦ê°€í•˜ë©´ì„œ ì•ˆì „ìì‚° ì„ í˜¸ í˜„ìƒì´ ë‚˜íƒ€ë‚˜ê³  ìˆë‹¤. ê¸ˆê³¼ êµ­ì±„ ê°€ê²©ì´ ìƒìŠ¹í•˜ëŠ” ë°˜ë©´, ìœ„í—˜ìì‚°ì¸ ì£¼ì‹ì€ ë³€ë™ì„±ì´ í™•ëŒ€ë˜ê³  ìˆë‹¤."
        ]
    
    elif data_source == "Reddit ëŒ“ê¸€":
        return [
            "Fedê°€ ë˜ ê¸ˆë¦¬ ì˜¬ë ¸ë„¤... ë‚´ ì£¼ì‹ í¬íŠ¸í´ë¦¬ì˜¤ê°€ ê±±ì •ëœë‹¤. íŠ¹íˆ í…Œí¬ì£¼ë“¤ì´ ë§ì´ ë–¨ì–´ì¡Œì–´.",
            "ì¸í”Œë ˆì´ì…˜ì´ ì´ë ‡ê²Œ ê³„ì† ì˜¤ë¥´ë©´ ìƒí™œë¹„ê°€ ë„ˆë¬´ ë¶€ë‹´ìŠ¤ëŸ¬ì›Œ. ì •ë¶€ê°€ ë­”ê°€ ëŒ€ì±…ì„ ë‚´ë†”ì•¼ í•  ê²ƒ ê°™ì€ë°.",
            "ë¹„íŠ¸ì½”ì¸ ë‹¤ì‹œ ì˜¤ë¥´ê¸° ì‹œì‘í–ˆë„¤! ì´ë²ˆì—” ì§„ì§œ 10ë§Œ ë‹¬ëŸ¬ê¹Œì§€ ê°ˆ ìˆ˜ ìˆì„ê¹Œ?",
            "ESG íˆ¬ìê°€ íŠ¸ë Œë“œë¼ê³  í•˜ëŠ”ë°, ì •ë§ ìˆ˜ìµì„±ì´ ìˆì„ê¹Œ? ì•„ì§ í™•ì‹ ì´ ì•ˆ ì„œë„¤.",
            "ì• í”Œ ì‹¤ì  ë°œí‘œ ì•ë‘ê³  ìˆëŠ”ë°, ì´ë²ˆ ë¶„ê¸°ëŠ” ì–´ë–¨ê¹Œ? iPhone íŒë§¤ëŸ‰ì´ ê´€ê±´ì¼ ê²ƒ ê°™ì•„.",
            "ì¤‘êµ­ ê²½ì œê°€ ë‘”í™”ë˜ê³  ìˆë‹¤ëŠ” ë‰´ìŠ¤ê°€ ë§ì´ ë‚˜ì˜¤ëŠ”ë°, ìš°ë¦¬ë‚˜ë¼ ê²½ì œì—ë„ ì˜í–¥ì´ í´ ê²ƒ ê°™ì•„.",
            "ë¶€ë™ì‚° ê°€ê²©ì´ ê³„ì† ì˜¤ë¥´ê³  ìˆì–´ì„œ ì§‘ ì‚¬ê¸°ê°€ ë„ˆë¬´ ì–´ë ¤ì›Œì¡Œì–´. ì–¸ì œì¯¤ ì•ˆì •ë ê¹Œ?",
            "ì—ë„ˆì§€ ì£¼ì‹ë“¤ì´ ìš”ì¦˜ ì¢‹ì€ ê²ƒ ê°™ì€ë°, ì¥ê¸°ì ìœ¼ë¡œ íˆ¬ìí•´ë³¼ ë§Œí• ê¹Œ?",
            "ì‹¤ì—…ë¥ ì´ ë‚®ì•„ì¡Œë‹¤ê³  í•˜ëŠ”ë°, ì²´ê°ìƒìœ¼ë¡œëŠ” ì·¨ì—…ì´ ì—¬ì „íˆ ì–´ë ¤ìš´ ê²ƒ ê°™ì•„.",
            "ì „ìŸ ë•Œë¬¸ì— ì‹œì¥ì´ ë¶ˆì•ˆì •í•´. ì•ˆì „ìì‚°ìœ¼ë¡œ ê°ˆì•„íƒ€ì•¼ í•  ì‹œì ì¸ê°€?"
        ]
    
    elif data_source == "Twitter ë°ì´í„°":
        return [
            "#Fed #ê¸ˆë¦¬ì¸ìƒ ë˜ ì‹œì‘ëë„¤. #ì¸í”Œë ˆì´ì…˜ ì¡ìœ¼ë ¤ë‹¤ #ê²½ê¸°ì¹¨ì²´ ì˜¬ ìˆ˜ë„ ìˆê² ì–´ #ì£¼ì‹ì‹œì¥",
            "#Apple #AI íŒŒíŠ¸ë„ˆì‹­ ì†Œì‹ì— ì£¼ê°€ ê¸‰ë“±! #ê¸°ìˆ ì£¼ #íˆ¬ì ê¸°íšŒì¼ê¹Œ? #AAPL",
            "#Bitcoin 5ë§Œë‹¬ëŸ¬ ëŒíŒŒ! #ì•”í˜¸í™”í #ë¶ˆë§ˆì¼“ ë‹¤ì‹œ ì‹œì‘ë˜ë‚˜? #BTC #íˆ¬ì",
            "#ESGíˆ¬ì ì—´í’ ì†ì—ì„œ #ì¹œí™˜ê²½ ê¸°ì—…ë“¤ ì£¼ëª©ë°›ê³  ìˆì–´ #ì§€ì†ê°€ëŠ¥íˆ¬ì #ê·¸ë¦°ì—ë„ˆì§€",
            "#ë¬´ì—­ì „ìŸ ì¬ì í™”? #ì¤‘ë¯¸ê´€ê³„ ì•…í™”ë¡œ #ê³µê¸‰ë§ ì°¨ì§ˆ ìš°ë ¤ #ê¸€ë¡œë²Œê²½ì œ",
            "#ê³ ìš©ì‹œì¥ ê°œì„ ìœ¼ë¡œ #ì†Œë¹„ì‹¬ë¦¬ íšŒë³µ ê¸°ëŒ€ #ì‹¤ì—…ë¥  í•˜ë½ #ê²½ê¸°íšŒë³µ",
            "#ë¶€ë™ì‚° ê°€ê²© ì—¬ì „íˆ ìƒìŠ¹ì„¸ #ê¸ˆë¦¬ì¸ìƒì—ë„ ë¶ˆêµ¬í•˜ê³  #ì£¼íƒì‹œì¥ ê²¬ì¡°",
            "#ì—ë„ˆì§€ê°€ê²© ê¸‰ë“±ìœ¼ë¡œ #ì¸í”Œë ˆì´ì…˜ ì••ë ¥ ì¦ê°€ #ì›ìœ  #ì²œì—°ê°€ìŠ¤",
            "#ì •ë¶€ #ì¸í”„ë¼íˆ¬ì ê³„íš ë°œí‘œ #ê±´ì„¤ì£¼ #ì†Œì¬ì£¼ ê´€ì‹¬ ì¦ê°€",
            "#ì§€ì •í•™ì ë¦¬ìŠ¤í¬ ì¦ê°€ë¡œ #ì•ˆì „ìì‚° ì„ í˜¸ #ê¸ˆ #êµ­ì±„ ê°€ê²© ìƒìŠ¹"
        ]
    
    else:  # ë‰´ìŠ¤ ëŒ“ê¸€
        return [
            "ê¸ˆë¦¬ ì¸ìƒì´ ê³„ì†ë˜ë©´ ì„œë¯¼ë“¤ ëŒ€ì¶œ ë¶€ë‹´ë§Œ ëŠ˜ì–´ë‚  í…ë°... ì •ì±… ë‹¹êµ­ì´ ì¢€ ë” ì‹ ì¤‘í•˜ê²Œ ì ‘ê·¼í–ˆìœ¼ë©´ ì¢‹ê² ì–´ìš”.",
            "ê¸°ìˆ ì£¼ íˆ¬ìí–ˆë‹¤ê°€ í° ì†ì‹¤ ë´¤ìŠµë‹ˆë‹¤. ì•ìœ¼ë¡œëŠ” ì¢€ ë” ì•ˆì •ì ì¸ íˆ¬ìì²˜ë¥¼ ì°¾ì•„ì•¼ê² ì–´ìš”.",
            "ì¸í”Œë ˆì´ì…˜ ë•Œë¬¸ì— ì¥ë³´ê¸°ê°€ ë¶€ë‹´ìŠ¤ëŸ¬ì›Œì¡Œì–´ìš”. íŠ¹íˆ ì‹ë£Œí’ˆ ê°€ê²©ì´ ë„ˆë¬´ ë§ì´ ì˜¬ëë„¤ìš”.",
            "ì•”í˜¸í™”í íˆ¬ìëŠ” ì—¬ì „íˆ ìœ„í—˜í•˜ë‹¤ê³  ìƒê°í•´ìš”. ë³€ë™ì„±ì´ ë„ˆë¬´ ì»¤ì„œ ì¼ë°˜ì¸ë“¤ì´ ì ‘ê·¼í•˜ê¸° ì–´ë ¤ì›Œìš”.",
            "ESG íˆ¬ìê°€ ì¢‹ë‹¤ê³ ëŠ” í•˜ëŠ”ë°, ì‹¤ì œë¡œ ìˆ˜ìµë¥ ì´ ì–´ë–¤ì§€ ê¶ê¸ˆí•˜ë„¤ìš”. ì¥ê¸°ì ìœ¼ë¡œëŠ” ì¢‹ì„ ê²ƒ ê°™ê¸´ í•´ìš”.",
            "ê³ ìš©ì‹œì¥ì´ ì¢‹ì•„ì¡Œë‹¤ê³  í•˜ì§€ë§Œ, ì²­ë…„ ì·¨ì—…ì€ ì—¬ì „íˆ ì–´ë ¤ìš´ ê²ƒ ê°™ì•„ìš”. ì–‘ì§ˆì˜ ì¼ìë¦¬ê°€ ë¶€ì¡±í•´ìš”.",
            "ë¶€ë™ì‚° íˆ¬ìëŠ” ì´ì œ ì¼ë°˜ì¸ë“¤ì´ ì ‘ê·¼í•˜ê¸° ì–´ë ¤ìš´ ìˆ˜ì¤€ì´ ëœ ê²ƒ ê°™ì•„ìš”. ì •ë¶€ ëŒ€ì±…ì´ í•„ìš”í•´ìš”.",
            "ì—ë„ˆì§€ ê°€ê²© ìƒìŠ¹ì´ ëª¨ë“  ë¬¼ê°€ì— ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆì–´ìš”. ëŒ€ì²´ ì—ë„ˆì§€ ê°œë°œì´ ì‹œê¸‰í•´ ë³´ì—¬ìš”.",
            "ì •ë¶€ì˜ ê²½ê¸° ë¶€ì–‘ì±…ì´ íš¨ê³¼ê°€ ìˆì„ì§€ ì˜ë¬¸ì´ì—ìš”. ê·¼ë³¸ì ì¸ êµ¬ì¡° ê°œì„ ì´ í•„ìš”í•œ ê²ƒ ê°™ì•„ìš”.",
            "êµ­ì œ ì •ì„¸ê°€ ë¶ˆì•ˆí•´ì„œ íˆ¬ìí•˜ê¸°ê°€ ì¡°ì‹¬ìŠ¤ëŸ¬ì›Œìš”. ë‹¹ë¶„ê°„ì€ í˜„ê¸ˆ ë³´ìœ  ë¹„ì¤‘ì„ ëŠ˜ë ¤ì•¼ê² ì–´ìš”."
        ]

def create_enhanced_network_visualization(network_data: dict, layout_type: str, min_edge_weight: float):
    """ê°œì„ ëœ ë„¤íŠ¸ì›Œí¬ ì‹œê°í™” ìƒì„±"""
    
    G = network_data['graph']
    
    if len(G.nodes()) == 0:
        # ë¹ˆ ê·¸ë˜í”„ ì²˜ë¦¬
        fig = go.Figure()
        fig.add_annotation(text="ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤", 
                          xref="paper", yref="paper",
                          x=0.5, y=0.5, showarrow=False)
        return fig
    
    # ë ˆì´ì•„ì›ƒ ê³„ì‚°
    if layout_type == "spring":
        pos = nx.spring_layout(G, k=3, iterations=50)
    elif layout_type == "circular":
        pos = nx.circular_layout(G)
    elif layout_type == "kamada_kawai":
        pos = nx.kamada_kawai_layout(G)
    else:  # random
        pos = nx.random_layout(G)
    
    # ì—£ì§€ íŠ¸ë ˆì´ìŠ¤ ìƒì„±
    edge_x = []
    edge_y = []
    edge_info = []
    
    for edge in G.edges(data=True):
        if edge[2].get('weight', 0) >= min_edge_weight:
            x0, y0 = pos[edge[0]]
            x1, y1 = pos[edge[1]]
            edge_x.extend([x0, x1, None])
            edge_y.extend([y0, y1, None])
            
            weight = edge[2].get('weight', 0)
            rel_type = edge[2].get('relationship_type', 'related')
            edge_info.append(f"{edge[0]} â†” {edge[1]}<br>ê°•ë„: {weight:.2f}<br>ìœ í˜•: {rel_type}")
    
    edge_trace = go.Scatter(x=edge_x, y=edge_y,
                           line=dict(width=0.5, color='#888'),
                           hoverinfo='none',
                           mode='lines')
    
    # ë…¸ë“œ íŠ¸ë ˆì´ìŠ¤ ìƒì„±
    node_x = []
    node_y = []
    node_text = []
    node_info = []
    node_size = []
    node_color = []
    
    # ì¹´í…Œê³ ë¦¬ë³„ ìƒ‰ìƒ ë§¤í•‘
    category_colors = {
        'monetary_policy': '#FF6B6B',      # ë¹¨ê°•
        'inflation': '#4ECDC4',           # ì²­ë¡
        'stock_market': '#45B7D1',        # íŒŒë‘
        'corporate_performance': '#96CEB4', # ì—°ë‘
        'technology': '#FFEAA7',          # ë…¸ë‘
        'financial_sector': '#DDA0DD',     # ë³´ë¼
        'energy': '#FFA07A',              # ì£¼í™©
        'real_estate': '#98D8C8',         # ë¯¼íŠ¸
        'international_trade': '#F7DC6F', # ì—°ë…¸ë‘
        'cryptocurrency': '#BB8FCE',       # ì—°ë³´ë¼
        'esg': '#85C1E9',                 # ì—°íŒŒë‘
        'labor_market': '#F8C471',        # ì—°ì£¼í™©
        'consumer_spending': '#82E0AA',    # ì—°ì´ˆë¡
        'government_policy': '#F1948A',    # ì—°ë¹¨ê°•
        'geopolitical_risk': '#D7DBDD',    # íšŒìƒ‰
        'market_sentiment': '#AED6F1'      # í•˜ëŠ˜ìƒ‰
    }
    
    for node in G.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        
        # ë…¸ë“œ ì •ë³´
        node_data = G.nodes[node]
        score = node_data.get('score', 0)
        mentions = node_data.get('mentions', 0)
        sentiment = node_data.get('sentiment', 0)
        terms = node_data.get('terms', [])
        
        # í‘œì‹œ ì´ë¦„
        analyzer = EnhancedEconomicNetworkAnalyzer()
        display_name = analyzer._get_concept_display_name(node)
        node_text.append(display_name)
        
        # í˜¸ë²„ ì •ë³´
        sentiment_emoji = "ğŸ˜Š" if sentiment > 0.1 else "ğŸ˜Ÿ" if sentiment < -0.1 else "ğŸ˜"
        info = f"<b>{display_name}</b><br>"
        info += f"ì ìˆ˜: {score:.1f}<br>"
        info += f"ì–¸ê¸‰ íšŸìˆ˜: {mentions}<br>"
        info += f"ê°ì •: {sentiment_emoji} ({sentiment:.2f})<br>"
        info += f"ê´€ë ¨ ìš©ì–´: {', '.join(terms[:3])}"
        node_info.append(info)
        
        # ë…¸ë“œ í¬ê¸° (ì ìˆ˜ ê¸°ë°˜)
        size = max(10, min(score * 5, 50))
        node_size.append(size)
        
        # ë…¸ë“œ ìƒ‰ìƒ (ì¹´í…Œê³ ë¦¬ ê¸°ë°˜)
        color = category_colors.get(node, '#888888')
        node_color.append(color)
    
    node_trace = go.Scatter(x=node_x, y=node_y,
                           mode='markers+text',
                           hoverinfo='text',
                           text=node_text,
                           hovertext=node_info,
                           textposition="middle center",
                           marker=dict(size=node_size,
                                     color=node_color,
                                     line=dict(width=2, color='white')))
    
    # ê·¸ë˜í”„ ìƒì„±
    fig = go.Figure(data=[edge_trace, node_trace],
                   layout=go.Layout(
                        title=dict(
                            text=f'ê²½ì œ ê°œë… ë„¤íŠ¸ì›Œí¬ ({len(G.nodes())}ê°œ ë…¸ë“œ, {len(G.edges())}ê°œ ì—°ê²°)',
                            font=dict(size=16)
                        ),
                        showlegend=False,
                        hovermode='closest',
                        margin=dict(b=20,l=5,r=5,t=40),
                        annotations=[ dict(
                            text="ë…¸ë“œ í¬ê¸°: ì¤‘ìš”ë„ | ìƒ‰ìƒ: ê²½ì œ ì¹´í…Œê³ ë¦¬",
                            showarrow=False,
                            xref="paper", yref="paper",
                            x=0.005, y=-0.002,
                            xanchor='left', yanchor='bottom',
                            font=dict(size=12)
                        )],
                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                        height=600))
    
    return fig

def display_sample_network():
    """ìƒ˜í”Œ ë„¤íŠ¸ì›Œí¬ í‘œì‹œ"""
    st.info("ğŸ¯ **ê°œì„ ëœ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ì˜ íŠ¹ì§•:**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **ğŸ“ˆ ë” ë§ì€ ë…¸ë“œ:**
        - 16ê°œ ì£¼ìš” ê²½ì œ ì¹´í…Œê³ ë¦¬
        - ê° ì¹´í…Œê³ ë¦¬ë³„ 10-20ê°œ ì„¸ë¶€ ê°œë…
        - ì´ 50-100ê°œ ë…¸ë“œ ìƒì„± ê°€ëŠ¥
        
        **ğŸ”— ì˜ë¯¸ ìˆëŠ” ê´€ê³„:**
        - ê²½ì œì  ì¸ê³¼ê´€ê³„ ë¶„ì„
        - ìƒê´€ê´€ê³„ vs ì—­ìƒê´€ê´€ê³„ êµ¬ë¶„
        - ì‹œê°„ì  ì„ í›„ê´€ê³„ ê³ ë ¤
        """)
    
    with col2:
        st.markdown("""
        **ğŸ¨ í–¥ìƒëœ ì‹œê°í™”:**
        - ì¹´í…Œê³ ë¦¬ë³„ ìƒ‰ìƒ êµ¬ë¶„
        - ì¤‘ìš”ë„ ê¸°ë°˜ ë…¸ë“œ í¬ê¸°
        - ê´€ê³„ ê°•ë„ë³„ ì—°ê²°ì„  êµµê¸°
        
        **ğŸ“Š ê³ ê¸‰ ë¶„ì„:**
        - ê°ì • ë¶„ì„ í†µí•©
        - ë„¤íŠ¸ì›Œí¬ ì¤‘ì‹¬ì„± ì§€í‘œ
        - ì‹¤ì‹œê°„ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        """)

def display_network_metrics(network_data: dict):
    """ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­ í‘œì‹œ"""
    metrics = network_data.get('metrics', {})
    
    if not metrics:
        return
    
    st.markdown("### ğŸ“Š ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ë…¸ë“œ ìˆ˜", network_data.get('node_count', 0))
    
    with col2:
        st.metric("ì—°ê²° ìˆ˜", network_data.get('edge_count', 0))
    
    with col3:
        density = metrics.get('density', 0)
        st.metric("ë„¤íŠ¸ì›Œí¬ ë°€ë„", f"{density:.3f}")
    
    with col4:
        clustering = metrics.get('average_clustering', 0)
        st.metric("í‰ê·  í´ëŸ¬ìŠ¤í„°ë§", f"{clustering:.3f}")

def display_top_concepts(network_data: dict):
    """ìƒìœ„ ê°œë…ë“¤ í‘œì‹œ"""
    metrics = network_data.get('metrics', {})
    
    if 'top_nodes' in metrics:
        top_by_degree = metrics['top_nodes'].get('by_degree', [])
        
        if top_by_degree:
            analyzer = EnhancedEconomicNetworkAnalyzer()
            
            for i, (concept, centrality) in enumerate(top_by_degree[:5], 1):
                display_name = analyzer._get_concept_display_name(concept)
                st.markdown(f"{i}. **{display_name}** (ì¤‘ì‹¬ì„±: {centrality:.3f})")

def display_relationship_distribution(network_data: dict):
    """ê´€ê³„ ìœ í˜• ë¶„í¬ í‘œì‹œ"""
    G = network_data.get('graph')
    
    if not G:
        return
    
    # ê´€ê³„ ìœ í˜• ì§‘ê³„
    relationship_counts = {}
    for _, _, data in G.edges(data=True):
        rel_type = data.get('relationship_type', 'unknown')
        relationship_counts[rel_type] = relationship_counts.get(rel_type, 0) + 1
    
    if relationship_counts:
        # íŒŒì´ ì°¨íŠ¸ ìƒì„±
        fig = px.pie(
            values=list(relationship_counts.values()),
            names=list(relationship_counts.keys()),
            title="ê´€ê³„ ìœ í˜• ë¶„í¬"
        )
        st.plotly_chart(fig, use_container_width=True)

def display_sentiment_analysis(network_data: dict):
    """ê°ì • ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    concept_sentiments = network_data.get('concept_sentiments', {})
    
    if not concept_sentiments:
        st.info("ê°ì • ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê°ì • ì ìˆ˜ ê³„ì‚°
    sentiment_data = []
    analyzer = EnhancedEconomicNetworkAnalyzer()
    
    for concept, sentiments in concept_sentiments.items():
        if sentiments:
            avg_sentiment = np.mean(sentiments)
            display_name = analyzer._get_concept_display_name(concept)
            sentiment_data.append({
                'concept': display_name,
                'sentiment': avg_sentiment,
                'emoji': "ğŸ˜Š" if avg_sentiment > 0.1 else "ğŸ˜Ÿ" if avg_sentiment < -0.1 else "ğŸ˜"
            })
    
    # ê°ì •ë³„ë¡œ ì •ë ¬
    sentiment_data.sort(key=lambda x: x['sentiment'], reverse=True)
    
    # ìƒìœ„ 5ê°œ í‘œì‹œ
    for data in sentiment_data[:5]:
        sentiment_color = "green" if data['sentiment'] > 0 else "red" if data['sentiment'] < 0 else "gray"
        st.markdown(f"{data['emoji']} **{data['concept']}**: "
                   f"<span style='color: {sentiment_color}'>{data['sentiment']:.3f}</span>", 
                   unsafe_allow_html=True)

if __name__ == "__main__":
    create_enhanced_network_page()
