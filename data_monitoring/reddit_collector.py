#!/usr/bin/env python3
"""
Reddit ê²½ì œ ë°ì´í„° ìˆ˜ì§‘ê¸°
"""

import os
import praw
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from textblob import TextBlob
import time
import re

class RedditEconomicCollector:
    """Reddit ê²½ì œ ê´€ë ¨ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        """Reddit API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        self.logger = logging.getLogger(__name__)
        
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ Reddit ìžê²©ì¦ëª… ë¡œë“œ
        self.client_id = os.getenv('REDDIT_CLIENT_ID')
        self.client_secret = os.getenv('REDDIT_CLIENT_SECRET')
        self.user_agent = os.getenv('REDDIT_USER_AGENT', 'EconomicNewsBot/1.0')
        
        if not self.client_id or not self.client_secret:
            raise ValueError("Reddit API ìžê²©ì¦ëª…ì´ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Reddit í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            self.reddit = praw.Reddit(
                client_id=self.client_id,
                client_secret=self.client_secret,
                user_agent=self.user_agent
            )
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            self.reddit.user.me()  # ì¸ì¦ í…ŒìŠ¤íŠ¸
            self.logger.info(f"âœ… Reddit API ì—°ê²° ì„±ê³µ")
            
        except Exception as e:
            self.logger.error(f"âŒ Reddit API ì—°ê²° ì‹¤íŒ¨: {e}")
            # ì½ê¸° ì „ìš© ëª¨ë“œë¡œ ì‹œë„
            try:
                self.reddit = praw.Reddit(
                    client_id=self.client_id,
                    client_secret=self.client_secret,
                    user_agent=self.user_agent
                )
                self.logger.info("âœ… Reddit API ì½ê¸° ì „ìš© ëª¨ë“œë¡œ ì—°ê²°")
            except Exception as e2:
                self.logger.error(f"âŒ Reddit API ì½ê¸° ì „ìš© ì—°ê²°ë„ ì‹¤íŒ¨: {e2}")
                raise
        
        # ê²½ì œ ê´€ë ¨ ì„œë¸Œë ˆë”§ ëª©ë¡
        self.economic_subreddits = [
            'investing',
            'stocks',
            'economics',
            'SecurityAnalysis',
            'ValueInvesting',
            'financialindependence',
            'personalfinance',
            'StockMarket',
            'wallstreetbets',
            'economy',
            'finance',
            'business',
            'entrepreneur',
            'cryptocurrency',
            'Bitcoin'
        ]
        
        # ê²½ì œ ê´€ë ¨ í‚¤ì›Œë“œ
        self.economic_keywords = [
            'fed', 'federal reserve', 'interest rate', 'inflation', 'recession',
            'gdp', 'unemployment', 'stock market', 'nasdaq', 'sp500', 'dow jones',
            'earnings', 'revenue', 'profit', 'loss', 'merger', 'acquisition',
            'ipo', 'dividend', 'buyback', 'split', 'volatility', 'bull market',
            'bear market', 'correction', 'crash', 'rally', 'bubble'
        ]
        
        self.logger.info(f"ðŸ”§ Reddit ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def collect_subreddit_posts(self, subreddit_name: str, limit: int = 25, time_filter: str = 'day') -> List[Dict[str, Any]]:
        """íŠ¹ì • ì„œë¸Œë ˆë”§ì—ì„œ í¬ìŠ¤íŠ¸ ìˆ˜ì§‘"""
        try:
            subreddit = self.reddit.subreddit(subreddit_name)
            posts = []
            
            # ì¸ê¸° í¬ìŠ¤íŠ¸ ìˆ˜ì§‘ (hot, new, top ì¤‘ ì„ íƒ)
            if time_filter == 'day':
                submissions = subreddit.hot(limit=limit)
            elif time_filter == 'week':
                submissions = subreddit.top(time_filter='week', limit=limit)
            else:
                submissions = subreddit.new(limit=limit)
            
            for submission in submissions:
                # ê²½ì œ ê´€ë ¨ í‚¤ì›Œë“œ í•„í„°ë§
                if self._is_economic_content(submission.title + " " + submission.selftext):
                    post_data = {
                        'id': submission.id,
                        'title': submission.title,
                        'selftext': submission.selftext,
                        'score': submission.score,
                        'upvote_ratio': submission.upvote_ratio,
                        'num_comments': submission.num_comments,
                        'created_utc': submission.created_utc,
                        'created_datetime': datetime.fromtimestamp(submission.created_utc),
                        'author': str(submission.author) if submission.author else '[deleted]',
                        'subreddit': subreddit_name,
                        'url': submission.url,
                        'permalink': f"https://reddit.com{submission.permalink}",
                        'flair': submission.link_flair_text,
                        'is_self': submission.is_self,
                        'sentiment': self._analyze_sentiment(submission.title + " " + submission.selftext),
                        'economic_topics': self._extract_economic_topics(submission.title + " " + submission.selftext)
                    }
                    posts.append(post_data)
            
            self.logger.info(f"âœ… r/{subreddit_name}: {len(posts)}ê°œ ê²½ì œ ê´€ë ¨ í¬ìŠ¤íŠ¸ ìˆ˜ì§‘")
            return posts
            
        except Exception as e:
            self.logger.error(f"âŒ r/{subreddit_name} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []
    
    def collect_subreddit_comments(self, subreddit_name: str, post_limit: int = 10, comment_limit: int = 50) -> List[Dict[str, Any]]:
        """íŠ¹ì • ì„œë¸Œë ˆë”§ì˜ ëŒ“ê¸€ ìˆ˜ì§‘"""
        try:
            subreddit = self.reddit.subreddit(subreddit_name)
            comments = []
            
            # ì¸ê¸° í¬ìŠ¤íŠ¸ì˜ ëŒ“ê¸€ ìˆ˜ì§‘
            for submission in subreddit.hot(limit=post_limit):
                if self._is_economic_content(submission.title + " " + submission.selftext):
                    submission.comments.replace_more(limit=0)  # "ë” ë³´ê¸°" ëŒ“ê¸€ ì œì™¸
                    
                    comment_count = 0
                    for comment in submission.comments.list():
                        if comment_count >= comment_limit:
                            break
                        
                        if hasattr(comment, 'body') and len(comment.body) > 20:  # ì˜ë¯¸ìžˆëŠ” ëŒ“ê¸€ë§Œ
                            comment_data = {
                                'id': comment.id,
                                'body': comment.body,
                                'score': comment.score,
                                'created_utc': comment.created_utc,
                                'created_datetime': datetime.fromtimestamp(comment.created_utc),
                                'author': str(comment.author) if comment.author else '[deleted]',
                                'subreddit': subreddit_name,
                                'post_id': submission.id,
                                'post_title': submission.title,
                                'permalink': f"https://reddit.com{comment.permalink}",
                                'sentiment': self._analyze_sentiment(comment.body),
                                'economic_topics': self._extract_economic_topics(comment.body)
                            }
                            comments.append(comment_data)
                            comment_count += 1
            
            self.logger.info(f"âœ… r/{subreddit_name}: {len(comments)}ê°œ ëŒ“ê¸€ ìˆ˜ì§‘")
            return comments
            
        except Exception as e:
            self.logger.error(f"âŒ r/{subreddit_name} ëŒ“ê¸€ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []
    
    def collect_comprehensive_data(self, max_subreddits: int = 8, posts_per_subreddit: int = 15) -> Dict[str, Any]:
        """ì¢…í•©ì ì¸ Reddit ê²½ì œ ë°ì´í„° ìˆ˜ì§‘"""
        self.logger.info("ðŸ”„ Reddit ì¢…í•© ê²½ì œ ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘")
        
        reddit_data = {
            'timestamp': datetime.now().isoformat(),
            'subreddits': {},
            'summary': {},
            'trending_topics': {},
            'sentiment_analysis': {}
        }
        
        all_posts = []
        all_comments = []
        
        # ì£¼ìš” ì„œë¸Œë ˆë”§ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
        for i, subreddit_name in enumerate(self.economic_subreddits[:max_subreddits]):
            try:
                self.logger.info(f"ðŸ“Š r/{subreddit_name} ìˆ˜ì§‘ ì¤‘... ({i+1}/{max_subreddits})")
                
                # í¬ìŠ¤íŠ¸ ìˆ˜ì§‘
                posts = self.collect_subreddit_posts(subreddit_name, limit=posts_per_subreddit)
                
                # ëŒ“ê¸€ ìˆ˜ì§‘ (ìƒìœ„ í¬ìŠ¤íŠ¸ 5ê°œì—ì„œë§Œ)
                comments = self.collect_subreddit_comments(subreddit_name, post_limit=5, comment_limit=20)
                
                reddit_data['subreddits'][subreddit_name] = {
                    'posts': posts,
                    'comments': comments,
                    'post_count': len(posts),
                    'comment_count': len(comments),
                    'avg_score': sum(p['score'] for p in posts) / len(posts) if posts else 0,
                    'avg_sentiment': sum(p['sentiment']['polarity'] for p in posts) / len(posts) if posts else 0
                }
                
                all_posts.extend(posts)
                all_comments.extend(comments)
                
                # Rate limiting
                time.sleep(1)
                
            except Exception as e:
                self.logger.error(f"âŒ r/{subreddit_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        # ì „ì²´ ìš”ì•½ ìƒì„±
        reddit_data['summary'] = self._generate_summary(all_posts, all_comments)
        reddit_data['trending_topics'] = self._extract_trending_topics(all_posts + all_comments)
        reddit_data['sentiment_analysis'] = self._analyze_overall_sentiment(all_posts + all_comments)
        
        self.logger.info(f"âœ… Reddit ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(all_posts)}ê°œ í¬ìŠ¤íŠ¸, {len(all_comments)}ê°œ ëŒ“ê¸€")
        return reddit_data
    
    def _is_economic_content(self, text: str) -> bool:
        """ê²½ì œ ê´€ë ¨ ì½˜í…ì¸ ì¸ì§€ íŒë‹¨"""
        text_lower = text.lower()
        return any(keyword in text_lower for keyword in self.economic_keywords)
    
    def _analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„"""
        try:
            blob = TextBlob(text)
            polarity = blob.sentiment.polarity
            subjectivity = blob.sentiment.subjectivity
            
            if polarity > 0.1:
                label = "positive"
            elif polarity < -0.1:
                label = "negative"
            else:
                label = "neutral"
            
            return {
                'polarity': round(polarity, 3),
                'subjectivity': round(subjectivity, 3),
                'label': label
            }
        except:
            return {'polarity': 0, 'subjectivity': 0, 'label': 'neutral'}
    
    def _extract_economic_topics(self, text: str) -> List[str]:
        """ê²½ì œ ì£¼ì œ ì¶”ì¶œ"""
        text_lower = text.lower()
        topics = []
        
        topic_keywords = {
            'monetary_policy': ['fed', 'federal reserve', 'interest rate', 'monetary policy'],
            'stock_market': ['stock', 'nasdaq', 'sp500', 'dow jones', 'market'],
            'cryptocurrency': ['bitcoin', 'crypto', 'ethereum', 'blockchain'],
            'inflation': ['inflation', 'cpi', 'price increase', 'cost of living'],
            'employment': ['unemployment', 'jobs', 'employment', 'labor'],
            'earnings': ['earnings', 'revenue', 'profit', 'quarterly'],
            'recession': ['recession', 'economic downturn', 'bear market'],
            'investment': ['investing', 'portfolio', 'dividend', 'value investing']
        }
        
        for topic, keywords in topic_keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                topics.append(topic)
        
        return topics
    
    def _generate_summary(self, posts: List[Dict], comments: List[Dict]) -> Dict[str, Any]:
        """ì „ì²´ ìš”ì•½ ìƒì„±"""
        if not posts and not comments:
            return {}
        
        total_posts = len(posts)
        total_comments = len(comments)
        
        # ê°ì • ë¶„ì„
        all_content = posts + comments
        sentiments = [item['sentiment']['label'] for item in all_content]
        
        # ì¸ê¸° ì„œë¸Œë ˆë”§
        subreddit_counts = {}
        for post in posts:
            subreddit = post['subreddit']
            subreddit_counts[subreddit] = subreddit_counts.get(subreddit, 0) + 1
        
        # í‰ê·  ì ìˆ˜
        avg_post_score = sum(p['score'] for p in posts) / len(posts) if posts else 0
        avg_comment_score = sum(c['score'] for c in comments) / len(comments) if comments else 0
        
        return {
            'total_posts': total_posts,
            'total_comments': total_comments,
            'total_content': total_posts + total_comments,
            'avg_post_score': round(avg_post_score, 2),
            'avg_comment_score': round(avg_comment_score, 2),
            'sentiment_distribution': {
                'positive': sentiments.count('positive'),
                'negative': sentiments.count('negative'),
                'neutral': sentiments.count('neutral')
            },
            'top_subreddits': dict(sorted(subreddit_counts.items(), key=lambda x: x[1], reverse=True)[:5]),
            'collection_time': datetime.now().isoformat()
        }
    
    def _extract_trending_topics(self, content: List[Dict]) -> Dict[str, int]:
        """íŠ¸ë Œë”© ì£¼ì œ ì¶”ì¶œ"""
        topic_counts = {}
        
        for item in content:
            topics = item.get('economic_topics', [])
            for topic in topics:
                topic_counts[topic] = topic_counts.get(topic, 0) + 1
        
        # ìƒìœ„ 10ê°œ ì£¼ì œ ë°˜í™˜
        return dict(sorted(topic_counts.items(), key=lambda x: x[1], reverse=True)[:10])
    
    def _analyze_overall_sentiment(self, content: List[Dict]) -> Dict[str, Any]:
        """ì „ì²´ ê°ì • ë¶„ì„"""
        if not content:
            return {}
        
        sentiments = [item['sentiment'] for item in content]
        polarities = [s['polarity'] for s in sentiments]
        
        avg_polarity = sum(polarities) / len(polarities)
        
        # ê°ì • ë¼ë²¨ ë¶„í¬
        labels = [s['label'] for s in sentiments]
        total = len(labels)
        
        return {
            'average_polarity': round(avg_polarity, 3),
            'overall_sentiment': 'positive' if avg_polarity > 0.1 else 'negative' if avg_polarity < -0.1 else 'neutral',
            'distribution': {
                'positive': labels.count('positive'),
                'negative': labels.count('negative'),
                'neutral': labels.count('neutral')
            },
            'percentages': {
                'positive': round(labels.count('positive') / total * 100, 1),
                'negative': round(labels.count('negative') / total * 100, 1),
                'neutral': round(labels.count('neutral') / total * 100, 1)
            }
        }

def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ðŸ“± Reddit ê²½ì œ ë°ì´í„° ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        collector = RedditEconomicCollector()
        
        # ì¢…í•© ë°ì´í„° ìˆ˜ì§‘ (ì†ŒëŸ‰ í…ŒìŠ¤íŠ¸)
        reddit_data = collector.collect_comprehensive_data(max_subreddits=3, posts_per_subreddit=5)
        
        # ê²°ê³¼ ì¶œë ¥
        summary = reddit_data.get('summary', {})
        print(f"\nðŸ“Š ìˆ˜ì§‘ ê²°ê³¼:")
        print(f"  ì´ í¬ìŠ¤íŠ¸: {summary.get('total_posts', 0)}ê°œ")
        print(f"  ì´ ëŒ“ê¸€: {summary.get('total_comments', 0)}ê°œ")
        print(f"  í‰ê·  í¬ìŠ¤íŠ¸ ì ìˆ˜: {summary.get('avg_post_score', 0)}")
        
        # ê°ì • ë¶„ì„
        sentiment = reddit_data.get('sentiment_analysis', {})
        if sentiment:
            print(f"\nðŸ’­ ì „ì²´ ê°ì • ë¶„ì„:")
            print(f"  ì „ì²´ ê°ì •: {sentiment.get('overall_sentiment', 'unknown')}")
            percentages = sentiment.get('percentages', {})
            print(f"  ê¸ì •: {percentages.get('positive', 0)}%")
            print(f"  ë¶€ì •: {percentages.get('negative', 0)}%")
            print(f"  ì¤‘ë¦½: {percentages.get('neutral', 0)}%")
        
        # íŠ¸ë Œë”© ì£¼ì œ
        trending = reddit_data.get('trending_topics', {})
        if trending:
            print(f"\nðŸ”¥ íŠ¸ë Œë”© ì£¼ì œ:")
            for topic, count in list(trending.items())[:5]:
                print(f"  {topic}: {count}íšŒ ì–¸ê¸‰")
        
        # ì¸ê¸° ì„œë¸Œë ˆë”§
        top_subreddits = summary.get('top_subreddits', {})
        if top_subreddits:
            print(f"\nðŸ“ˆ í™œë°œí•œ ì„œë¸Œë ˆë”§:")
            for subreddit, count in top_subreddits.items():
                print(f"  r/{subreddit}: {count}ê°œ í¬ìŠ¤íŠ¸")
        
        print(f"\nâœ… Reddit ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
