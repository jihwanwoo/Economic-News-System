#!/usr/bin/env python3
"""
ì‹¤ì œ Reddit ë°ì´í„° ìˆ˜ì§‘ê¸° (ê°€ìƒ ë°ì´í„° ì—†ìŒ)
.env íŒŒì¼ì˜ API í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ Reddit ë°ì´í„°ë§Œ ìˆ˜ì§‘
"""

import os
import sys
import praw
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dotenv import load_dotenv
import time
import re

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

class RealRedditCollector:
    """ì‹¤ì œ Reddit ë°ì´í„°ë§Œ ìˆ˜ì§‘í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        """Reddit API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        self.logger = logging.getLogger(__name__)
        
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ Reddit ìê²©ì¦ëª… ë¡œë“œ
        self.client_id = os.getenv('REDDIT_CLIENT_ID')
        self.client_secret = os.getenv('REDDIT_CLIENT_SECRET')
        self.user_agent = os.getenv('REDDIT_USER_AGENT', 'EconomicNewsBot/1.0')
        
        if not self.client_id or not self.client_secret:
            raise ValueError("âŒ Reddit API ìê²©ì¦ëª…ì´ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Reddit í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            self.reddit = praw.Reddit(
                client_id=self.client_id,
                client_secret=self.client_secret,
                user_agent=self.user_agent
            )
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            test_subreddit = self.reddit.subreddit('economics')
            _ = test_subreddit.display_name  # ì‹¤ì œ API í˜¸ì¶œë¡œ ì—°ê²° í™•ì¸
            
            self.logger.info(f"âœ… Reddit API ì—°ê²° ì„±ê³µ")
            
        except Exception as e:
            self.logger.error(f"âŒ Reddit API ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
        
        # ê²½ì œ ê´€ë ¨ ì„œë¸Œë ˆë”§ ëª©ë¡
        self.economic_subreddits = [
            'economics',
            'investing', 
            'stocks',
            'personalfinance',
            'SecurityAnalysis',
            'ValueInvesting',
            'financialindependence',
            'StockMarket'
        ]
        
        self.logger.info(f"âœ… ì‹¤ì œ Reddit ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def collect_economic_posts(self, max_posts_per_subreddit: int = 10) -> Dict[str, Any]:
        """ê²½ì œ ê´€ë ¨ Reddit í¬ìŠ¤íŠ¸ ìˆ˜ì§‘"""
        
        self.logger.info(f"ğŸ“± ì‹¤ì œ Reddit ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (ì„œë¸Œë ˆë”§ë‹¹ ìµœëŒ€ {max_posts_per_subreddit}ê°œ)")
        
        all_posts = []
        subreddit_stats = {}
        
        for subreddit_name in self.economic_subreddits:
            try:
                self.logger.info(f"ğŸ” r/{subreddit_name} ìˆ˜ì§‘ ì¤‘...")
                
                subreddit = self.reddit.subreddit(subreddit_name)
                posts = []
                
                # ì¸ê¸° í¬ìŠ¤íŠ¸ ìˆ˜ì§‘
                for post in subreddit.hot(limit=max_posts_per_subreddit):
                    try:
                        # í¬ìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ
                        post_data = {
                            'id': post.id,
                            'title': post.title,
                            'selftext': post.selftext,
                            'score': post.score,
                            'upvote_ratio': post.upvote_ratio,
                            'num_comments': post.num_comments,
                            'created_utc': datetime.fromtimestamp(post.created_utc),
                            'author': str(post.author) if post.author else '[deleted]',
                            'subreddit': subreddit_name,
                            'url': post.url,
                            'permalink': f"https://reddit.com{post.permalink}",
                            'is_self': post.is_self,
                            'over_18': post.over_18,
                            'spoiler': post.spoiler,
                            'stickied': post.stickied
                        }
                        
                        # ê°ì • ë¶„ì„ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
                        post_data['sentiment'] = self._analyze_post_sentiment(post.title, post.selftext)
                        
                        # ê²½ì œ ê´€ë ¨ì„± ì ìˆ˜
                        post_data['economic_relevance'] = self._calculate_economic_relevance(post.title, post.selftext)
                        
                        posts.append(post_data)
                        all_posts.append(post_data)
                        
                    except Exception as e:
                        self.logger.warning(f"í¬ìŠ¤íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜ (r/{subreddit_name}): {e}")
                        continue
                
                subreddit_stats[subreddit_name] = {
                    'posts_collected': len(posts),
                    'subscribers': subreddit.subscribers,
                    'active_users': getattr(subreddit, 'active_user_count', None)
                }
                
                self.logger.info(f"âœ… r/{subreddit_name}: {len(posts)}ê°œ í¬ìŠ¤íŠ¸ ìˆ˜ì§‘")
                
                # Rate limiting
                time.sleep(1)
                
            except Exception as e:
                self.logger.error(f"âŒ r/{subreddit_name} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                subreddit_stats[subreddit_name] = {
                    'posts_collected': 0,
                    'error': str(e)
                }
                continue
        
        # ê²°ê³¼ ì •ë¦¬
        result = {
            'status': 'success',
            'timestamp': datetime.now().isoformat(),
            'total_posts': len(all_posts),
            'posts': all_posts,
            'subreddit_stats': subreddit_stats,
            'collection_summary': self._generate_collection_summary(all_posts, subreddit_stats)
        }
        
        self.logger.info(f"âœ… Reddit ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(all_posts)}ê°œ í¬ìŠ¤íŠ¸")
        return result
    
    def collect_economic_comments(self, max_comments_per_subreddit: int = 20) -> Dict[str, Any]:
        """ê²½ì œ ê´€ë ¨ Reddit ëŒ“ê¸€ ìˆ˜ì§‘"""
        
        self.logger.info(f"ğŸ’¬ ì‹¤ì œ Reddit ëŒ“ê¸€ ìˆ˜ì§‘ ì‹œì‘")
        
        all_comments = []
        
        for subreddit_name in self.economic_subreddits[:3]:  # ì²˜ìŒ 3ê°œ ì„œë¸Œë ˆë”§ë§Œ
            try:
                self.logger.info(f"ğŸ” r/{subreddit_name} ëŒ“ê¸€ ìˆ˜ì§‘ ì¤‘...")
                
                subreddit = self.reddit.subreddit(subreddit_name)
                
                # ì¸ê¸° í¬ìŠ¤íŠ¸ì˜ ëŒ“ê¸€ ìˆ˜ì§‘
                for post in subreddit.hot(limit=3):  # í¬ìŠ¤íŠ¸ë‹¹ 3ê°œë§Œ
                    try:
                        post.comments.replace_more(limit=0)  # "ë” ë³´ê¸°" ëŒ“ê¸€ ì œê±°
                        
                        comment_count = 0
                        for comment in post.comments.list():
                            if comment_count >= max_comments_per_subreddit // 3:
                                break
                            
                            if hasattr(comment, 'body') and len(comment.body) > 20:
                                comment_data = {
                                    'id': comment.id,
                                    'body': comment.body,
                                    'score': comment.score,
                                    'created_utc': datetime.fromtimestamp(comment.created_utc),
                                    'author': str(comment.author) if comment.author else '[deleted]',
                                    'subreddit': subreddit_name,
                                    'post_id': post.id,
                                    'post_title': post.title,
                                    'permalink': f"https://reddit.com{comment.permalink}"
                                }
                                
                                # ê°ì • ë¶„ì„
                                comment_data['sentiment'] = self._analyze_comment_sentiment(comment.body)
                                
                                all_comments.append(comment_data)
                                comment_count += 1
                        
                    except Exception as e:
                        self.logger.warning(f"ëŒ“ê¸€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        continue
                
                self.logger.info(f"âœ… r/{subreddit_name}: ëŒ“ê¸€ ìˆ˜ì§‘ ì™„ë£Œ")
                time.sleep(2)  # Rate limiting
                
            except Exception as e:
                self.logger.error(f"âŒ r/{subreddit_name} ëŒ“ê¸€ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                continue
        
        result = {
            'status': 'success',
            'timestamp': datetime.now().isoformat(),
            'total_comments': len(all_comments),
            'comments': all_comments
        }
        
        self.logger.info(f"âœ… Reddit ëŒ“ê¸€ ìˆ˜ì§‘ ì™„ë£Œ: {len(all_comments)}ê°œ ëŒ“ê¸€")
        return result
    
    def _analyze_post_sentiment(self, title: str, selftext: str) -> Dict[str, Any]:
        """í¬ìŠ¤íŠ¸ ê°ì • ë¶„ì„ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        
        text = f"{title} {selftext}".lower()
        
        # ê¸ì •ì  í‚¤ì›Œë“œ
        positive_keywords = [
            'good', 'great', 'excellent', 'positive', 'bullish', 'growth', 'profit',
            'success', 'opportunity', 'optimistic', 'recovery', 'improvement'
        ]
        
        # ë¶€ì •ì  í‚¤ì›Œë“œ  
        negative_keywords = [
            'bad', 'terrible', 'negative', 'bearish', 'loss', 'crash', 'decline',
            'recession', 'crisis', 'worry', 'concern', 'risk', 'problem'
        ]
        
        positive_count = sum(1 for keyword in positive_keywords if keyword in text)
        negative_count = sum(1 for keyword in negative_keywords if keyword in text)
        
        if positive_count > negative_count:
            sentiment = 'positive'
            polarity = 0.3
        elif negative_count > positive_count:
            sentiment = 'negative'
            polarity = -0.3
        else:
            sentiment = 'neutral'
            polarity = 0.0
        
        return {
            'label': sentiment,
            'polarity': polarity,
            'positive_keywords': positive_count,
            'negative_keywords': negative_count
        }
    
    def _analyze_comment_sentiment(self, text: str) -> Dict[str, Any]:
        """ëŒ“ê¸€ ê°ì • ë¶„ì„"""
        return self._analyze_post_sentiment(text, "")
    
    def _calculate_economic_relevance(self, title: str, selftext: str) -> float:
        """ê²½ì œ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        
        text = f"{title} {selftext}".lower()
        
        economic_keywords = [
            'economy', 'economic', 'finance', 'financial', 'market', 'stock', 'investment',
            'inflation', 'recession', 'gdp', 'fed', 'interest rate', 'monetary policy',
            'fiscal policy', 'unemployment', 'employment', 'trade', 'currency', 'dollar',
            'bitcoin', 'cryptocurrency', 'real estate', 'housing', 'mortgage'
        ]
        
        relevance_score = 0
        for keyword in economic_keywords:
            if keyword in text:
                relevance_score += 1
        
        # 0-1 ì‚¬ì´ë¡œ ì •ê·œí™”
        return min(relevance_score / 5.0, 1.0)
    
    def _generate_collection_summary(self, posts: List[Dict], subreddit_stats: Dict) -> Dict[str, Any]:
        """ìˆ˜ì§‘ ìš”ì•½ ìƒì„±"""
        
        if not posts:
            return {'error': 'No posts collected'}
        
        # ê°ì • ë¶„ì„ ìš”ì•½
        sentiments = [post['sentiment']['label'] for post in posts]
        sentiment_counts = {
            'positive': sentiments.count('positive'),
            'negative': sentiments.count('negative'),
            'neutral': sentiments.count('neutral')
        }
        
        # ìƒìœ„ ì„œë¸Œë ˆë”§
        subreddit_counts = {}
        for post in posts:
            subreddit = post['subreddit']
            subreddit_counts[subreddit] = subreddit_counts.get(subreddit, 0) + 1
        
        top_subreddits = sorted(subreddit_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        
        # í‰ê·  ì ìˆ˜
        avg_score = sum(post['score'] for post in posts) / len(posts)
        avg_comments = sum(post['num_comments'] for post in posts) / len(posts)
        
        return {
            'total_posts': len(posts),
            'sentiment_distribution': sentiment_counts,
            'top_subreddits': top_subreddits,
            'average_score': round(avg_score, 1),
            'average_comments': round(avg_comments, 1),
            'successful_subreddits': len([s for s in subreddit_stats.values() if 'error' not in s]),
            'failed_subreddits': len([s for s in subreddit_stats.values() if 'error' in s])
        }
    
    def get_texts_for_network_analysis(self, max_posts: int = 50) -> List[str]:
        """ë„¤íŠ¸ì›Œí¬ ë¶„ì„ìš© í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        
        self.logger.info(f"ğŸ•¸ï¸ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ìš© í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (ìµœëŒ€ {max_posts}ê°œ)")
        
        try:
            # í¬ìŠ¤íŠ¸ ìˆ˜ì§‘
            posts_data = self.collect_economic_posts(max_posts_per_subreddit=max_posts//len(self.economic_subreddits))
            
            texts = []
            for post in posts_data['posts']:
                # ì œëª©ê³¼ ë³¸ë¬¸ ê²°í•©
                title = post['title'].strip()
                selftext = post['selftext'].strip()
                
                if selftext:
                    combined_text = f"{title}. {selftext}"
                else:
                    combined_text = title
                
                # ìµœì†Œ ê¸¸ì´ í•„í„°
                if len(combined_text) > 20:
                    texts.append(combined_text)
            
            self.logger.info(f"âœ… ë„¤íŠ¸ì›Œí¬ ë¶„ì„ìš© í…ìŠ¤íŠ¸ {len(texts)}ê°œ ì¶”ì¶œ")
            return texts
            
        except Exception as e:
            self.logger.error(f"âŒ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ìš© í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    try:
        collector = RealRedditCollector()
        
        print("ğŸ“± ì‹¤ì œ Reddit ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸")
        print("=" * 50)
        
        # í¬ìŠ¤íŠ¸ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
        posts_result = collector.collect_economic_posts(max_posts_per_subreddit=3)
        
        print(f"âœ… í¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ê²°ê³¼:")
        print(f"   ì´ í¬ìŠ¤íŠ¸: {posts_result['total_posts']}ê°œ")
        print(f"   ì„±ê³µí•œ ì„œë¸Œë ˆë”§: {posts_result['collection_summary']['successful_subreddits']}ê°œ")
        print(f"   ì‹¤íŒ¨í•œ ì„œë¸Œë ˆë”§: {posts_result['collection_summary']['failed_subreddits']}ê°œ")
        
        if posts_result['posts']:
            sample_post = posts_result['posts'][0]
            print(f"\nğŸ“ ìƒ˜í”Œ í¬ìŠ¤íŠ¸:")
            print(f"   ì œëª©: {sample_post['title'][:60]}...")
            print(f"   ì„œë¸Œë ˆë”§: r/{sample_post['subreddit']}")
            print(f"   ì ìˆ˜: {sample_post['score']}")
            print(f"   ëŒ“ê¸€ ìˆ˜: {sample_post['num_comments']}")
        
        # ë„¤íŠ¸ì›Œí¬ ë¶„ì„ìš© í…ìŠ¤íŠ¸ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
        texts = collector.get_texts_for_network_analysis(max_posts=20)
        print(f"\nğŸ•¸ï¸ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ìš© í…ìŠ¤íŠ¸: {len(texts)}ê°œ")
        
        if texts:
            print(f"   ìƒ˜í”Œ í…ìŠ¤íŠ¸: {texts[0][:80]}...")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        print("\nğŸ”§ í•´ê²° ë°©ë²•:")
        print("1. .env íŒŒì¼ì— Reddit API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
        print("2. ì¸í„°ë„· ì—°ê²° ìƒíƒœ í™•ì¸")
        print("3. Reddit API ì‚¬ìš©ëŸ‰ ì œí•œ í™•ì¸")
